{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14422,
     "status": "ok",
     "timestamp": 1742788815436,
     "user": {
      "displayName": "Reilly H",
      "userId": "05616995266737589283"
     },
     "user_tz": -780
    },
    "id": "56erhy86NuEA",
    "outputId": "512696d7-b0c8-4ad9-ea93-c2865e6ae145"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n",
      "/tmp/ipykernel_40563/3899178729.py:742: UserWarning: Some groups have less than 5 prompts, they have lengths [1]\n",
      "  warnings.warn(\n",
      "2025-05-06 11:42:35.092751: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-06 11:42:35.111380: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-05-06 11:42:35.111400: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-05-06 11:42:35.111951: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-05-06 11:42:35.115102: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-05-06 11:42:35.629110: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "from logging import warning\n",
    "from typing import Union, List\n",
    "from site import PREFIXES\n",
    "import warnings\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer\n",
    "import random\n",
    "random.seed(42)\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "\n",
    "NAMES = [\n",
    "    \"Michael\",\n",
    "    \"Christopher\",\n",
    "    \"Jessica\",\n",
    "    \"Matthew\",\n",
    "    \"Ashley\",\n",
    "    \"Jennifer\",\n",
    "    \"Joshua\",\n",
    "    \"Amanda\",\n",
    "    \"Daniel\",\n",
    "    \"David\",\n",
    "    \"James\",\n",
    "    \"Robert\",\n",
    "    \"John\",\n",
    "    \"Joseph\",\n",
    "    \"Andrew\",\n",
    "    \"Ryan\",\n",
    "    \"Brandon\",\n",
    "    \"Jason\",\n",
    "    \"Justin\",\n",
    "    \"Sarah\",\n",
    "    \"William\",\n",
    "    \"Jonathan\",\n",
    "    \"Stephanie\",\n",
    "    \"Brian\",\n",
    "    \"Nicole\",\n",
    "    \"Nicholas\",\n",
    "    \"Anthony\",\n",
    "    \"Heather\",\n",
    "    \"Eric\",\n",
    "    \"Elizabeth\",\n",
    "    \"Adam\",\n",
    "    \"Megan\",\n",
    "    \"Melissa\",\n",
    "    \"Kevin\",\n",
    "    \"Steven\",\n",
    "    \"Thomas\",\n",
    "    \"Timothy\",\n",
    "    \"Christina\",\n",
    "    \"Kyle\",\n",
    "    \"Rachel\",\n",
    "    \"Laura\",\n",
    "    \"Lauren\",\n",
    "    \"Amber\",\n",
    "    \"Brittany\",\n",
    "    \"Danielle\",\n",
    "    \"Richard\",\n",
    "    \"Kimberly\",\n",
    "    \"Jeffrey\",\n",
    "    \"Amy\",\n",
    "    \"Crystal\",\n",
    "    \"Michelle\",\n",
    "    \"Tiffany\",\n",
    "    \"Jeremy\",\n",
    "    \"Benjamin\",\n",
    "    \"Mark\",\n",
    "    \"Emily\",\n",
    "    \"Aaron\",\n",
    "    \"Charles\",\n",
    "    \"Rebecca\",\n",
    "    \"Jacob\",\n",
    "    \"Stephen\",\n",
    "    \"Patrick\",\n",
    "    \"Sean\",\n",
    "    \"Erin\",\n",
    "    \"Jamie\",\n",
    "    \"Kelly\",\n",
    "    \"Samantha\",\n",
    "    \"Nathan\",\n",
    "    \"Sara\",\n",
    "    \"Dustin\",\n",
    "    \"Paul\",\n",
    "    \"Angela\",\n",
    "    \"Tyler\",\n",
    "    \"Scott\",\n",
    "    \"Katherine\",\n",
    "    \"Andrea\",\n",
    "    \"Gregory\",\n",
    "    \"Erica\",\n",
    "    \"Mary\",\n",
    "    \"Travis\",\n",
    "    \"Lisa\",\n",
    "    \"Kenneth\",\n",
    "    \"Bryan\",\n",
    "    \"Lindsey\",\n",
    "    \"Kristen\",\n",
    "    \"Jose\",\n",
    "    \"Alexander\",\n",
    "    \"Jesse\",\n",
    "    \"Katie\",\n",
    "    \"Lindsay\",\n",
    "    \"Shannon\",\n",
    "    \"Vanessa\",\n",
    "    \"Courtney\",\n",
    "    \"Christine\",\n",
    "    \"Alicia\",\n",
    "    \"Cody\",\n",
    "    \"Allison\",\n",
    "    \"Bradley\",\n",
    "    \"Samuel\",\n",
    "]\n",
    "\n",
    "ABC_TEMPLATES = [\n",
    "    \"Then, [A], [B] and [C] went to the [PLACE]. [B] and [C] gave a [OBJECT] to [A]\",\n",
    "    \"Afterwards [A], [B] and [C] went to the [PLACE]. [B] and [C] gave a [OBJECT] to [A]\",\n",
    "    \"When [A], [B] and [C] arrived at the [PLACE], [B] and [C] gave a [OBJECT] to [A]\",\n",
    "    \"Friends [A], [B] and [C] went to the [PLACE]. [B] and [C] gave a [OBJECT] to [A]\",\n",
    "]\n",
    "\n",
    "BAC_TEMPLATES = [\n",
    "    template.replace(\"[B]\", \"[A]\", 1).replace(\"[A]\", \"[B]\", 1)\n",
    "    for template in ABC_TEMPLATES\n",
    "]\n",
    "\n",
    "BABA_TEMPLATES = [\n",
    "    \"Then, [B] and [A] went to the [PLACE]. [B] gave a [OBJECT] to [A]\",\n",
    "    \"Then, [B] and [A] had a lot of fun at the [PLACE]. [B] gave a [OBJECT] to [A]\",\n",
    "    \"Then, [B] and [A] were working at the [PLACE]. [B] decided to give a [OBJECT] to [A]\",\n",
    "    \"Then, [B] and [A] were thinking about going to the [PLACE]. [B] wanted to give a [OBJECT] to [A]\",\n",
    "    \"Then, [B] and [A] had a long argument, and afterwards [B] said to [A]\",\n",
    "    \"After [B] and [A] went to the [PLACE], [B] gave a [OBJECT] to [A]\",\n",
    "    \"When [B] and [A] got a [OBJECT] at the [PLACE], [B] decided to give it to [A]\",\n",
    "    \"When [B] and [A] got a [OBJECT] at the [PLACE], [B] decided to give the [OBJECT] to [A]\",\n",
    "    \"While [B] and [A] were working at the [PLACE], [B] gave a [OBJECT] to [A]\",\n",
    "    \"While [B] and [A] were commuting to the [PLACE], [B] gave a [OBJECT] to [A]\",\n",
    "    \"After the lunch, [B] and [A] went to the [PLACE]. [B] gave a [OBJECT] to [A]\",\n",
    "    \"Afterwards, [B] and [A] went to the [PLACE]. [B] gave a [OBJECT] to [A]\",\n",
    "    \"Then, [B] and [A] had a long argument. Afterwards [B] said to [A]\",\n",
    "    \"The [PLACE] [B] and [A] went to had a [OBJECT]. [B] gave it to [A]\",\n",
    "    \"Friends [B] and [A] found a [OBJECT] at the [PLACE]. [B] gave it to [A]\",\n",
    "]\n",
    "\n",
    "BABA_LONG_TEMPLATES = [\n",
    "    \"Then in the morning, [B] and [A] went to the [PLACE]. [B] gave a [OBJECT] to [A]\",\n",
    "    \"Then in the morning, [B] and [A] had a lot of fun at the [PLACE]. [B] gave a [OBJECT] to [A]\",\n",
    "    \"Then in the morning, [B] and [A] were working at the [PLACE]. [B] decided to give a [OBJECT] to [A]\",\n",
    "    \"Then in the morning, [B] and [A] were thinking about going to the [PLACE]. [B] wanted to give a [OBJECT] to [A]\",\n",
    "    \"Then in the morning, [B] and [A] had a long argument, and afterwards [B] said to [A]\",\n",
    "    \"After taking a long break [B] and [A] went to the [PLACE], [B] gave a [OBJECT] to [A]\",\n",
    "    \"When soon afterwards [B] and [A] got a [OBJECT] at the [PLACE], [B] decided to give it to [A]\",\n",
    "    \"When soon afterwards [B] and [A] got a [OBJECT] at the [PLACE], [B] decided to give the [OBJECT] to [A]\",\n",
    "    \"While spending time together [B] and [A] were working at the [PLACE], [B] gave a [OBJECT] to [A]\",\n",
    "    \"While spending time together [B] and [A] were commuting to the [PLACE], [B] gave a [OBJECT] to [A]\",\n",
    "    \"After the lunch in the afternoon, [B] and [A] went to the [PLACE]. [B] gave a [OBJECT] to [A]\",\n",
    "    \"Afterwards, while spending time together [B] and [A] went to the [PLACE]. [B] gave a [OBJECT] to [A]\",\n",
    "    \"Then in the morning afterwards, [B] and [A] had a long argument. Afterwards [B] said to [A]\",\n",
    "    \"The local big [PLACE] [B] and [A] went to had a [OBJECT]. [B] gave it to [A]\",\n",
    "    \"Friends separated at birth [B] and [A] found a [OBJECT] at the [PLACE]. [B] gave it to [A]\",\n",
    "]\n",
    "\n",
    "BABA_LATE_IOS = [\n",
    "    \"Then, [B] and [A] went to the [PLACE]. [B] gave a [OBJECT] to [A]\",\n",
    "    \"Then, [B] and [A] had a lot of fun at the [PLACE]. [B] gave a [OBJECT] to [A]\",\n",
    "    \"Then, [B] and [A] were working at the [PLACE]. [B] decided to give a [OBJECT] to [A]\",\n",
    "    \"Then, [B] and [A] were thinking about going to the [PLACE]. [B] wanted to give a [OBJECT] to [A]\",\n",
    "    \"Then, [B] and [A] had a long argument and after that [B] said to [A]\",\n",
    "    \"After the lunch, [B] and [A] went to the [PLACE]. [B] gave a [OBJECT] to [A]\",\n",
    "    \"Afterwards, [B] and [A] went to the [PLACE]. [B] gave a [OBJECT] to [A]\",\n",
    "    \"Then, [B] and [A] had a long argument. Afterwards [B] said to [A]\",\n",
    "]\n",
    "\n",
    "BABA_EARLY_IOS = [\n",
    "    \"Then [B] and [A] went to the [PLACE], and [B] gave a [OBJECT] to [A]\",\n",
    "    \"Then [B] and [A] had a lot of fun at the [PLACE], and [B] gave a [OBJECT] to [A]\",\n",
    "    \"Then [B] and [A] were working at the [PLACE], and [B] decided to give a [OBJECT] to [A]\",\n",
    "    \"Then [B] and [A] were thinking about going to the [PLACE], and [B] wanted to give a [OBJECT] to [A]\",\n",
    "    \"Then [B] and [A] had a long argument, and after that [B] said to [A]\",\n",
    "    \"After the lunch [B] and [A] went to the [PLACE], and [B] gave a [OBJECT] to [A]\",\n",
    "    \"Afterwards [B] and [A] went to the [PLACE], and [B] gave a [OBJECT] to [A]\",\n",
    "    \"Then [B] and [A] had a long argument, and afterwards [B] said to [A]\",\n",
    "]\n",
    "\n",
    "TEMPLATES_VARIED_MIDDLE = [\n",
    "    \"\",\n",
    "]\n",
    "\n",
    "# no end of texts, GPT-2 small wasn't trained this way (ask Arthur)\n",
    "# warnings.warn(\"Adding end of text prefixes!\")\n",
    "# for TEMPLATES in [BABA_TEMPLATES, BABA_EARLY_IOS, BABA_LATE_IOS]:\n",
    "#     for i in range(len(TEMPLATES)):\n",
    "#         TEMPLATES[i] = \"<|endoftext|>\" + TEMPLATES[i]\n",
    "\n",
    "ABBA_TEMPLATES = BABA_TEMPLATES[:]\n",
    "ABBA_LATE_IOS = BABA_LATE_IOS[:]\n",
    "ABBA_EARLY_IOS = BABA_EARLY_IOS[:]\n",
    "\n",
    "for TEMPLATES in [ABBA_TEMPLATES, ABBA_LATE_IOS, ABBA_EARLY_IOS]:\n",
    "    for i in range(len(TEMPLATES)):\n",
    "        first_clause = True\n",
    "        for j in range(1, len(TEMPLATES[i]) - 1):\n",
    "            if TEMPLATES[i][j - 1 : j + 2] == \"[B]\" and first_clause:\n",
    "                TEMPLATES[i] = TEMPLATES[i][:j] + \"A\" + TEMPLATES[i][j + 1 :]\n",
    "            elif TEMPLATES[i][j - 1 : j + 2] == \"[A]\" and first_clause:\n",
    "                first_clause = False\n",
    "                TEMPLATES[i] = TEMPLATES[i][:j] + \"B\" + TEMPLATES[i][j + 1 :]\n",
    "\n",
    "VERBS = [\" tried\", \" said\", \" decided\", \" wanted\", \" gave\"]\n",
    "PLACES = [\n",
    "    \"store\",\n",
    "    \"garden\",\n",
    "    \"restaurant\",\n",
    "    \"school\",\n",
    "    \"hospital\",\n",
    "    \"office\",\n",
    "    \"house\",\n",
    "    \"station\",\n",
    "]\n",
    "OBJECTS = [\n",
    "    \"ring\",\n",
    "    \"kiss\",\n",
    "    \"bone\",\n",
    "    \"basketball\",\n",
    "    \"computer\",\n",
    "    \"necklace\",\n",
    "    \"drink\",\n",
    "    \"snack\",\n",
    "]\n",
    "\n",
    "ANIMALS = [\n",
    "    \"dog\",\n",
    "    \"cat\",\n",
    "    \"snake\",\n",
    "    \"elephant\",\n",
    "    \"beetle\",\n",
    "    \"hippo\",\n",
    "    \"giraffe\",\n",
    "    \"tiger\",\n",
    "    \"husky\",\n",
    "    \"lion\",\n",
    "    \"panther\",\n",
    "    \"whale\",\n",
    "    \"dolphin\",\n",
    "    \"beaver\",\n",
    "    \"rabbit\",\n",
    "    \"fox\",\n",
    "    \"lamb\",\n",
    "    \"ferret\",\n",
    "]\n",
    "\n",
    "\n",
    "def multiple_replace(dict, text):\n",
    "    # from: https://stackoverflow.com/questions/15175142/how-can-i-do-multiple-substitutions-using-regex\n",
    "    # Create a regular expression from the dictionary keys\n",
    "    regex = re.compile(\"(%s)\" % \"|\".join(map(re.escape, dict.keys())))\n",
    "\n",
    "    # For each match, look-up corresponding value in dictionary\n",
    "    return regex.sub(lambda mo: dict[mo.string[mo.start() : mo.end()]], text)\n",
    "\n",
    "\n",
    "def iter_sample_fast(iterable, samplesize):\n",
    "    results = []\n",
    "    try:\n",
    "        for _ in range(samplesize):\n",
    "            results.append(next(iterable))\n",
    "    except StopIteration:\n",
    "        raise ValueError(\"Sample larger than population.\")\n",
    "    random.shuffle(results)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "NOUNS_DICT = NOUNS_DICT = {\"[PLACE]\": PLACES, \"[OBJECT]\": OBJECTS}\n",
    "\n",
    "\n",
    "def gen_prompt_uniform(\n",
    "    templates, names, nouns_dict, N, symmetric, prefixes=None, abc=False\n",
    "):\n",
    "    nb_gen = 0\n",
    "    ioi_prompts = []\n",
    "    while nb_gen < N:\n",
    "        temp = random.choice(templates)\n",
    "        temp_id = templates.index(temp)\n",
    "        name_1 = \"\"\n",
    "        name_2 = \"\"\n",
    "        name_3 = \"\"\n",
    "        while len(set([name_1, name_2, name_3])) < 3:\n",
    "            name_1 = random.choice(names)\n",
    "            name_2 = random.choice(names)\n",
    "            name_3 = random.choice(names)\n",
    "\n",
    "        nouns = {}\n",
    "        ioi_prompt = {}\n",
    "        for k in nouns_dict:\n",
    "            nouns[k] = random.choice(nouns_dict[k])\n",
    "            ioi_prompt[k] = nouns[k]\n",
    "        prompt = temp\n",
    "        for k in nouns_dict:\n",
    "            prompt = prompt.replace(k, nouns[k])\n",
    "\n",
    "        if prefixes is not None:\n",
    "            L = random.randint(30, 40)\n",
    "            pref = \".\".join(random.choice(prefixes).split(\".\")[:L])\n",
    "            pref += \"<|endoftext|>\"\n",
    "        else:\n",
    "            pref = \"\"\n",
    "\n",
    "        prompt1 = prompt.replace(\"[A]\", name_1)\n",
    "        prompt1 = prompt1.replace(\"[B]\", name_2)\n",
    "        if abc:\n",
    "            prompt1 = prompt1.replace(\"[C]\", name_3)\n",
    "        prompt1 = pref + prompt1\n",
    "        ioi_prompt[\"text\"] = prompt1\n",
    "        ioi_prompt[\"IO\"] = name_1\n",
    "        ioi_prompt[\"S\"] = name_2\n",
    "        ioi_prompt[\"TEMPLATE_IDX\"] = temp_id\n",
    "        ioi_prompts.append(ioi_prompt)\n",
    "        if abc:\n",
    "            ioi_prompts[-1][\"C\"] = name_3\n",
    "\n",
    "        nb_gen += 1\n",
    "\n",
    "        if symmetric and nb_gen < N:\n",
    "            prompt2 = prompt.replace(\"[A]\", name_2)\n",
    "            prompt2 = prompt2.replace(\"[B]\", name_1)\n",
    "            prompt2 = pref + prompt2\n",
    "            ioi_prompts.append(\n",
    "                {\"text\": prompt2, \"IO\": name_2, \"S\": name_1, \"TEMPLATE_IDX\": temp_id}\n",
    "            )\n",
    "            nb_gen += 1\n",
    "    return ioi_prompts\n",
    "\n",
    "\n",
    "def gen_flipped_prompts(prompts, names, flip=(\"S2\", \"IO\")):\n",
    "    flipped_prompts = []\n",
    "\n",
    "    for prompt in prompts:\n",
    "        t = prompt[\"text\"].split(\" \")\n",
    "        prompt = prompt.copy()\n",
    "        if flip[0] == \"S2\":\n",
    "            if flip[1] == \"IO\":\n",
    "                t[len(t) - t[::-1].index(prompt[\"S\"]) - 1] = prompt[\"IO\"]\n",
    "                temp = prompt[\"IO\"]\n",
    "                prompt[\"IO\"] = prompt[\"S\"]\n",
    "                prompt[\"S\"] = temp\n",
    "            elif flip[1] == \"RAND\":\n",
    "                rand_name = names[np.random.randint(len(names))]\n",
    "                while rand_name == prompt[\"IO\"] or rand_name == prompt[\"S\"]:\n",
    "                    rand_name = names[np.random.randint(len(names))]\n",
    "                t[len(t) - t[::-1].index(prompt[\"S\"]) - 1] = rand_name\n",
    "            else:\n",
    "                raise ValueError(\"Invalid flip[1] value\")\n",
    "\n",
    "        elif flip[0] == \"IO\":\n",
    "            if flip[1] == \"RAND\":\n",
    "                rand_name = names[np.random.randint(len(names))]\n",
    "                while rand_name == prompt[\"IO\"] or rand_name == prompt[\"S\"]:\n",
    "                    rand_name = names[np.random.randint(len(names))]\n",
    "\n",
    "                t[t.index(prompt[\"IO\"])] = rand_name\n",
    "                t[t.index(prompt[\"IO\"])] = rand_name\n",
    "                prompt[\"IO\"] = rand_name\n",
    "            elif flip[1] == \"ANIMAL\":\n",
    "                rand_animal = ANIMALS[np.random.randint(len(ANIMALS))]\n",
    "                t[t.index(prompt[\"IO\"])] = rand_animal\n",
    "                prompt[\"IO\"] = rand_animal\n",
    "                # print(t)\n",
    "            elif flip[1] == \"S1\":\n",
    "                io_index = t.index(prompt[\"IO\"])\n",
    "                s1_index = t.index(prompt[\"S\"])\n",
    "                io = t[io_index]\n",
    "                s1 = t[s1_index]\n",
    "                t[io_index] = s1\n",
    "                t[s1_index] = io\n",
    "            else:\n",
    "                raise ValueError(\"Invalid flip[1] value\")\n",
    "\n",
    "        elif flip[0] in [\"S\", \"S1\"]:\n",
    "            if flip[1] == \"ANIMAL\":\n",
    "                new_s = ANIMALS[np.random.randint(len(ANIMALS))]\n",
    "            if flip[1] == \"RAND\":\n",
    "                new_s = names[np.random.randint(len(names))]\n",
    "            t[t.index(prompt[\"S\"])] = new_s\n",
    "            if flip[0] == \"S\":\n",
    "                t[len(t) - t[::-1].index(prompt[\"S\"]) - 1] = new_s\n",
    "                prompt[\"S\"] = new_s\n",
    "        elif flip[0] == \"END\":\n",
    "            if flip[1] == \"S\":\n",
    "                t[len(t) - t[::-1].index(prompt[\"IO\"]) - 1] = prompt[\"S\"]\n",
    "        elif flip[0] == \"PUNC\":\n",
    "            n = []\n",
    "\n",
    "            for i, word in enumerate(t):\n",
    "                if \".\" in word:\n",
    "                    n.append(word[:-1])\n",
    "                    n.append(\".\")\n",
    "                elif \",\" in word:\n",
    "                    n.append(word[:-1])\n",
    "                    n.append(\",\")\n",
    "                else:\n",
    "                    n.append(word)\n",
    "\n",
    "            if flip[1] == \"NONE\":\n",
    "                if \".\" in n:\n",
    "                    n[n.index(\".\")] = \"\"\n",
    "                elif \",\" in n:\n",
    "                    n[len(n) - n[::-1].index(\",\") - 1] = \"\"\n",
    "\n",
    "            while \"\" in n:\n",
    "                n.remove(\"\")\n",
    "\n",
    "            while \",\" in n:\n",
    "                n[n.index(\",\") - 1] += \",\"\n",
    "                n.remove(\",\")\n",
    "\n",
    "            while \".\" in n:\n",
    "                n[n.index(\".\") - 1] += \".\"\n",
    "                n.remove(\".\")\n",
    "\n",
    "            t = n\n",
    "\n",
    "        elif flip[0] == \"C2\":\n",
    "            if flip[1] == \"A\":\n",
    "                t[len(t) - t[::-1].index(prompt[\"C\"]) - 1] = prompt[\"A\"]\n",
    "        elif flip[0] == \"S+1\":\n",
    "            if t[t.index(prompt[\"S\"]) + 1] == \"and\":\n",
    "                t[t.index(prompt[\"S\"]) + 1] = [\n",
    "                    \"with one friend named\",\n",
    "                    \"accompanied by\",\n",
    "                ][np.random.randint(2)]\n",
    "            else:\n",
    "                t[t.index(prompt[\"S\"]) + 1] = (\n",
    "                    t[t.index(prompt[\"S\"])]\n",
    "                    + \", after a great day, \"\n",
    "                    + t[t.index(prompt[\"S\"]) + 1]\n",
    "                )\n",
    "                del t[t.index(prompt[\"S\"])]\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid flipper {flip[0]}\")\n",
    "\n",
    "        if \"IO\" in prompt:\n",
    "            prompt[\"text\"] = \" \".join(t)\n",
    "            flipped_prompts.append(prompt)\n",
    "        else:\n",
    "            flipped_prompts.append(\n",
    "                {\n",
    "                    \"A\": prompt[\"A\"],\n",
    "                    \"B\": prompt[\"B\"],\n",
    "                    \"C\": prompt[\"C\"],\n",
    "                    \"text\": \" \".join(t),\n",
    "                }\n",
    "            )\n",
    "\n",
    "    return flipped_prompts\n",
    "\n",
    "\n",
    "\n",
    "def get_name_idxs(prompts, tokenizer, idx_types=[\"IO\", \"S\", \"S2\"], prepend_bos=False):\n",
    "    name_idx_dict = dict((idx_type, []) for idx_type in idx_types)\n",
    "    double_s2 = False\n",
    "    for prompt in prompts:\n",
    "        t = prompt[\"text\"].split(\" \")\n",
    "        toks = tokenizer.tokenize(\" \".join(t[:-1]))\n",
    "        for idx_type in idx_types:\n",
    "            if \"2\" in idx_type:\n",
    "                idx = (\n",
    "                    len(toks)\n",
    "                    - toks[::-1].index(\n",
    "                        tokenizer.tokenize(\" \" + prompt[idx_type[:-1]])[0]\n",
    "                    )\n",
    "                    - 1\n",
    "                )\n",
    "            else:\n",
    "                idx = toks.index(tokenizer.tokenize(\" \" + prompt[idx_type])[0])\n",
    "            name_idx_dict[idx_type].append(idx)\n",
    "        if \"S\" in idx_types and \"S2\" in idx_types:\n",
    "            if name_idx_dict[\"S\"][-1] == name_idx_dict[\"S2\"][-1]:\n",
    "                double_s2 = True\n",
    "    if double_s2:\n",
    "        warnings.warn(\"S2 index has been computed as the same for S and S2\")\n",
    "\n",
    "    return [\n",
    "        int(prepend_bos) + torch.tensor(name_idx_dict[idx_type])\n",
    "        for idx_type in idx_types\n",
    "    ]\n",
    "\n",
    "\n",
    "def get_word_idxs(prompts, word_list, tokenizer):\n",
    "    idxs = []\n",
    "    tokenized_words = [\n",
    "        tokenizer.decode(tokenizer(word)[\"input_ids\"][0]) for word in word_list\n",
    "    ]\n",
    "    for pr_idx, prompt in enumerate(prompts):\n",
    "        toks = [\n",
    "            tokenizer.decode(t)\n",
    "            for t in tokenizer(prompt[\"text\"], return_tensors=\"pt\", padding=True)[\n",
    "                \"input_ids\"\n",
    "            ][0]\n",
    "        ]\n",
    "        idx = None\n",
    "        for i, w_tok in enumerate(tokenized_words):\n",
    "            if word_list[i] in prompt[\"text\"]:\n",
    "                try:\n",
    "                    idx = toks.index(w_tok)\n",
    "                    if toks.count(w_tok) > 1:\n",
    "                        idx = len(toks) - toks[::-1].index(w_tok) - 1\n",
    "                except:\n",
    "                    idx = toks.index(w_tok)\n",
    "                    # raise ValueError(toks, w_tok, prompt[\"text\"])\n",
    "        if idx is None:\n",
    "            raise ValueError(f\"Word {word_list} and {i} not found {prompt}\")\n",
    "        idxs.append(idx)\n",
    "    return torch.tensor(idxs)\n",
    "\n",
    "\n",
    "def get_end_idxs(prompts, tokenizer, name_tok_len=1, prepend_bos=False, toks=None):\n",
    "    # toks = torch.Tensor(tokenizer([prompt[\"text\"] for prompt in prompts], padding=True).input_ids).type(torch.int)\n",
    "    relevant_idx = int(prepend_bos)\n",
    "\n",
    "    pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "    end_idxs_raw = []\n",
    "    for i in range(toks.shape[0]):\n",
    "        if pad_token_id not in toks[i][1:]:\n",
    "            end_idxs_raw.append(toks.shape[1])\n",
    "            continue\n",
    "        nonzers = (toks[i] == pad_token_id).nonzero()\n",
    "        try:\n",
    "            nonzers = nonzers[relevant_idx]\n",
    "        except:\n",
    "            print(toks[i])\n",
    "            print(nonzers)\n",
    "            print(relevant_idx)\n",
    "            print(i)\n",
    "            raise ValueError(\"Something went wrong\")\n",
    "        nonzers = nonzers[0]\n",
    "        nonzers = nonzers.item()\n",
    "        end_idxs_raw.append(nonzers)\n",
    "    end_idxs = torch.tensor(end_idxs_raw)\n",
    "    end_idxs = end_idxs - 1 - name_tok_len\n",
    "\n",
    "    for i in range(toks.shape[0]):\n",
    "        assert toks[i][end_idxs[i] + 1] != 0 and (\n",
    "            toks.shape[1] == end_idxs[i] + 2 or toks[i][end_idxs[i] + 2] == pad_token_id\n",
    "        ), (\n",
    "            toks[i],\n",
    "            end_idxs[i],\n",
    "            toks[i].shape,\n",
    "            \"the END idxs aren't properly formatted\",\n",
    "        )\n",
    "\n",
    "    return end_idxs\n",
    "\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "ALL_SEM = [\n",
    "    \"S\",\n",
    "    \"IO\",\n",
    "    \"S2\",\n",
    "    \"end\",\n",
    "    \"S+1\",\n",
    "    \"and\",\n",
    "]\n",
    "\n",
    "\n",
    "def get_idx_dict(ioi_prompts, tokenizer, prepend_bos=False, toks=None):\n",
    "    (IO_idxs, S_idxs, S2_idxs,) = get_name_idxs(\n",
    "        ioi_prompts,\n",
    "        tokenizer,\n",
    "        idx_types=[\"IO\", \"S\", \"S2\"],\n",
    "        prepend_bos=prepend_bos,\n",
    "    )\n",
    "\n",
    "    end_idxs = get_end_idxs(\n",
    "        ioi_prompts,\n",
    "        tokenizer,\n",
    "        name_tok_len=1,\n",
    "        prepend_bos=prepend_bos,\n",
    "        toks=toks,\n",
    "    )\n",
    "\n",
    "    punct_idxs = get_word_idxs(ioi_prompts, [\",\", \".\"], tokenizer)\n",
    "\n",
    "    return {\n",
    "        \"IO\": IO_idxs,\n",
    "        \"IO-1\": IO_idxs - 1,\n",
    "        \"IO+1\": IO_idxs + 1,\n",
    "        \"S\": S_idxs,\n",
    "        \"S-1\": S_idxs - 1,\n",
    "        \"S+1\": S_idxs + 1,\n",
    "        \"S2\": S2_idxs,\n",
    "        \"end\": end_idxs,\n",
    "        \"starts\": torch.zeros_like(end_idxs),\n",
    "        \"punct\": punct_idxs,\n",
    "    }\n",
    "\n",
    "\n",
    "PREFIXES = [\n",
    "    \"             Afterwards,\",\n",
    "    \"            Two friends met at a bar. Then,\",\n",
    "    \"  After a long day,\",\n",
    "    \"  After a long day,\",\n",
    "    \"    Then,\",\n",
    "    \"         Then,\",\n",
    "]\n",
    "\n",
    "\n",
    "def flip_prefixes(ioi_prompts):\n",
    "    ioi_prompts = copy.deepcopy(ioi_prompts)\n",
    "    for prompt in ioi_prompts:\n",
    "        if prompt[\"text\"].startswith(\"The \"):\n",
    "            prompt[\"text\"] = \"After the lunch, the\" + prompt[\"text\"][4:]\n",
    "        else:\n",
    "            io_idx = prompt[\"text\"].index(prompt[\"IO\"])\n",
    "            s_idx = prompt[\"text\"].index(prompt[\"S\"])\n",
    "            first_idx = min(io_idx, s_idx)\n",
    "            prompt[\"text\"] = random.choice(PREFIXES) + \" \" + prompt[\"text\"][first_idx:]\n",
    "\n",
    "    return ioi_prompts\n",
    "\n",
    "\n",
    "def flip_names(ioi_prompts):\n",
    "    ioi_prompts = copy.deepcopy(ioi_prompts)\n",
    "    for prompt in ioi_prompts:\n",
    "        punct_idx = max(\n",
    "            [i for i, x in enumerate(list(prompt[\"text\"])) if x in [\",\", \".\"]]\n",
    "        )\n",
    "        io = prompt[\"IO\"]\n",
    "        s = prompt[\"S\"]\n",
    "        prompt[\"text\"] = (\n",
    "            prompt[\"text\"][:punct_idx]\n",
    "            .replace(io, \"#\")\n",
    "            .replace(s, \"@\")\n",
    "            .replace(\"#\", s)\n",
    "            .replace(\"@\", io)\n",
    "        ) + prompt[\"text\"][punct_idx:]\n",
    "        # print(prompt[\"text\"])\n",
    "\n",
    "    return ioi_prompts\n",
    "\n",
    "\n",
    "class IOIDataset:\n",
    "    def __init__(\n",
    "        self,\n",
    "        prompt_type: Union[\n",
    "            str, List[str]\n",
    "        ],  # if list, then it will be a list of templates\n",
    "        N=500,\n",
    "        tokenizer=None,\n",
    "        prompts=None,\n",
    "        symmetric=False,\n",
    "        prefixes=None,\n",
    "        nb_templates=None,\n",
    "        ioi_prompts_for_word_idxs=None,\n",
    "        prepend_bos=False,\n",
    "        manual_word_idx=None,\n",
    "    ):\n",
    "\n",
    "        if not (\n",
    "            N == 1\n",
    "            or prepend_bos == False\n",
    "            or tokenizer.bos_token_id == tokenizer.eos_token_id\n",
    "        ):\n",
    "            warnings.warn(\n",
    "                \"Probably word_idx will be calculated incorrectly due to this formatting\"\n",
    "            )\n",
    "        assert not (symmetric and prompt_type == \"ABC\")\n",
    "        assert (\n",
    "            (prompts is not None) or (not symmetric) or (N % 2 == 0)\n",
    "        ), f\"{symmetric} {N}\"\n",
    "        assert nb_templates is None or (nb_templates % 2 == 0 or prompt_type != \"mixed\")\n",
    "        self.prompt_type = prompt_type\n",
    "\n",
    "        if nb_templates is None:\n",
    "            nb_templates = len(BABA_TEMPLATES)\n",
    "\n",
    "        if prompt_type == \"ABBA\":\n",
    "            self.templates = ABBA_TEMPLATES[:nb_templates].copy()\n",
    "        elif prompt_type == \"BABA\":\n",
    "            self.templates = BABA_TEMPLATES[:nb_templates].copy()\n",
    "        elif prompt_type == \"mixed\":\n",
    "            self.templates = (\n",
    "                BABA_TEMPLATES[: nb_templates // 2].copy()\n",
    "                + ABBA_TEMPLATES[: nb_templates // 2].copy()\n",
    "            )\n",
    "            random.shuffle(self.templates)\n",
    "        elif prompt_type == \"ABC\":\n",
    "            self.templates = ABC_TEMPLATES[:nb_templates].copy()\n",
    "        elif prompt_type == \"BAC\":\n",
    "            self.templates = BAC_TEMPLATES[:nb_templates].copy()\n",
    "        elif prompt_type == \"ABC mixed\":\n",
    "            self.templates = (\n",
    "                ABC_TEMPLATES[: nb_templates // 2].copy()\n",
    "                + BAC_TEMPLATES[: nb_templates // 2].copy()\n",
    "            )\n",
    "            random.shuffle(self.templates)\n",
    "        elif isinstance(prompt_type, list):\n",
    "            self.templates = prompt_type\n",
    "        else:\n",
    "            raise ValueError(prompt_type)\n",
    "\n",
    "        if tokenizer is None:\n",
    "            self.tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "        else:\n",
    "            self.tokenizer = tokenizer\n",
    "\n",
    "        self.prefixes = prefixes\n",
    "        self.prompt_type = prompt_type\n",
    "        if prompts is None:\n",
    "            self.ioi_prompts = gen_prompt_uniform(  # a list of dict of the form {\"text\": \"Alice and Bob bla bla. Bob gave bla to Alice\", \"IO\": \"Alice\", \"S\": \"Bob\"}\n",
    "                self.templates,\n",
    "                NAMES,\n",
    "                nouns_dict={\"[PLACE]\": PLACES, \"[OBJECT]\": OBJECTS},\n",
    "                N=N,\n",
    "                symmetric=symmetric,\n",
    "                prefixes=self.prefixes,\n",
    "                abc=(prompt_type in [\"ABC\", \"ABC mixed\", \"BAC\"]),\n",
    "            )\n",
    "        else:\n",
    "            assert N == len(prompts), f\"{N} and {len(prompts)}\"\n",
    "            self.ioi_prompts = prompts\n",
    "\n",
    "        all_ids = [prompt[\"TEMPLATE_IDX\"] for prompt in self.ioi_prompts]\n",
    "        all_ids_ar = np.array(all_ids)\n",
    "        self.groups = []\n",
    "        for id in list(set(all_ids)):\n",
    "            self.groups.append(np.where(all_ids_ar == id)[0])\n",
    "\n",
    "        small_groups = []\n",
    "        for group in self.groups:\n",
    "            if len(group) < 5:\n",
    "                small_groups.append(len(group))\n",
    "        if len(small_groups) > 0:\n",
    "            warnings.warn(\n",
    "                f\"Some groups have less than 5 prompts, they have lengths {small_groups}\"\n",
    "            )\n",
    "\n",
    "        self.sentences = [\n",
    "            prompt[\"text\"] for prompt in self.ioi_prompts\n",
    "        ]  # a list of strings. Renamed as this should NOT be forward passed\n",
    "\n",
    "        self.templates_by_prompt = []  # for each prompt if it's ABBA or BABA\n",
    "        for i in range(N):\n",
    "            if self.sentences[i].index(self.ioi_prompts[i][\"IO\"]) < self.sentences[\n",
    "                i\n",
    "            ].index(self.ioi_prompts[i][\"S\"]):\n",
    "                self.templates_by_prompt.append(\"ABBA\")\n",
    "            else:\n",
    "                self.templates_by_prompt.append(\"BABA\")\n",
    "\n",
    "        # print(self.ioi_prompts, \"that's that\")\n",
    "        texts = [\n",
    "            (self.tokenizer.bos_token if prepend_bos else \"\") + prompt[\"text\"]\n",
    "            for prompt in self.ioi_prompts\n",
    "        ]\n",
    "        self.toks = torch.Tensor(self.tokenizer(texts, padding=True).input_ids).type(\n",
    "            torch.int\n",
    "        )\n",
    "\n",
    "        if ioi_prompts_for_word_idxs is None:\n",
    "            ioi_prompts_for_word_idxs = self.ioi_prompts\n",
    "        self.word_idx = get_idx_dict(\n",
    "            ioi_prompts_for_word_idxs,\n",
    "            self.tokenizer,\n",
    "            prepend_bos=prepend_bos,\n",
    "            toks=self.toks,\n",
    "        )\n",
    "        self.prepend_bos = prepend_bos\n",
    "        if manual_word_idx is not None:\n",
    "            self.word_idx = manual_word_idx\n",
    "\n",
    "        self.sem_tok_idx = {\n",
    "            k: v for k, v in self.word_idx.items() if k in ALL_SEM\n",
    "        }\n",
    "        self.N = N\n",
    "        self.max_len = max(\n",
    "            [\n",
    "                len(self.tokenizer(prompt[\"text\"]).input_ids)\n",
    "                for prompt in self.ioi_prompts\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.io_tokenIDs = [\n",
    "            self.tokenizer.encode(\" \" + prompt[\"IO\"])[0] for prompt in self.ioi_prompts\n",
    "        ]\n",
    "        self.s_tokenIDs = [\n",
    "            self.tokenizer.encode(\" \" + prompt[\"S\"])[0] for prompt in self.ioi_prompts\n",
    "        ]\n",
    "\n",
    "        self.tokenized_prompts = []\n",
    "\n",
    "        for i in range(self.N):\n",
    "            self.tokenized_prompts.append(\n",
    "                \"|\".join([self.tokenizer.decode(tok) for tok in self.toks[i]])\n",
    "            )\n",
    "\n",
    "    @classmethod\n",
    "    def construct_from_ioi_prompts_metadata(cls, templates, ioi_prompts_data, **kwargs):\n",
    "\n",
    "        prompts = []\n",
    "        for metadata in ioi_prompts_data:\n",
    "            cur_template = templates[metadata[\"TEMPLATE_IDX\"]]\n",
    "            prompts.append(metadata)\n",
    "            prompts[-1][\"text\"] = (\n",
    "                cur_template.replace(\"[A]\", metadata[\"IO\"])\n",
    "                .replace(\"[B]\", metadata[\"S\"])\n",
    "                .replace(\"[PLACE]\", metadata[\"[PLACE]\"])\n",
    "                .replace(\"[OBJECT]\", metadata[\"[OBJECT]\"])\n",
    "            )\n",
    "            # prompts[-1][\"[PLACE]\"] = metadata[\"[PLACE]\"]\n",
    "            # prompts[-1][\"[OBJECT]\"] = metadata[\"[OBJECT]\"]\n",
    "        return IOIDataset(prompt_type=templates, prompts=prompts, **kwargs)\n",
    "\n",
    "    def gen_flipped_prompts(self, flip):\n",
    "        assert isinstance(flip, tuple) or flip in [\n",
    "            \"prefix\",\n",
    "        ], f\"{flip} is not a tuple. Probably change to ('IO', 'RAND') or equivalent?\"\n",
    "\n",
    "        if flip == \"prefix\":\n",
    "            flipped_prompts = flip_prefixes(self.ioi_prompts)\n",
    "        else:\n",
    "            if flip in [(\"IO\", \"S1\"), (\"S\", \"IO\")]:\n",
    "                flipped_prompts = gen_flipped_prompts(\n",
    "                    self.ioi_prompts,\n",
    "                    None,\n",
    "                    flip,\n",
    "                )\n",
    "            elif flip == (\"S2\", \"IO\"):\n",
    "                flipped_prompts = gen_flipped_prompts(\n",
    "                    self.ioi_prompts,\n",
    "                    None,\n",
    "                    flip,\n",
    "                )\n",
    "\n",
    "            else:\n",
    "                assert flip[1] == \"RAND\" and flip[0] in [\n",
    "                    \"S\",\n",
    "                    \"RAND\",\n",
    "                    \"S2\",\n",
    "                    \"IO\",\n",
    "                    \"S1\",\n",
    "                    \"S+1\",\n",
    "                ], flip\n",
    "                flipped_prompts = gen_flipped_prompts(self.ioi_prompts, NAMES, flip)\n",
    "\n",
    "        flipped_ioi_dataset = IOIDataset(\n",
    "            prompt_type=self.prompt_type,\n",
    "            N=self.N,\n",
    "            tokenizer=self.tokenizer,\n",
    "            prompts=flipped_prompts,\n",
    "            prefixes=self.prefixes,\n",
    "            ioi_prompts_for_word_idxs=flipped_prompts if flip[0] == \"RAND\" else None,\n",
    "            prepend_bos=self.prepend_bos,\n",
    "            manual_word_idx=self.word_idx,\n",
    "        )\n",
    "        return flipped_ioi_dataset\n",
    "\n",
    "    def copy(self):\n",
    "        copy_ioi_dataset = IOIDataset(\n",
    "            prompt_type=self.prompt_type,\n",
    "            N=self.N,\n",
    "            tokenizer=self.tokenizer,\n",
    "            prompts=self.ioi_prompts.copy(),\n",
    "            prefixes=self.prefixes.copy()\n",
    "            if self.prefixes is not None\n",
    "            else self.prefixes,\n",
    "            ioi_prompts_for_word_idxs=self.ioi_prompts.copy(),\n",
    "        )\n",
    "        return copy_ioi_dataset\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        sliced_prompts = self.ioi_prompts[key]\n",
    "        sliced_dataset = IOIDataset(\n",
    "            prompt_type=self.prompt_type,\n",
    "            N=len(sliced_prompts),\n",
    "            tokenizer=self.tokenizer,\n",
    "            prompts=sliced_prompts,\n",
    "            prefixes=self.prefixes,\n",
    "            prepend_bos=self.prepend_bos,\n",
    "        )\n",
    "        return sliced_dataset\n",
    "\n",
    "    def __setitem__(self, key, value):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def __delitem__(self, key):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.N\n",
    "\n",
    "    def tokenized_prompts(self):\n",
    "        return self.toks\n",
    "\n",
    "\n",
    "# tests that the templates work as intended\n",
    "assert len(BABA_EARLY_IOS) == len(BABA_LATE_IOS), (len(BABA_EARLY_IOS), len(BABA_LATE_IOS))\n",
    "for i in range(len(BABA_EARLY_IOS)):\n",
    "    d1 = IOIDataset(N=1, prompt_type=BABA_EARLY_IOS[i:i+1])\n",
    "    d2 = IOIDataset(N=1, prompt_type=BABA_LATE_IOS[i:i+1])\n",
    "    for tok in [\"IO\", \"S\"]: # occur one earlier and one later\n",
    "        assert d1.word_idx[tok] + 1 == d2.word_idx[tok], (d1.word_idx[tok], d2.word_idx[tok])\n",
    "    for tok in [\"S2\"]:\n",
    "        assert d1.word_idx[tok] == d2.word_idx[tok], (d1.word_idx[tok], d2.word_idx[tok])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9938,
     "status": "ok",
     "timestamp": 1742788825378,
     "user": {
      "displayName": "Reilly H",
      "userId": "05616995266737589283"
     },
     "user_tz": -780
    },
    "id": "qtVXcqc7QJ2f",
    "outputId": "297db241-31da-4f49-cc49-cfbb82a86ee8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting git+https://github.com/neelnanda-io/TransformerLens.git\n",
      "  Cloning https://github.com/neelnanda-io/TransformerLens.git to /tmp/pip-req-build-zi4ily4b\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/neelnanda-io/TransformerLens.git /tmp/pip-req-build-zi4ily4b\n",
      "  Resolved https://github.com/neelnanda-io/TransformerLens.git to commit 47fe15666017d1b507bfebeefd877dbc428d8463\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (2.1.3)\n",
      "Requirement already satisfied: wandb>=0.13.5 in /csse/users/rha192/.local/lib/python3.10/site-packages (from transformer-lens==0.0.0) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.64.1 in /csse/users/rha192/.local/lib/python3.10/site-packages (from transformer-lens==0.0.0) (4.66.4)\n",
      "Requirement already satisfied: fancy-einsum>=0.0.3 in /csse/users/rha192/.local/lib/python3.10/site-packages (from transformer-lens==0.0.0) (0.0.3)\n",
      "Requirement already satisfied: rich>=12.6.0 in /csse/users/rha192/.local/lib/python3.10/site-packages (from transformer-lens==0.0.0) (12.6.0)\n",
      "Requirement already satisfied: jaxtyping>=0.2.11 in /csse/users/rha192/.local/lib/python3.10/site-packages (from transformer-lens==0.0.0) (0.2.36)\n",
      "Requirement already satisfied: transformers>=4.43 in /csse/users/rha192/.local/lib/python3.10/site-packages (from transformer-lens==0.0.0) (4.48.0)\n",
      "Requirement already satisfied: typeguard<5.0,>=4.2 in /csse/users/rha192/.local/lib/python3.10/site-packages (from transformer-lens==0.0.0) (4.4.1)\n",
      "Requirement already satisfied: sentencepiece in /csse/users/rha192/.local/lib/python3.10/site-packages (from transformer-lens==0.0.0) (0.2.0)\n",
      "Requirement already satisfied: torch>=2.2 in /csse/users/rha192/.local/lib/python3.10/site-packages (from transformer-lens==0.0.0) (2.6.0)\n",
      "Requirement already satisfied: accelerate>=0.23.0 in /csse/users/rha192/.local/lib/python3.10/site-packages (from transformer-lens==0.0.0) (1.2.1)\n",
      "Requirement already satisfied: datasets>=2.7.1 in /csse/users/rha192/.local/lib/python3.10/site-packages (from transformer-lens==0.0.0) (3.1.0)\n",
      "Requirement already satisfied: transformers-stream-generator<0.0.6,>=0.0.5 in /csse/users/rha192/.local/lib/python3.10/site-packages (from transformer-lens==0.0.0) (0.0.5)\n",
      "Requirement already satisfied: typing-extensions in /csse/users/rha192/.local/lib/python3.10/site-packages (from transformer-lens==0.0.0) (4.12.2)\n",
      "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (1.26.2)\n",
      "Requirement already satisfied: better-abc<0.0.4,>=0.0.3 in /csse/users/rha192/.local/lib/python3.10/site-packages (from transformer-lens==0.0.0) (0.0.3)\n",
      "Requirement already satisfied: beartype<0.15.0,>=0.14.1 in /csse/users/rha192/.local/lib/python3.10/site-packages (from transformer-lens==0.0.0) (0.14.1)\n",
      "Requirement already satisfied: einops>=0.6.0 in /csse/users/rha192/.local/lib/python3.10/site-packages (from transformer-lens==0.0.0) (0.8.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /csse/users/rha192/.local/lib/python3.10/site-packages (from accelerate>=0.23.0->transformer-lens==0.0.0) (0.26.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /csse/users/rha192/.local/lib/python3.10/site-packages (from accelerate>=0.23.0->transformer-lens==0.0.0) (0.5.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /csse/users/rha192/.local/lib/python3.10/site-packages (from accelerate>=0.23.0->transformer-lens==0.0.0) (24.1)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer-lens==0.0.0) (6.0.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer-lens==0.0.0) (5.9.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /csse/users/rha192/.local/lib/python3.10/site-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (0.3.6)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /csse/users/rha192/.local/lib/python3.10/site-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (16.1.0)\n",
      "Requirement already satisfied: filelock in /csse/users/rha192/.local/lib/python3.10/site-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (3.6.0)\n",
      "Requirement already satisfied: aiohttp in /csse/users/rha192/.local/lib/python3.10/site-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (3.9.5)\n",
      "Requirement already satisfied: fsspec[http]<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (2023.10.0)\n",
      "Requirement already satisfied: xxhash in /csse/users/rha192/.local/lib/python3.10/site-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (3.4.1)\n",
      "Requirement already satisfied: requests>=2.32.2 in /csse/users/rha192/.local/lib/python3.10/site-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (2.32.3)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /csse/users/rha192/.local/lib/python3.10/site-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (0.70.14)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->transformer-lens==0.0.0) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->transformer-lens==0.0.0) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->transformer-lens==0.0.0) (2023.3)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.6.0->transformer-lens==0.0.0) (2.17.2)\n",
      "Requirement already satisfied: commonmark<0.10.0,>=0.9.0 in /csse/users/rha192/.local/lib/python3.10/site-packages (from rich>=12.6.0->transformer-lens==0.0.0) (0.9.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in /csse/users/rha192/.local/lib/python3.10/site-packages (from torch>=2.2->transformer-lens==0.0.0) (1.13.1)\n",
      "Requirement already satisfied: jinja2 in /csse/users/rha192/.local/lib/python3.10/site-packages (from torch>=2.2->transformer-lens==0.0.0) (3.1.4)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /csse/users/rha192/.local/lib/python3.10/site-packages (from torch>=2.2->transformer-lens==0.0.0) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /csse/users/rha192/.local/lib/python3.10/site-packages (from torch>=2.2->transformer-lens==0.0.0) (3.2.0)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /csse/users/rha192/.local/lib/python3.10/site-packages (from torch>=2.2->transformer-lens==0.0.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /csse/users/rha192/.local/lib/python3.10/site-packages (from torch>=2.2->transformer-lens==0.0.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /csse/users/rha192/.local/lib/python3.10/site-packages (from torch>=2.2->transformer-lens==0.0.0) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /csse/users/rha192/.local/lib/python3.10/site-packages (from torch>=2.2->transformer-lens==0.0.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /csse/users/rha192/.local/lib/python3.10/site-packages (from torch>=2.2->transformer-lens==0.0.0) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /csse/users/rha192/.local/lib/python3.10/site-packages (from torch>=2.2->transformer-lens==0.0.0) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /csse/users/rha192/.local/lib/python3.10/site-packages (from torch>=2.2->transformer-lens==0.0.0) (2.21.5)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /csse/users/rha192/.local/lib/python3.10/site-packages (from torch>=2.2->transformer-lens==0.0.0) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /csse/users/rha192/.local/lib/python3.10/site-packages (from torch>=2.2->transformer-lens==0.0.0) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /csse/users/rha192/.local/lib/python3.10/site-packages (from torch>=2.2->transformer-lens==0.0.0) (11.2.1.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.2->transformer-lens==0.0.0) (3.2.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /csse/users/rha192/.local/lib/python3.10/site-packages (from torch>=2.2->transformer-lens==0.0.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /csse/users/rha192/.local/lib/python3.10/site-packages (from torch>=2.2->transformer-lens==0.0.0) (0.6.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=2.2->transformer-lens==0.0.0) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /csse/users/rha192/.local/lib/python3.10/site-packages (from transformers>=4.43->transformer-lens==0.0.0) (2024.5.15)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /csse/users/rha192/.local/lib/python3.10/site-packages (from transformers>=4.43->transformer-lens==0.0.0) (0.21.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (68.2.2)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/lib/python3/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (3.1.24)\n",
      "Requirement already satisfied: pydantic<3,>=2.6 in /csse/users/rha192/.local/lib/python3.10/site-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (2.9.2)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in /csse/users/rha192/.local/lib/python3.10/site-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (2.18.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /csse/users/rha192/.local/lib/python3.10/site-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (3.20.3)\n",
      "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (3.11.0)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /csse/users/rha192/.local/lib/python3.10/site-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (0.4.0)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (8.1.7)\n",
      "Requirement already satisfied: setproctitle in /usr/lib/python3/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (1.2.2)\n",
      "Requirement already satisfied: six>=1.4.0 in /usr/lib/python3/dist-packages (from docker-pycreds>=0.4.0->wandb>=0.13.5->transformer-lens==0.0.0) (1.16.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /csse/users/rha192/.local/lib/python3.10/site-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (1.9.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /csse/users/rha192/.local/lib/python3.10/site-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (6.0.5)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /csse/users/rha192/.local/lib/python3.10/site-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /csse/users/rha192/.local/lib/python3.10/site-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (4.0.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /csse/users/rha192/.local/lib/python3.10/site-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (1.4.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /csse/users/rha192/.local/lib/python3.10/site-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (23.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2.6->wandb>=0.13.5->transformer-lens==0.0.0) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /csse/users/rha192/.local/lib/python3.10/site-packages (from pydantic<3,>=2.6->wandb>=0.13.5->transformer-lens==0.0.0) (2.23.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /csse/users/rha192/.local/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=2.7.1->transformer-lens==0.0.0) (2024.6.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.7.1->transformer-lens==0.0.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /csse/users/rha192/.local/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=2.7.1->transformer-lens==0.0.0) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /csse/users/rha192/.local/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=2.7.1->transformer-lens==0.0.0) (2.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /csse/users/rha192/.local/lib/python3.10/site-packages (from jinja2->torch>=2.2->transformer-lens==0.0.0) (2.1.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/csse/users/rha192/.local/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /csse/users/rha192/.local/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7ff3f839c0a0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pip install git+https://github.com/neelnanda-io/TransformerLens.git\n",
    "from transformer_lens import HookedTransformer\n",
    "import torch\n",
    "torch.set_grad_enabled(False)  # turn automatic differentiation off to save mem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6611,
     "status": "ok",
     "timestamp": 1742788832001,
     "user": {
      "displayName": "Reilly H",
      "userId": "05616995266737589283"
     },
     "user_tz": -780
    },
    "id": "eRe6AqxIQMio",
    "outputId": "06f561e7-d88d-4e6c-fea8-816ea33e2a51"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n",
      "Loaded pretrained model distillgpt2 into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "teacher_str = \"gpt2-small\"\n",
    "student_str = \"distillgpt2\"\n",
    "\n",
    "teacher = HookedTransformer.from_pretrained(\n",
    "    teacher_str,\n",
    "    center_unembed=True,\n",
    "    center_writing_weights=True,\n",
    "    fold_ln=True,\n",
    "    refactor_factored_attn_matrices=True,\n",
    ")\n",
    "\n",
    "student = HookedTransformer.from_pretrained(\n",
    "    student_str,\n",
    "    center_unembed=True,\n",
    "    center_writing_weights=True,\n",
    "    fold_ln=True,\n",
    "    refactor_factored_attn_matrices=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 202,
     "status": "ok",
     "timestamp": 1742788832206,
     "user": {
      "displayName": "Reilly H",
      "userId": "05616995266737589283"
     },
     "user_tz": -780
    },
    "id": "wQFgMmBbOTEQ",
    "outputId": "7c4703c6-bd17-419f-eb14-bf38a3fea164"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are two of the prompts from the dataset: ['Then, Kimberly and Tiffany had a long argument, and afterwards Kimberly said to Tiffany', 'Then, Joshua and Allison had a lot of fun at the restaurant. Joshua gave a bone to Allison']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_40563/3899178729.py:742: UserWarning: Some groups have less than 5 prompts, they have lengths [4]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "N = 100\n",
    "ioi_dataset = IOIDataset(\n",
    "    prompt_type=\"mixed\",\n",
    "    N=N,\n",
    "    tokenizer=teacher.tokenizer,\n",
    "    prepend_bos=False,\n",
    ")\n",
    "\n",
    "print(f\"Here are two of the prompts from the dataset: {ioi_dataset.sentences[:2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 903,
     "status": "ok",
     "timestamp": 1742788833124,
     "user": {
      "displayName": "Reilly H",
      "userId": "05616995266737589283"
     },
     "user_tz": -780
    },
    "id": "KhfkM2HFRD7s",
    "outputId": "0cbca134-a698-4816-f8d5-2dbd13b47de5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_40563/3899178729.py:742: UserWarning: Some groups have less than 5 prompts, they have lengths [4]\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_40563/3899178729.py:485: UserWarning: S2 index has been computed as the same for S and S2\n",
      "  warnings.warn(\"S2 index has been computed as the same for S and S2\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are two of the prompts from the corrupted dataset: ['Then, Rachel and Brittany had a long argument, and afterwards Tyler said to Brittany', 'Then, Sarah and Stephanie had a lot of fun at the restaurant. Kevin gave a bone to Stephanie']\n"
     ]
    }
   ],
   "source": [
    "abc_dataset = (\n",
    "    ioi_dataset.gen_flipped_prompts((\"IO\", \"RAND\"))\n",
    "    .gen_flipped_prompts((\"S\", \"RAND\"))\n",
    "    .gen_flipped_prompts((\"S1\", \"RAND\"))\n",
    ")\n",
    "\n",
    "print(f\"Here are two of the prompts from the corrupted dataset: {abc_dataset.sentences[:2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1742788833134,
     "user": {
      "displayName": "Reilly H",
      "userId": "05616995266737589283"
     },
     "user_tz": -780
    },
    "id": "e4znb20eYL17"
   },
   "outputs": [],
   "source": [
    "prompts = ioi_dataset.ioi_prompts\n",
    "prompts_2 = abc_dataset.ioi_prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1742788833141,
     "user": {
      "displayName": "Reilly H",
      "userId": "05616995266737589283"
     },
     "user_tz": -780
    },
    "id": "1L_4CkbnZKMC",
    "outputId": "9d1217f4-cd3b-4c1d-8590-6967264df474"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'[PLACE]': 'restaurant',\n",
       "  '[OBJECT]': 'snack',\n",
       "  'text': 'Then, Kimberly and Tiffany had a long argument, and afterwards Kimberly said to Tiffany',\n",
       "  'IO': 'Tiffany',\n",
       "  'S': 'Kimberly',\n",
       "  'TEMPLATE_IDX': 9},\n",
       " {'[PLACE]': 'restaurant',\n",
       "  '[OBJECT]': 'bone',\n",
       "  'text': 'Then, Joshua and Allison had a lot of fun at the restaurant. Joshua gave a bone to Allison',\n",
       "  'IO': 'Allison',\n",
       "  'S': 'Joshua',\n",
       "  'TEMPLATE_IDX': 1},\n",
       " {'[PLACE]': 'garden',\n",
       "  '[OBJECT]': 'drink',\n",
       "  'text': 'Then, Jesse and Mark were thinking about going to the garden. Mark wanted to give a drink to Jesse',\n",
       "  'IO': 'Jesse',\n",
       "  'S': 'Mark',\n",
       "  'TEMPLATE_IDX': 12},\n",
       " {'[PLACE]': 'hospital',\n",
       "  '[OBJECT]': 'ring',\n",
       "  'text': 'After Jacob and Gregory went to the hospital, Jacob gave a ring to Gregory',\n",
       "  'IO': 'Gregory',\n",
       "  'S': 'Jacob',\n",
       "  'TEMPLATE_IDX': 6},\n",
       " {'[PLACE]': 'hospital',\n",
       "  '[OBJECT]': 'necklace',\n",
       "  'text': 'Then, Andrew and Courtney were working at the hospital. Andrew decided to give a necklace to Courtney',\n",
       "  'IO': 'Courtney',\n",
       "  'S': 'Andrew',\n",
       "  'TEMPLATE_IDX': 10},\n",
       " {'[PLACE]': 'station',\n",
       "  '[OBJECT]': 'ring',\n",
       "  'text': 'Then, Emily and Christina had a lot of fun at the station. Emily gave a ring to Christina',\n",
       "  'IO': 'Christina',\n",
       "  'S': 'Emily',\n",
       "  'TEMPLATE_IDX': 1},\n",
       " {'[PLACE]': 'restaurant',\n",
       "  '[OBJECT]': 'kiss',\n",
       "  'text': 'Then, Courtney and Kevin went to the restaurant. Kevin gave a kiss to Courtney',\n",
       "  'IO': 'Courtney',\n",
       "  'S': 'Kevin',\n",
       "  'TEMPLATE_IDX': 11},\n",
       " {'[PLACE]': 'school',\n",
       "  '[OBJECT]': 'bone',\n",
       "  'text': 'When Kyle and Lisa got a bone at the school, Kyle decided to give it to Lisa',\n",
       "  'IO': 'Lisa',\n",
       "  'S': 'Kyle',\n",
       "  'TEMPLATE_IDX': 13},\n",
       " {'[PLACE]': 'store',\n",
       "  '[OBJECT]': 'necklace',\n",
       "  'text': 'Then, Bradley and William were working at the store. William decided to give a necklace to Bradley',\n",
       "  'IO': 'Bradley',\n",
       "  'S': 'William',\n",
       "  'TEMPLATE_IDX': 5},\n",
       " {'[PLACE]': 'hospital',\n",
       "  '[OBJECT]': 'basketball',\n",
       "  'text': 'Then, Andrew and Jessica were thinking about going to the hospital. Andrew wanted to give a basketball to Jessica',\n",
       "  'IO': 'Jessica',\n",
       "  'S': 'Andrew',\n",
       "  'TEMPLATE_IDX': 7},\n",
       " {'[PLACE]': 'garden',\n",
       "  '[OBJECT]': 'snack',\n",
       "  'text': 'Then, Tyler and Adam went to the garden. Tyler gave a snack to Adam',\n",
       "  'IO': 'Adam',\n",
       "  'S': 'Tyler',\n",
       "  'TEMPLATE_IDX': 0},\n",
       " {'[PLACE]': 'restaurant',\n",
       "  '[OBJECT]': 'bone',\n",
       "  'text': 'When Bradley and Daniel got a bone at the restaurant, Bradley decided to give it to Daniel',\n",
       "  'IO': 'Daniel',\n",
       "  'S': 'Bradley',\n",
       "  'TEMPLATE_IDX': 13},\n",
       " {'[PLACE]': 'hospital',\n",
       "  '[OBJECT]': 'drink',\n",
       "  'text': 'Then, Paul and Stephen were working at the hospital. Paul decided to give a drink to Stephen',\n",
       "  'IO': 'Stephen',\n",
       "  'S': 'Paul',\n",
       "  'TEMPLATE_IDX': 10},\n",
       " {'[PLACE]': 'school',\n",
       "  '[OBJECT]': 'computer',\n",
       "  'text': 'Then, Dustin and Allison had a lot of fun at the school. Allison gave a computer to Dustin',\n",
       "  'IO': 'Dustin',\n",
       "  'S': 'Allison',\n",
       "  'TEMPLATE_IDX': 3},\n",
       " {'[PLACE]': 'station',\n",
       "  '[OBJECT]': 'snack',\n",
       "  'text': 'After Lindsey and Jose went to the station, Lindsey gave a snack to Jose',\n",
       "  'IO': 'Jose',\n",
       "  'S': 'Lindsey',\n",
       "  'TEMPLATE_IDX': 6},\n",
       " {'[PLACE]': 'office',\n",
       "  '[OBJECT]': 'ring',\n",
       "  'text': 'Then, Eric and Megan had a lot of fun at the office. Eric gave a ring to Megan',\n",
       "  'IO': 'Megan',\n",
       "  'S': 'Eric',\n",
       "  'TEMPLATE_IDX': 1},\n",
       " {'[PLACE]': 'school',\n",
       "  '[OBJECT]': 'ring',\n",
       "  'text': 'Then, Elizabeth and Paul had a long argument, and afterwards Elizabeth said to Paul',\n",
       "  'IO': 'Paul',\n",
       "  'S': 'Elizabeth',\n",
       "  'TEMPLATE_IDX': 9},\n",
       " {'[PLACE]': 'school',\n",
       "  '[OBJECT]': 'kiss',\n",
       "  'text': 'Then, Lisa and Shannon had a lot of fun at the school. Lisa gave a kiss to Shannon',\n",
       "  'IO': 'Shannon',\n",
       "  'S': 'Lisa',\n",
       "  'TEMPLATE_IDX': 1},\n",
       " {'[PLACE]': 'school',\n",
       "  '[OBJECT]': 'computer',\n",
       "  'text': 'Then, David and Amber went to the school. David gave a computer to Amber',\n",
       "  'IO': 'Amber',\n",
       "  'S': 'David',\n",
       "  'TEMPLATE_IDX': 0},\n",
       " {'[PLACE]': 'restaurant',\n",
       "  '[OBJECT]': 'snack',\n",
       "  'text': 'Then, Heather and Sean were working at the restaurant. Heather decided to give a snack to Sean',\n",
       "  'IO': 'Sean',\n",
       "  'S': 'Heather',\n",
       "  'TEMPLATE_IDX': 10},\n",
       " {'[PLACE]': 'garden',\n",
       "  '[OBJECT]': 'kiss',\n",
       "  'text': 'Then, Stephen and Jeremy had a lot of fun at the garden. Jeremy gave a kiss to Stephen',\n",
       "  'IO': 'Stephen',\n",
       "  'S': 'Jeremy',\n",
       "  'TEMPLATE_IDX': 3},\n",
       " {'[PLACE]': 'house',\n",
       "  '[OBJECT]': 'snack',\n",
       "  'text': 'Then, Richard and Emily were working at the house. Richard decided to give a snack to Emily',\n",
       "  'IO': 'Emily',\n",
       "  'S': 'Richard',\n",
       "  'TEMPLATE_IDX': 10},\n",
       " {'[PLACE]': 'garden',\n",
       "  '[OBJECT]': 'ring',\n",
       "  'text': 'When Joshua and Christine got a ring at the garden, Joshua decided to give it to Christine',\n",
       "  'IO': 'Christine',\n",
       "  'S': 'Joshua',\n",
       "  'TEMPLATE_IDX': 13},\n",
       " {'[PLACE]': 'school',\n",
       "  '[OBJECT]': 'basketball',\n",
       "  'text': 'After Brittany and Christine went to the school, Brittany gave a basketball to Christine',\n",
       "  'IO': 'Christine',\n",
       "  'S': 'Brittany',\n",
       "  'TEMPLATE_IDX': 6},\n",
       " {'[PLACE]': 'house',\n",
       "  '[OBJECT]': 'bone',\n",
       "  'text': 'Then, Sara and Charles had a lot of fun at the house. Charles gave a bone to Sara',\n",
       "  'IO': 'Sara',\n",
       "  'S': 'Charles',\n",
       "  'TEMPLATE_IDX': 3},\n",
       " {'[PLACE]': 'station',\n",
       "  '[OBJECT]': 'kiss',\n",
       "  'text': 'When Jacob and Megan got a kiss at the station, Megan decided to give it to Jacob',\n",
       "  'IO': 'Jacob',\n",
       "  'S': 'Megan',\n",
       "  'TEMPLATE_IDX': 4},\n",
       " {'[PLACE]': 'garden',\n",
       "  '[OBJECT]': 'basketball',\n",
       "  'text': 'Then, Dustin and Lindsey went to the garden. Dustin gave a basketball to Lindsey',\n",
       "  'IO': 'Lindsey',\n",
       "  'S': 'Dustin',\n",
       "  'TEMPLATE_IDX': 0},\n",
       " {'[PLACE]': 'school',\n",
       "  '[OBJECT]': 'drink',\n",
       "  'text': 'Then, Jeremy and Sean had a long argument, and afterwards Sean said to Jeremy',\n",
       "  'IO': 'Jeremy',\n",
       "  'S': 'Sean',\n",
       "  'TEMPLATE_IDX': 2},\n",
       " {'[PLACE]': 'house',\n",
       "  '[OBJECT]': 'computer',\n",
       "  'text': 'Then, Amy and Jonathan went to the house. Amy gave a computer to Jonathan',\n",
       "  'IO': 'Jonathan',\n",
       "  'S': 'Amy',\n",
       "  'TEMPLATE_IDX': 0},\n",
       " {'[PLACE]': 'station',\n",
       "  '[OBJECT]': 'bone',\n",
       "  'text': 'Then, Rebecca and Timothy were thinking about going to the station. Timothy wanted to give a bone to Rebecca',\n",
       "  'IO': 'Rebecca',\n",
       "  'S': 'Timothy',\n",
       "  'TEMPLATE_IDX': 12},\n",
       " {'[PLACE]': 'store',\n",
       "  '[OBJECT]': 'necklace',\n",
       "  'text': 'Then, Christina and Heather had a lot of fun at the store. Heather gave a necklace to Christina',\n",
       "  'IO': 'Christina',\n",
       "  'S': 'Heather',\n",
       "  'TEMPLATE_IDX': 3},\n",
       " {'[PLACE]': 'restaurant',\n",
       "  '[OBJECT]': 'ring',\n",
       "  'text': 'Then, Katherine and Joshua went to the restaurant. Katherine gave a ring to Joshua',\n",
       "  'IO': 'Joshua',\n",
       "  'S': 'Katherine',\n",
       "  'TEMPLATE_IDX': 0},\n",
       " {'[PLACE]': 'garden',\n",
       "  '[OBJECT]': 'basketball',\n",
       "  'text': 'After James and Brian went to the garden, Brian gave a basketball to James',\n",
       "  'IO': 'James',\n",
       "  'S': 'Brian',\n",
       "  'TEMPLATE_IDX': 8},\n",
       " {'[PLACE]': 'store',\n",
       "  '[OBJECT]': 'kiss',\n",
       "  'text': 'After Tyler and Ryan went to the store, Tyler gave a kiss to Ryan',\n",
       "  'IO': 'Ryan',\n",
       "  'S': 'Tyler',\n",
       "  'TEMPLATE_IDX': 6},\n",
       " {'[PLACE]': 'office',\n",
       "  '[OBJECT]': 'computer',\n",
       "  'text': 'After Katherine and Kristen went to the office, Katherine gave a computer to Kristen',\n",
       "  'IO': 'Kristen',\n",
       "  'S': 'Katherine',\n",
       "  'TEMPLATE_IDX': 6},\n",
       " {'[PLACE]': 'school',\n",
       "  '[OBJECT]': 'computer',\n",
       "  'text': 'Then, Jose and Vanessa had a lot of fun at the school. Vanessa gave a computer to Jose',\n",
       "  'IO': 'Jose',\n",
       "  'S': 'Vanessa',\n",
       "  'TEMPLATE_IDX': 3},\n",
       " {'[PLACE]': 'hospital',\n",
       "  '[OBJECT]': 'snack',\n",
       "  'text': 'After Jose and Brandon went to the hospital, Jose gave a snack to Brandon',\n",
       "  'IO': 'Brandon',\n",
       "  'S': 'Jose',\n",
       "  'TEMPLATE_IDX': 6},\n",
       " {'[PLACE]': 'station',\n",
       "  '[OBJECT]': 'kiss',\n",
       "  'text': 'Then, Allison and David were working at the station. David decided to give a kiss to Allison',\n",
       "  'IO': 'Allison',\n",
       "  'S': 'David',\n",
       "  'TEMPLATE_IDX': 5},\n",
       " {'[PLACE]': 'hospital',\n",
       "  '[OBJECT]': 'bone',\n",
       "  'text': 'Then, Heather and Sara had a lot of fun at the hospital. Heather gave a bone to Sara',\n",
       "  'IO': 'Sara',\n",
       "  'S': 'Heather',\n",
       "  'TEMPLATE_IDX': 1},\n",
       " {'[PLACE]': 'hospital',\n",
       "  '[OBJECT]': 'bone',\n",
       "  'text': 'Then, Daniel and Megan were working at the hospital. Megan decided to give a bone to Daniel',\n",
       "  'IO': 'Daniel',\n",
       "  'S': 'Megan',\n",
       "  'TEMPLATE_IDX': 5},\n",
       " {'[PLACE]': 'store',\n",
       "  '[OBJECT]': 'computer',\n",
       "  'text': 'Then, Shannon and Dustin were thinking about going to the store. Shannon wanted to give a computer to Dustin',\n",
       "  'IO': 'Dustin',\n",
       "  'S': 'Shannon',\n",
       "  'TEMPLATE_IDX': 7},\n",
       " {'[PLACE]': 'garden',\n",
       "  '[OBJECT]': 'kiss',\n",
       "  'text': 'Then, Jason and Joseph were working at the garden. Jason decided to give a kiss to Joseph',\n",
       "  'IO': 'Joseph',\n",
       "  'S': 'Jason',\n",
       "  'TEMPLATE_IDX': 10},\n",
       " {'[PLACE]': 'hospital',\n",
       "  '[OBJECT]': 'basketball',\n",
       "  'text': 'Then, Paul and Sarah went to the hospital. Sarah gave a basketball to Paul',\n",
       "  'IO': 'Paul',\n",
       "  'S': 'Sarah',\n",
       "  'TEMPLATE_IDX': 11},\n",
       " {'[PLACE]': 'hospital',\n",
       "  '[OBJECT]': 'snack',\n",
       "  'text': 'Then, Brittany and Anthony went to the hospital. Anthony gave a snack to Brittany',\n",
       "  'IO': 'Brittany',\n",
       "  'S': 'Anthony',\n",
       "  'TEMPLATE_IDX': 11},\n",
       " {'[PLACE]': 'house',\n",
       "  '[OBJECT]': 'computer',\n",
       "  'text': 'When Joshua and Robert got a computer at the house, Robert decided to give it to Joshua',\n",
       "  'IO': 'Joshua',\n",
       "  'S': 'Robert',\n",
       "  'TEMPLATE_IDX': 4},\n",
       " {'[PLACE]': 'restaurant',\n",
       "  '[OBJECT]': 'computer',\n",
       "  'text': 'Then, Amber and Michael went to the restaurant. Amber gave a computer to Michael',\n",
       "  'IO': 'Michael',\n",
       "  'S': 'Amber',\n",
       "  'TEMPLATE_IDX': 0},\n",
       " {'[PLACE]': 'house',\n",
       "  '[OBJECT]': 'ring',\n",
       "  'text': 'Then, Alicia and Aaron had a long argument, and afterwards Aaron said to Alicia',\n",
       "  'IO': 'Alicia',\n",
       "  'S': 'Aaron',\n",
       "  'TEMPLATE_IDX': 2},\n",
       " {'[PLACE]': 'store',\n",
       "  '[OBJECT]': 'necklace',\n",
       "  'text': 'Then, Katie and David had a lot of fun at the store. Katie gave a necklace to David',\n",
       "  'IO': 'David',\n",
       "  'S': 'Katie',\n",
       "  'TEMPLATE_IDX': 1},\n",
       " {'[PLACE]': 'restaurant',\n",
       "  '[OBJECT]': 'ring',\n",
       "  'text': 'Then, Justin and Paul had a long argument, and afterwards Justin said to Paul',\n",
       "  'IO': 'Paul',\n",
       "  'S': 'Justin',\n",
       "  'TEMPLATE_IDX': 9},\n",
       " {'[PLACE]': 'school',\n",
       "  '[OBJECT]': 'basketball',\n",
       "  'text': 'When Kimberly and Jennifer got a basketball at the school, Jennifer decided to give it to Kimberly',\n",
       "  'IO': 'Kimberly',\n",
       "  'S': 'Jennifer',\n",
       "  'TEMPLATE_IDX': 4},\n",
       " {'[PLACE]': 'house',\n",
       "  '[OBJECT]': 'bone',\n",
       "  'text': 'Then, Richard and Joseph were working at the house. Richard decided to give a bone to Joseph',\n",
       "  'IO': 'Joseph',\n",
       "  'S': 'Richard',\n",
       "  'TEMPLATE_IDX': 10},\n",
       " {'[PLACE]': 'store',\n",
       "  '[OBJECT]': 'bone',\n",
       "  'text': 'Then, William and Stephanie had a lot of fun at the store. Stephanie gave a bone to William',\n",
       "  'IO': 'William',\n",
       "  'S': 'Stephanie',\n",
       "  'TEMPLATE_IDX': 3},\n",
       " {'[PLACE]': 'school',\n",
       "  '[OBJECT]': 'computer',\n",
       "  'text': 'Then, Amber and Jeremy went to the school. Jeremy gave a computer to Amber',\n",
       "  'IO': 'Amber',\n",
       "  'S': 'Jeremy',\n",
       "  'TEMPLATE_IDX': 11},\n",
       " {'[PLACE]': 'store',\n",
       "  '[OBJECT]': 'snack',\n",
       "  'text': 'Then, Lindsay and Joseph had a long argument, and afterwards Joseph said to Lindsay',\n",
       "  'IO': 'Lindsay',\n",
       "  'S': 'Joseph',\n",
       "  'TEMPLATE_IDX': 2},\n",
       " {'[PLACE]': 'hospital',\n",
       "  '[OBJECT]': 'basketball',\n",
       "  'text': 'Then, Nicholas and Rebecca had a lot of fun at the hospital. Rebecca gave a basketball to Nicholas',\n",
       "  'IO': 'Nicholas',\n",
       "  'S': 'Rebecca',\n",
       "  'TEMPLATE_IDX': 3},\n",
       " {'[PLACE]': 'house',\n",
       "  '[OBJECT]': 'necklace',\n",
       "  'text': 'Then, Matthew and Kristen had a lot of fun at the house. Kristen gave a necklace to Matthew',\n",
       "  'IO': 'Matthew',\n",
       "  'S': 'Kristen',\n",
       "  'TEMPLATE_IDX': 3},\n",
       " {'[PLACE]': 'office',\n",
       "  '[OBJECT]': 'drink',\n",
       "  'text': 'When Daniel and Samuel got a drink at the office, Samuel decided to give it to Daniel',\n",
       "  'IO': 'Daniel',\n",
       "  'S': 'Samuel',\n",
       "  'TEMPLATE_IDX': 4},\n",
       " {'[PLACE]': 'garden',\n",
       "  '[OBJECT]': 'computer',\n",
       "  'text': 'Then, Amber and Sara were working at the garden. Amber decided to give a computer to Sara',\n",
       "  'IO': 'Sara',\n",
       "  'S': 'Amber',\n",
       "  'TEMPLATE_IDX': 10},\n",
       " {'[PLACE]': 'garden',\n",
       "  '[OBJECT]': 'drink',\n",
       "  'text': 'Then, Katherine and Kevin had a long argument, and afterwards Kevin said to Katherine',\n",
       "  'IO': 'Katherine',\n",
       "  'S': 'Kevin',\n",
       "  'TEMPLATE_IDX': 2},\n",
       " {'[PLACE]': 'garden',\n",
       "  '[OBJECT]': 'drink',\n",
       "  'text': 'Then, Christine and Laura were working at the garden. Laura decided to give a drink to Christine',\n",
       "  'IO': 'Christine',\n",
       "  'S': 'Laura',\n",
       "  'TEMPLATE_IDX': 5},\n",
       " {'[PLACE]': 'house',\n",
       "  '[OBJECT]': 'ring',\n",
       "  'text': 'Then, Melissa and Nicole had a long argument, and afterwards Melissa said to Nicole',\n",
       "  'IO': 'Nicole',\n",
       "  'S': 'Melissa',\n",
       "  'TEMPLATE_IDX': 9},\n",
       " {'[PLACE]': 'school',\n",
       "  '[OBJECT]': 'necklace',\n",
       "  'text': 'After Sara and Jesse went to the school, Jesse gave a necklace to Sara',\n",
       "  'IO': 'Sara',\n",
       "  'S': 'Jesse',\n",
       "  'TEMPLATE_IDX': 8},\n",
       " {'[PLACE]': 'office',\n",
       "  '[OBJECT]': 'kiss',\n",
       "  'text': 'After Jose and Daniel went to the office, Jose gave a kiss to Daniel',\n",
       "  'IO': 'Daniel',\n",
       "  'S': 'Jose',\n",
       "  'TEMPLATE_IDX': 6},\n",
       " {'[PLACE]': 'house',\n",
       "  '[OBJECT]': 'necklace',\n",
       "  'text': 'Then, Kyle and Jamie went to the house. Jamie gave a necklace to Kyle',\n",
       "  'IO': 'Kyle',\n",
       "  'S': 'Jamie',\n",
       "  'TEMPLATE_IDX': 11},\n",
       " {'[PLACE]': 'restaurant',\n",
       "  '[OBJECT]': 'basketball',\n",
       "  'text': 'After Christina and Lindsay went to the restaurant, Christina gave a basketball to Lindsay',\n",
       "  'IO': 'Lindsay',\n",
       "  'S': 'Christina',\n",
       "  'TEMPLATE_IDX': 6},\n",
       " {'[PLACE]': 'restaurant',\n",
       "  '[OBJECT]': 'computer',\n",
       "  'text': 'After Amy and Jose went to the restaurant, Amy gave a computer to Jose',\n",
       "  'IO': 'Jose',\n",
       "  'S': 'Amy',\n",
       "  'TEMPLATE_IDX': 6},\n",
       " {'[PLACE]': 'hospital',\n",
       "  '[OBJECT]': 'basketball',\n",
       "  'text': 'After Michael and Paul went to the hospital, Michael gave a basketball to Paul',\n",
       "  'IO': 'Paul',\n",
       "  'S': 'Michael',\n",
       "  'TEMPLATE_IDX': 6},\n",
       " {'[PLACE]': 'office',\n",
       "  '[OBJECT]': 'snack',\n",
       "  'text': 'After Erica and Katherine went to the office, Erica gave a snack to Katherine',\n",
       "  'IO': 'Katherine',\n",
       "  'S': 'Erica',\n",
       "  'TEMPLATE_IDX': 6},\n",
       " {'[PLACE]': 'station',\n",
       "  '[OBJECT]': 'bone',\n",
       "  'text': 'Then, Alexander and Aaron were thinking about going to the station. Alexander wanted to give a bone to Aaron',\n",
       "  'IO': 'Aaron',\n",
       "  'S': 'Alexander',\n",
       "  'TEMPLATE_IDX': 7},\n",
       " {'[PLACE]': 'office',\n",
       "  '[OBJECT]': 'kiss',\n",
       "  'text': 'Then, Timothy and James were working at the office. Timothy decided to give a kiss to James',\n",
       "  'IO': 'James',\n",
       "  'S': 'Timothy',\n",
       "  'TEMPLATE_IDX': 10},\n",
       " {'[PLACE]': 'hospital',\n",
       "  '[OBJECT]': 'basketball',\n",
       "  'text': 'When Adam and Allison got a basketball at the hospital, Adam decided to give it to Allison',\n",
       "  'IO': 'Allison',\n",
       "  'S': 'Adam',\n",
       "  'TEMPLATE_IDX': 13},\n",
       " {'[PLACE]': 'store',\n",
       "  '[OBJECT]': 'basketball',\n",
       "  'text': 'Then, Nicholas and Justin were thinking about going to the store. Justin wanted to give a basketball to Nicholas',\n",
       "  'IO': 'Nicholas',\n",
       "  'S': 'Justin',\n",
       "  'TEMPLATE_IDX': 12},\n",
       " {'[PLACE]': 'station',\n",
       "  '[OBJECT]': 'drink',\n",
       "  'text': 'Then, Samuel and Mary were thinking about going to the station. Samuel wanted to give a drink to Mary',\n",
       "  'IO': 'Mary',\n",
       "  'S': 'Samuel',\n",
       "  'TEMPLATE_IDX': 7},\n",
       " {'[PLACE]': 'house',\n",
       "  '[OBJECT]': 'snack',\n",
       "  'text': 'Then, Nicole and Scott were working at the house. Nicole decided to give a snack to Scott',\n",
       "  'IO': 'Scott',\n",
       "  'S': 'Nicole',\n",
       "  'TEMPLATE_IDX': 10},\n",
       " {'[PLACE]': 'store',\n",
       "  '[OBJECT]': 'kiss',\n",
       "  'text': 'After Justin and Megan went to the store, Justin gave a kiss to Megan',\n",
       "  'IO': 'Megan',\n",
       "  'S': 'Justin',\n",
       "  'TEMPLATE_IDX': 6},\n",
       " {'[PLACE]': 'station',\n",
       "  '[OBJECT]': 'ring',\n",
       "  'text': 'Then, Mark and Eric were thinking about going to the station. Eric wanted to give a ring to Mark',\n",
       "  'IO': 'Mark',\n",
       "  'S': 'Eric',\n",
       "  'TEMPLATE_IDX': 12},\n",
       " {'[PLACE]': 'restaurant',\n",
       "  '[OBJECT]': 'snack',\n",
       "  'text': 'After Megan and Ryan went to the restaurant, Ryan gave a snack to Megan',\n",
       "  'IO': 'Megan',\n",
       "  'S': 'Ryan',\n",
       "  'TEMPLATE_IDX': 8},\n",
       " {'[PLACE]': 'office',\n",
       "  '[OBJECT]': 'snack',\n",
       "  'text': 'Then, Angela and Nathan were working at the office. Angela decided to give a snack to Nathan',\n",
       "  'IO': 'Nathan',\n",
       "  'S': 'Angela',\n",
       "  'TEMPLATE_IDX': 10},\n",
       " {'[PLACE]': 'station',\n",
       "  '[OBJECT]': 'bone',\n",
       "  'text': 'Then, Jamie and Courtney had a long argument, and afterwards Jamie said to Courtney',\n",
       "  'IO': 'Courtney',\n",
       "  'S': 'Jamie',\n",
       "  'TEMPLATE_IDX': 9},\n",
       " {'[PLACE]': 'school',\n",
       "  '[OBJECT]': 'computer',\n",
       "  'text': 'Then, Stephen and Charles went to the school. Charles gave a computer to Stephen',\n",
       "  'IO': 'Stephen',\n",
       "  'S': 'Charles',\n",
       "  'TEMPLATE_IDX': 11},\n",
       " {'[PLACE]': 'school',\n",
       "  '[OBJECT]': 'computer',\n",
       "  'text': 'Then, Samantha and Sean were thinking about going to the school. Sean wanted to give a computer to Samantha',\n",
       "  'IO': 'Samantha',\n",
       "  'S': 'Sean',\n",
       "  'TEMPLATE_IDX': 12},\n",
       " {'[PLACE]': 'school',\n",
       "  '[OBJECT]': 'computer',\n",
       "  'text': 'Then, Vanessa and David were thinking about going to the school. Vanessa wanted to give a computer to David',\n",
       "  'IO': 'David',\n",
       "  'S': 'Vanessa',\n",
       "  'TEMPLATE_IDX': 7},\n",
       " {'[PLACE]': 'restaurant',\n",
       "  '[OBJECT]': 'bone',\n",
       "  'text': 'Then, Laura and Dustin were working at the restaurant. Dustin decided to give a bone to Laura',\n",
       "  'IO': 'Laura',\n",
       "  'S': 'Dustin',\n",
       "  'TEMPLATE_IDX': 5},\n",
       " {'[PLACE]': 'school',\n",
       "  '[OBJECT]': 'kiss',\n",
       "  'text': 'Then, Crystal and Katie had a lot of fun at the school. Katie gave a kiss to Crystal',\n",
       "  'IO': 'Crystal',\n",
       "  'S': 'Katie',\n",
       "  'TEMPLATE_IDX': 3},\n",
       " {'[PLACE]': 'station',\n",
       "  '[OBJECT]': 'drink',\n",
       "  'text': 'After Amber and Jeremy went to the station, Amber gave a drink to Jeremy',\n",
       "  'IO': 'Jeremy',\n",
       "  'S': 'Amber',\n",
       "  'TEMPLATE_IDX': 6},\n",
       " {'[PLACE]': 'store',\n",
       "  '[OBJECT]': 'drink',\n",
       "  'text': 'Then, Benjamin and Anthony went to the store. Benjamin gave a drink to Anthony',\n",
       "  'IO': 'Anthony',\n",
       "  'S': 'Benjamin',\n",
       "  'TEMPLATE_IDX': 0},\n",
       " {'[PLACE]': 'house',\n",
       "  '[OBJECT]': 'drink',\n",
       "  'text': 'Then, Richard and Michael were thinking about going to the house. Richard wanted to give a drink to Michael',\n",
       "  'IO': 'Michael',\n",
       "  'S': 'Richard',\n",
       "  'TEMPLATE_IDX': 7},\n",
       " {'[PLACE]': 'school',\n",
       "  '[OBJECT]': 'snack',\n",
       "  'text': 'After Cody and Alicia went to the school, Alicia gave a snack to Cody',\n",
       "  'IO': 'Cody',\n",
       "  'S': 'Alicia',\n",
       "  'TEMPLATE_IDX': 8},\n",
       " {'[PLACE]': 'store',\n",
       "  '[OBJECT]': 'drink',\n",
       "  'text': 'Then, Steven and Emily had a lot of fun at the store. Emily gave a drink to Steven',\n",
       "  'IO': 'Steven',\n",
       "  'S': 'Emily',\n",
       "  'TEMPLATE_IDX': 3},\n",
       " {'[PLACE]': 'restaurant',\n",
       "  '[OBJECT]': 'snack',\n",
       "  'text': 'Then, Jose and Alexander were working at the restaurant. Alexander decided to give a snack to Jose',\n",
       "  'IO': 'Jose',\n",
       "  'S': 'Alexander',\n",
       "  'TEMPLATE_IDX': 5},\n",
       " {'[PLACE]': 'house',\n",
       "  '[OBJECT]': 'ring',\n",
       "  'text': 'Then, Travis and Sara had a long argument, and afterwards Sara said to Travis',\n",
       "  'IO': 'Travis',\n",
       "  'S': 'Sara',\n",
       "  'TEMPLATE_IDX': 2},\n",
       " {'[PLACE]': 'station',\n",
       "  '[OBJECT]': 'bone',\n",
       "  'text': 'Then, Mark and Bryan had a lot of fun at the station. Mark gave a bone to Bryan',\n",
       "  'IO': 'Bryan',\n",
       "  'S': 'Mark',\n",
       "  'TEMPLATE_IDX': 1},\n",
       " {'[PLACE]': 'school',\n",
       "  '[OBJECT]': 'snack',\n",
       "  'text': 'Then, Amy and Kevin went to the school. Amy gave a snack to Kevin',\n",
       "  'IO': 'Kevin',\n",
       "  'S': 'Amy',\n",
       "  'TEMPLATE_IDX': 0},\n",
       " {'[PLACE]': 'hospital',\n",
       "  '[OBJECT]': 'drink',\n",
       "  'text': 'Then, Brittany and Bradley were working at the hospital. Bradley decided to give a drink to Brittany',\n",
       "  'IO': 'Brittany',\n",
       "  'S': 'Bradley',\n",
       "  'TEMPLATE_IDX': 5},\n",
       " {'[PLACE]': 'store',\n",
       "  '[OBJECT]': 'necklace',\n",
       "  'text': 'When James and Stephen got a necklace at the store, Stephen decided to give it to James',\n",
       "  'IO': 'James',\n",
       "  'S': 'Stephen',\n",
       "  'TEMPLATE_IDX': 4},\n",
       " {'[PLACE]': 'school',\n",
       "  '[OBJECT]': 'basketball',\n",
       "  'text': 'Then, Jennifer and Allison had a lot of fun at the school. Allison gave a basketball to Jennifer',\n",
       "  'IO': 'Jennifer',\n",
       "  'S': 'Allison',\n",
       "  'TEMPLATE_IDX': 3},\n",
       " {'[PLACE]': 'school',\n",
       "  '[OBJECT]': 'bone',\n",
       "  'text': 'When Travis and Jessica got a bone at the school, Travis decided to give it to Jessica',\n",
       "  'IO': 'Jessica',\n",
       "  'S': 'Travis',\n",
       "  'TEMPLATE_IDX': 13},\n",
       " {'[PLACE]': 'school',\n",
       "  '[OBJECT]': 'snack',\n",
       "  'text': 'Then, Andrew and Jose were thinking about going to the school. Andrew wanted to give a snack to Jose',\n",
       "  'IO': 'Jose',\n",
       "  'S': 'Andrew',\n",
       "  'TEMPLATE_IDX': 7},\n",
       " {'[PLACE]': 'restaurant',\n",
       "  '[OBJECT]': 'kiss',\n",
       "  'text': 'Then, Melissa and Samuel went to the restaurant. Samuel gave a kiss to Melissa',\n",
       "  'IO': 'Melissa',\n",
       "  'S': 'Samuel',\n",
       "  'TEMPLATE_IDX': 11},\n",
       " {'[PLACE]': 'store',\n",
       "  '[OBJECT]': 'computer',\n",
       "  'text': 'Then, William and Rachel were thinking about going to the store. Rachel wanted to give a computer to William',\n",
       "  'IO': 'William',\n",
       "  'S': 'Rachel',\n",
       "  'TEMPLATE_IDX': 12}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 0,
     "status": "ok",
     "timestamp": 1742788833142,
     "user": {
      "displayName": "Reilly H",
      "userId": "05616995266737589283"
     },
     "user_tz": -780
    },
    "id": "KhSVw1CER8MU"
   },
   "outputs": [],
   "source": [
    "prompts_text=[prompt['text'] for prompt in prompts]\n",
    "prompts_text_2=[prompt['text'] for prompt in prompts_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1742788833152,
     "user": {
      "displayName": "Reilly H",
      "userId": "05616995266737589283"
     },
     "user_tz": -780
    },
    "id": "e66q_5_JSC_H",
    "outputId": "97d98840-b483-4360-a983-11b3a66535aa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Then, Kimberly and Tiffany had a long argument, and afterwards Kimberly said to Tiffany',\n",
       " 'Then, Joshua and Allison had a lot of fun at the restaurant. Joshua gave a bone to Allison',\n",
       " 'Then, Jesse and Mark were thinking about going to the garden. Mark wanted to give a drink to Jesse',\n",
       " 'After Jacob and Gregory went to the hospital, Jacob gave a ring to Gregory',\n",
       " 'Then, Andrew and Courtney were working at the hospital. Andrew decided to give a necklace to Courtney']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts_text[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 161,
     "status": "ok",
     "timestamp": 1742788833315,
     "user": {
      "displayName": "Reilly H",
      "userId": "05616995266737589283"
     },
     "user_tz": -780
    },
    "id": "1PFPTrWySDSG"
   },
   "outputs": [],
   "source": [
    "tokens_t = teacher.to_tokens(prompts_text, prepend_bos=True)\n",
    "tokens_s = student.to_tokens(prompts_text, prepend_bos=True)\n",
    "# tokens = tokens.cuda() # Move the tokens to the GPU\n",
    "\n",
    "original_logits_t, local_cache_t = teacher.run_with_cache(tokens_t)\n",
    "original_logits_s, local_cache_s = student.run_with_cache(tokens_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MbgpOhbESkwV"
   },
   "source": [
    "# Node Influence Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1742788833332,
     "user": {
      "displayName": "Reilly H",
      "userId": "05616995266737589283"
     },
     "user_tz": -780
    },
    "id": "wczdkc8_Shjv",
    "outputId": "38e1ec81-048a-4e9c-d9d8-b45f323daa93"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7ff3f8382f50>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import einops\n",
    "from fancy_einsum import einsum\n",
    "import tqdm.notebook as tqdm\n",
    "import random\n",
    "from pathlib import Path\n",
    "# import plotly.express as px\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from jaxtyping import Float, Int\n",
    "from typing import List, Union, Optional\n",
    "from functools import partial\n",
    "import copy\n",
    "\n",
    "import itertools\n",
    "from transformers import AutoModelForCausalLM, AutoConfig, AutoTokenizer\n",
    "import dataclasses\n",
    "import datasets\n",
    "from IPython.display import HTML\n",
    "\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "\n",
    "import transformer_lens\n",
    "import transformer_lens.utils as utils\n",
    "from transformer_lens.hook_points import (\n",
    "    HookedRootModule,\n",
    "    HookPoint,\n",
    ")\n",
    "from transformer_lens import HookedTransformer, HookedTransformerConfig, FactoredMatrix, ActivationCache\n",
    "\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "class Dataset:\n",
    "    def __init__(self, prompts, tokenizer, prepend_bos=False):\n",
    "        self.prompts = prompts\n",
    "        self.tokenizer = tokenizer\n",
    "        self.N = len(prompts)\n",
    "        self.prepend_bos = prepend_bos\n",
    "\n",
    "        texts = [\n",
    "            (self.tokenizer.bos_token if self.prepend_bos else \"\") + prompt[\"text\"]\n",
    "            for prompt in self.prompts\n",
    "        ]\n",
    "\n",
    "        # padding dynamically to longest sequence\n",
    "        tokenized_batch = self.tokenizer(texts, padding=True, return_tensors=\"pt\")\n",
    "        self.toks = tokenized_batch.input_ids\n",
    "        \n",
    "        self.max_len = self.toks.shape[1]\n",
    "\n",
    "        all_ids = [prompt[\"TEMPLATE_IDX\"] for prompt in self.prompts]\n",
    "        all_ids_ar = np.array(all_ids)\n",
    "        self.groups = [np.where(all_ids_ar == id)[0] for id in set(all_ids)]\n",
    "\n",
    "        self.io_tokenIDs = [self.tokenizer.encode(\" \" + prompt[\"IO\"])[0] for prompt in self.prompts]\n",
    "        self.s_tokenIDs = [self.tokenizer.encode(\" \" + prompt[\"S\"])[0] for prompt in self.prompts]\n",
    "\n",
    "        self.corr_tokenIDs = [self.tokenizer.encode(prompt[\"IO\"])[0] for prompt in self.prompts]\n",
    "        self.incorr_tokenIDs = [self.tokenizer.encode(prompt[\"S\"])[0] for prompt in self.prompts]\n",
    "\n",
    "        self.word_idx = {}\n",
    "\n",
    "        io_indices = []\n",
    "        s_indices = []\n",
    "        end_indices = []\n",
    "\n",
    "\n",
    "        for i in range(self.N):\n",
    "            input_ids = self.toks[i]\n",
    "\n",
    "            matches_io = (input_ids == self.io_tokenIDs[i]).nonzero(as_tuple=True)\n",
    "            if len(matches_io[0]) > 0:\n",
    "                io_idx = matches_io[0][0].item()\n",
    "            else:\n",
    "                io_idx = -1\n",
    "            io_indices.append(io_idx)\n",
    "\n",
    "            matches_s = (input_ids == self.s_tokenIDs[i]).nonzero(as_tuple=True)\n",
    "            if len(matches_s[0]) > 0:\n",
    "                s_idx = matches_s[0][0].item()\n",
    "            else:\n",
    "                s_idx = -1\n",
    "            s_indices.append(s_idx)\n",
    "\n",
    "            input_text = (self.tokenizer.bos_token if self.prepend_bos else \"\") + self.prompts[i][\"text\"]\n",
    "            unpadded_input_ids = self.tokenizer(input_text, padding=False).input_ids\n",
    "            true_seq_len = len(unpadded_input_ids)\n",
    "\n",
    "            end_idx = true_seq_len - 1\n",
    "            if self.prepend_bos:\n",
    "                end_idx += 1\n",
    "\n",
    "            end_indices.append(end_idx)\n",
    "\n",
    "        self.word_idx[\"IO\"] = torch.tensor(io_indices, dtype=torch.long)\n",
    "        self.word_idx[\"S\"] = torch.tensor(s_indices, dtype=torch.long)\n",
    "        self.word_idx[\"end\"] = torch.tensor(end_indices, dtype=torch.long)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.N\n",
    "\n",
    "    def tokenized_prompts(self):\n",
    "        return self.toks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 188,
     "status": "ok",
     "timestamp": 1742788833563,
     "user": {
      "displayName": "Reilly H",
      "userId": "05616995266737589283"
     },
     "user_tz": -780
    },
    "id": "B1JM070GS4qz"
   },
   "outputs": [],
   "source": [
    "dataset = Dataset(prompts, teacher.tokenizer)\n",
    "dataset_2 = Dataset(prompts_2, teacher.tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1742788833588,
     "user": {
      "displayName": "Reilly H",
      "userId": "05616995266737589283"
     },
     "user_tz": -780
    },
    "id": "aWWiznT2hfeh",
    "outputId": "65251d09-811d-4854-e70e-8b2ddc136f18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'[PLACE]': 'restaurant', '[OBJECT]': 'snack', 'text': 'Then, Kimberly and Tiffany had a long argument, and afterwards Kimberly said to Tiffany', 'IO': 'Tiffany', 'S': 'Kimberly', 'TEMPLATE_IDX': 9}, {'[PLACE]': 'restaurant', '[OBJECT]': 'bone', 'text': 'Then, Joshua and Allison had a lot of fun at the restaurant. Joshua gave a bone to Allison', 'IO': 'Allison', 'S': 'Joshua', 'TEMPLATE_IDX': 1}, {'[PLACE]': 'garden', '[OBJECT]': 'drink', 'text': 'Then, Jesse and Mark were thinking about going to the garden. Mark wanted to give a drink to Jesse', 'IO': 'Jesse', 'S': 'Mark', 'TEMPLATE_IDX': 12}, {'[PLACE]': 'hospital', '[OBJECT]': 'ring', 'text': 'After Jacob and Gregory went to the hospital, Jacob gave a ring to Gregory', 'IO': 'Gregory', 'S': 'Jacob', 'TEMPLATE_IDX': 6}, {'[PLACE]': 'hospital', '[OBJECT]': 'necklace', 'text': 'Then, Andrew and Courtney were working at the hospital. Andrew decided to give a necklace to Courtney', 'IO': 'Courtney', 'S': 'Andrew', 'TEMPLATE_IDX': 10}, {'[PLACE]': 'station', '[OBJECT]': 'ring', 'text': 'Then, Emily and Christina had a lot of fun at the station. Emily gave a ring to Christina', 'IO': 'Christina', 'S': 'Emily', 'TEMPLATE_IDX': 1}, {'[PLACE]': 'restaurant', '[OBJECT]': 'kiss', 'text': 'Then, Courtney and Kevin went to the restaurant. Kevin gave a kiss to Courtney', 'IO': 'Courtney', 'S': 'Kevin', 'TEMPLATE_IDX': 11}, {'[PLACE]': 'school', '[OBJECT]': 'bone', 'text': 'When Kyle and Lisa got a bone at the school, Kyle decided to give it to Lisa', 'IO': 'Lisa', 'S': 'Kyle', 'TEMPLATE_IDX': 13}, {'[PLACE]': 'store', '[OBJECT]': 'necklace', 'text': 'Then, Bradley and William were working at the store. William decided to give a necklace to Bradley', 'IO': 'Bradley', 'S': 'William', 'TEMPLATE_IDX': 5}, {'[PLACE]': 'hospital', '[OBJECT]': 'basketball', 'text': 'Then, Andrew and Jessica were thinking about going to the hospital. Andrew wanted to give a basketball to Jessica', 'IO': 'Jessica', 'S': 'Andrew', 'TEMPLATE_IDX': 7}, {'[PLACE]': 'garden', '[OBJECT]': 'snack', 'text': 'Then, Tyler and Adam went to the garden. Tyler gave a snack to Adam', 'IO': 'Adam', 'S': 'Tyler', 'TEMPLATE_IDX': 0}, {'[PLACE]': 'restaurant', '[OBJECT]': 'bone', 'text': 'When Bradley and Daniel got a bone at the restaurant, Bradley decided to give it to Daniel', 'IO': 'Daniel', 'S': 'Bradley', 'TEMPLATE_IDX': 13}, {'[PLACE]': 'hospital', '[OBJECT]': 'drink', 'text': 'Then, Paul and Stephen were working at the hospital. Paul decided to give a drink to Stephen', 'IO': 'Stephen', 'S': 'Paul', 'TEMPLATE_IDX': 10}, {'[PLACE]': 'school', '[OBJECT]': 'computer', 'text': 'Then, Dustin and Allison had a lot of fun at the school. Allison gave a computer to Dustin', 'IO': 'Dustin', 'S': 'Allison', 'TEMPLATE_IDX': 3}, {'[PLACE]': 'station', '[OBJECT]': 'snack', 'text': 'After Lindsey and Jose went to the station, Lindsey gave a snack to Jose', 'IO': 'Jose', 'S': 'Lindsey', 'TEMPLATE_IDX': 6}, {'[PLACE]': 'office', '[OBJECT]': 'ring', 'text': 'Then, Eric and Megan had a lot of fun at the office. Eric gave a ring to Megan', 'IO': 'Megan', 'S': 'Eric', 'TEMPLATE_IDX': 1}, {'[PLACE]': 'school', '[OBJECT]': 'ring', 'text': 'Then, Elizabeth and Paul had a long argument, and afterwards Elizabeth said to Paul', 'IO': 'Paul', 'S': 'Elizabeth', 'TEMPLATE_IDX': 9}, {'[PLACE]': 'school', '[OBJECT]': 'kiss', 'text': 'Then, Lisa and Shannon had a lot of fun at the school. Lisa gave a kiss to Shannon', 'IO': 'Shannon', 'S': 'Lisa', 'TEMPLATE_IDX': 1}, {'[PLACE]': 'school', '[OBJECT]': 'computer', 'text': 'Then, David and Amber went to the school. David gave a computer to Amber', 'IO': 'Amber', 'S': 'David', 'TEMPLATE_IDX': 0}, {'[PLACE]': 'restaurant', '[OBJECT]': 'snack', 'text': 'Then, Heather and Sean were working at the restaurant. Heather decided to give a snack to Sean', 'IO': 'Sean', 'S': 'Heather', 'TEMPLATE_IDX': 10}, {'[PLACE]': 'garden', '[OBJECT]': 'kiss', 'text': 'Then, Stephen and Jeremy had a lot of fun at the garden. Jeremy gave a kiss to Stephen', 'IO': 'Stephen', 'S': 'Jeremy', 'TEMPLATE_IDX': 3}, {'[PLACE]': 'house', '[OBJECT]': 'snack', 'text': 'Then, Richard and Emily were working at the house. Richard decided to give a snack to Emily', 'IO': 'Emily', 'S': 'Richard', 'TEMPLATE_IDX': 10}, {'[PLACE]': 'garden', '[OBJECT]': 'ring', 'text': 'When Joshua and Christine got a ring at the garden, Joshua decided to give it to Christine', 'IO': 'Christine', 'S': 'Joshua', 'TEMPLATE_IDX': 13}, {'[PLACE]': 'school', '[OBJECT]': 'basketball', 'text': 'After Brittany and Christine went to the school, Brittany gave a basketball to Christine', 'IO': 'Christine', 'S': 'Brittany', 'TEMPLATE_IDX': 6}, {'[PLACE]': 'house', '[OBJECT]': 'bone', 'text': 'Then, Sara and Charles had a lot of fun at the house. Charles gave a bone to Sara', 'IO': 'Sara', 'S': 'Charles', 'TEMPLATE_IDX': 3}, {'[PLACE]': 'station', '[OBJECT]': 'kiss', 'text': 'When Jacob and Megan got a kiss at the station, Megan decided to give it to Jacob', 'IO': 'Jacob', 'S': 'Megan', 'TEMPLATE_IDX': 4}, {'[PLACE]': 'garden', '[OBJECT]': 'basketball', 'text': 'Then, Dustin and Lindsey went to the garden. Dustin gave a basketball to Lindsey', 'IO': 'Lindsey', 'S': 'Dustin', 'TEMPLATE_IDX': 0}, {'[PLACE]': 'school', '[OBJECT]': 'drink', 'text': 'Then, Jeremy and Sean had a long argument, and afterwards Sean said to Jeremy', 'IO': 'Jeremy', 'S': 'Sean', 'TEMPLATE_IDX': 2}, {'[PLACE]': 'house', '[OBJECT]': 'computer', 'text': 'Then, Amy and Jonathan went to the house. Amy gave a computer to Jonathan', 'IO': 'Jonathan', 'S': 'Amy', 'TEMPLATE_IDX': 0}, {'[PLACE]': 'station', '[OBJECT]': 'bone', 'text': 'Then, Rebecca and Timothy were thinking about going to the station. Timothy wanted to give a bone to Rebecca', 'IO': 'Rebecca', 'S': 'Timothy', 'TEMPLATE_IDX': 12}, {'[PLACE]': 'store', '[OBJECT]': 'necklace', 'text': 'Then, Christina and Heather had a lot of fun at the store. Heather gave a necklace to Christina', 'IO': 'Christina', 'S': 'Heather', 'TEMPLATE_IDX': 3}, {'[PLACE]': 'restaurant', '[OBJECT]': 'ring', 'text': 'Then, Katherine and Joshua went to the restaurant. Katherine gave a ring to Joshua', 'IO': 'Joshua', 'S': 'Katherine', 'TEMPLATE_IDX': 0}, {'[PLACE]': 'garden', '[OBJECT]': 'basketball', 'text': 'After James and Brian went to the garden, Brian gave a basketball to James', 'IO': 'James', 'S': 'Brian', 'TEMPLATE_IDX': 8}, {'[PLACE]': 'store', '[OBJECT]': 'kiss', 'text': 'After Tyler and Ryan went to the store, Tyler gave a kiss to Ryan', 'IO': 'Ryan', 'S': 'Tyler', 'TEMPLATE_IDX': 6}, {'[PLACE]': 'office', '[OBJECT]': 'computer', 'text': 'After Katherine and Kristen went to the office, Katherine gave a computer to Kristen', 'IO': 'Kristen', 'S': 'Katherine', 'TEMPLATE_IDX': 6}, {'[PLACE]': 'school', '[OBJECT]': 'computer', 'text': 'Then, Jose and Vanessa had a lot of fun at the school. Vanessa gave a computer to Jose', 'IO': 'Jose', 'S': 'Vanessa', 'TEMPLATE_IDX': 3}, {'[PLACE]': 'hospital', '[OBJECT]': 'snack', 'text': 'After Jose and Brandon went to the hospital, Jose gave a snack to Brandon', 'IO': 'Brandon', 'S': 'Jose', 'TEMPLATE_IDX': 6}, {'[PLACE]': 'station', '[OBJECT]': 'kiss', 'text': 'Then, Allison and David were working at the station. David decided to give a kiss to Allison', 'IO': 'Allison', 'S': 'David', 'TEMPLATE_IDX': 5}, {'[PLACE]': 'hospital', '[OBJECT]': 'bone', 'text': 'Then, Heather and Sara had a lot of fun at the hospital. Heather gave a bone to Sara', 'IO': 'Sara', 'S': 'Heather', 'TEMPLATE_IDX': 1}, {'[PLACE]': 'hospital', '[OBJECT]': 'bone', 'text': 'Then, Daniel and Megan were working at the hospital. Megan decided to give a bone to Daniel', 'IO': 'Daniel', 'S': 'Megan', 'TEMPLATE_IDX': 5}, {'[PLACE]': 'store', '[OBJECT]': 'computer', 'text': 'Then, Shannon and Dustin were thinking about going to the store. Shannon wanted to give a computer to Dustin', 'IO': 'Dustin', 'S': 'Shannon', 'TEMPLATE_IDX': 7}, {'[PLACE]': 'garden', '[OBJECT]': 'kiss', 'text': 'Then, Jason and Joseph were working at the garden. Jason decided to give a kiss to Joseph', 'IO': 'Joseph', 'S': 'Jason', 'TEMPLATE_IDX': 10}, {'[PLACE]': 'hospital', '[OBJECT]': 'basketball', 'text': 'Then, Paul and Sarah went to the hospital. Sarah gave a basketball to Paul', 'IO': 'Paul', 'S': 'Sarah', 'TEMPLATE_IDX': 11}, {'[PLACE]': 'hospital', '[OBJECT]': 'snack', 'text': 'Then, Brittany and Anthony went to the hospital. Anthony gave a snack to Brittany', 'IO': 'Brittany', 'S': 'Anthony', 'TEMPLATE_IDX': 11}, {'[PLACE]': 'house', '[OBJECT]': 'computer', 'text': 'When Joshua and Robert got a computer at the house, Robert decided to give it to Joshua', 'IO': 'Joshua', 'S': 'Robert', 'TEMPLATE_IDX': 4}, {'[PLACE]': 'restaurant', '[OBJECT]': 'computer', 'text': 'Then, Amber and Michael went to the restaurant. Amber gave a computer to Michael', 'IO': 'Michael', 'S': 'Amber', 'TEMPLATE_IDX': 0}, {'[PLACE]': 'house', '[OBJECT]': 'ring', 'text': 'Then, Alicia and Aaron had a long argument, and afterwards Aaron said to Alicia', 'IO': 'Alicia', 'S': 'Aaron', 'TEMPLATE_IDX': 2}, {'[PLACE]': 'store', '[OBJECT]': 'necklace', 'text': 'Then, Katie and David had a lot of fun at the store. Katie gave a necklace to David', 'IO': 'David', 'S': 'Katie', 'TEMPLATE_IDX': 1}, {'[PLACE]': 'restaurant', '[OBJECT]': 'ring', 'text': 'Then, Justin and Paul had a long argument, and afterwards Justin said to Paul', 'IO': 'Paul', 'S': 'Justin', 'TEMPLATE_IDX': 9}, {'[PLACE]': 'school', '[OBJECT]': 'basketball', 'text': 'When Kimberly and Jennifer got a basketball at the school, Jennifer decided to give it to Kimberly', 'IO': 'Kimberly', 'S': 'Jennifer', 'TEMPLATE_IDX': 4}, {'[PLACE]': 'house', '[OBJECT]': 'bone', 'text': 'Then, Richard and Joseph were working at the house. Richard decided to give a bone to Joseph', 'IO': 'Joseph', 'S': 'Richard', 'TEMPLATE_IDX': 10}, {'[PLACE]': 'store', '[OBJECT]': 'bone', 'text': 'Then, William and Stephanie had a lot of fun at the store. Stephanie gave a bone to William', 'IO': 'William', 'S': 'Stephanie', 'TEMPLATE_IDX': 3}, {'[PLACE]': 'school', '[OBJECT]': 'computer', 'text': 'Then, Amber and Jeremy went to the school. Jeremy gave a computer to Amber', 'IO': 'Amber', 'S': 'Jeremy', 'TEMPLATE_IDX': 11}, {'[PLACE]': 'store', '[OBJECT]': 'snack', 'text': 'Then, Lindsay and Joseph had a long argument, and afterwards Joseph said to Lindsay', 'IO': 'Lindsay', 'S': 'Joseph', 'TEMPLATE_IDX': 2}, {'[PLACE]': 'hospital', '[OBJECT]': 'basketball', 'text': 'Then, Nicholas and Rebecca had a lot of fun at the hospital. Rebecca gave a basketball to Nicholas', 'IO': 'Nicholas', 'S': 'Rebecca', 'TEMPLATE_IDX': 3}, {'[PLACE]': 'house', '[OBJECT]': 'necklace', 'text': 'Then, Matthew and Kristen had a lot of fun at the house. Kristen gave a necklace to Matthew', 'IO': 'Matthew', 'S': 'Kristen', 'TEMPLATE_IDX': 3}, {'[PLACE]': 'office', '[OBJECT]': 'drink', 'text': 'When Daniel and Samuel got a drink at the office, Samuel decided to give it to Daniel', 'IO': 'Daniel', 'S': 'Samuel', 'TEMPLATE_IDX': 4}, {'[PLACE]': 'garden', '[OBJECT]': 'computer', 'text': 'Then, Amber and Sara were working at the garden. Amber decided to give a computer to Sara', 'IO': 'Sara', 'S': 'Amber', 'TEMPLATE_IDX': 10}, {'[PLACE]': 'garden', '[OBJECT]': 'drink', 'text': 'Then, Katherine and Kevin had a long argument, and afterwards Kevin said to Katherine', 'IO': 'Katherine', 'S': 'Kevin', 'TEMPLATE_IDX': 2}, {'[PLACE]': 'garden', '[OBJECT]': 'drink', 'text': 'Then, Christine and Laura were working at the garden. Laura decided to give a drink to Christine', 'IO': 'Christine', 'S': 'Laura', 'TEMPLATE_IDX': 5}, {'[PLACE]': 'house', '[OBJECT]': 'ring', 'text': 'Then, Melissa and Nicole had a long argument, and afterwards Melissa said to Nicole', 'IO': 'Nicole', 'S': 'Melissa', 'TEMPLATE_IDX': 9}, {'[PLACE]': 'school', '[OBJECT]': 'necklace', 'text': 'After Sara and Jesse went to the school, Jesse gave a necklace to Sara', 'IO': 'Sara', 'S': 'Jesse', 'TEMPLATE_IDX': 8}, {'[PLACE]': 'office', '[OBJECT]': 'kiss', 'text': 'After Jose and Daniel went to the office, Jose gave a kiss to Daniel', 'IO': 'Daniel', 'S': 'Jose', 'TEMPLATE_IDX': 6}, {'[PLACE]': 'house', '[OBJECT]': 'necklace', 'text': 'Then, Kyle and Jamie went to the house. Jamie gave a necklace to Kyle', 'IO': 'Kyle', 'S': 'Jamie', 'TEMPLATE_IDX': 11}, {'[PLACE]': 'restaurant', '[OBJECT]': 'basketball', 'text': 'After Christina and Lindsay went to the restaurant, Christina gave a basketball to Lindsay', 'IO': 'Lindsay', 'S': 'Christina', 'TEMPLATE_IDX': 6}, {'[PLACE]': 'restaurant', '[OBJECT]': 'computer', 'text': 'After Amy and Jose went to the restaurant, Amy gave a computer to Jose', 'IO': 'Jose', 'S': 'Amy', 'TEMPLATE_IDX': 6}, {'[PLACE]': 'hospital', '[OBJECT]': 'basketball', 'text': 'After Michael and Paul went to the hospital, Michael gave a basketball to Paul', 'IO': 'Paul', 'S': 'Michael', 'TEMPLATE_IDX': 6}, {'[PLACE]': 'office', '[OBJECT]': 'snack', 'text': 'After Erica and Katherine went to the office, Erica gave a snack to Katherine', 'IO': 'Katherine', 'S': 'Erica', 'TEMPLATE_IDX': 6}, {'[PLACE]': 'station', '[OBJECT]': 'bone', 'text': 'Then, Alexander and Aaron were thinking about going to the station. Alexander wanted to give a bone to Aaron', 'IO': 'Aaron', 'S': 'Alexander', 'TEMPLATE_IDX': 7}, {'[PLACE]': 'office', '[OBJECT]': 'kiss', 'text': 'Then, Timothy and James were working at the office. Timothy decided to give a kiss to James', 'IO': 'James', 'S': 'Timothy', 'TEMPLATE_IDX': 10}, {'[PLACE]': 'hospital', '[OBJECT]': 'basketball', 'text': 'When Adam and Allison got a basketball at the hospital, Adam decided to give it to Allison', 'IO': 'Allison', 'S': 'Adam', 'TEMPLATE_IDX': 13}, {'[PLACE]': 'store', '[OBJECT]': 'basketball', 'text': 'Then, Nicholas and Justin were thinking about going to the store. Justin wanted to give a basketball to Nicholas', 'IO': 'Nicholas', 'S': 'Justin', 'TEMPLATE_IDX': 12}, {'[PLACE]': 'station', '[OBJECT]': 'drink', 'text': 'Then, Samuel and Mary were thinking about going to the station. Samuel wanted to give a drink to Mary', 'IO': 'Mary', 'S': 'Samuel', 'TEMPLATE_IDX': 7}, {'[PLACE]': 'house', '[OBJECT]': 'snack', 'text': 'Then, Nicole and Scott were working at the house. Nicole decided to give a snack to Scott', 'IO': 'Scott', 'S': 'Nicole', 'TEMPLATE_IDX': 10}, {'[PLACE]': 'store', '[OBJECT]': 'kiss', 'text': 'After Justin and Megan went to the store, Justin gave a kiss to Megan', 'IO': 'Megan', 'S': 'Justin', 'TEMPLATE_IDX': 6}, {'[PLACE]': 'station', '[OBJECT]': 'ring', 'text': 'Then, Mark and Eric were thinking about going to the station. Eric wanted to give a ring to Mark', 'IO': 'Mark', 'S': 'Eric', 'TEMPLATE_IDX': 12}, {'[PLACE]': 'restaurant', '[OBJECT]': 'snack', 'text': 'After Megan and Ryan went to the restaurant, Ryan gave a snack to Megan', 'IO': 'Megan', 'S': 'Ryan', 'TEMPLATE_IDX': 8}, {'[PLACE]': 'office', '[OBJECT]': 'snack', 'text': 'Then, Angela and Nathan were working at the office. Angela decided to give a snack to Nathan', 'IO': 'Nathan', 'S': 'Angela', 'TEMPLATE_IDX': 10}, {'[PLACE]': 'station', '[OBJECT]': 'bone', 'text': 'Then, Jamie and Courtney had a long argument, and afterwards Jamie said to Courtney', 'IO': 'Courtney', 'S': 'Jamie', 'TEMPLATE_IDX': 9}, {'[PLACE]': 'school', '[OBJECT]': 'computer', 'text': 'Then, Stephen and Charles went to the school. Charles gave a computer to Stephen', 'IO': 'Stephen', 'S': 'Charles', 'TEMPLATE_IDX': 11}, {'[PLACE]': 'school', '[OBJECT]': 'computer', 'text': 'Then, Samantha and Sean were thinking about going to the school. Sean wanted to give a computer to Samantha', 'IO': 'Samantha', 'S': 'Sean', 'TEMPLATE_IDX': 12}, {'[PLACE]': 'school', '[OBJECT]': 'computer', 'text': 'Then, Vanessa and David were thinking about going to the school. Vanessa wanted to give a computer to David', 'IO': 'David', 'S': 'Vanessa', 'TEMPLATE_IDX': 7}, {'[PLACE]': 'restaurant', '[OBJECT]': 'bone', 'text': 'Then, Laura and Dustin were working at the restaurant. Dustin decided to give a bone to Laura', 'IO': 'Laura', 'S': 'Dustin', 'TEMPLATE_IDX': 5}, {'[PLACE]': 'school', '[OBJECT]': 'kiss', 'text': 'Then, Crystal and Katie had a lot of fun at the school. Katie gave a kiss to Crystal', 'IO': 'Crystal', 'S': 'Katie', 'TEMPLATE_IDX': 3}, {'[PLACE]': 'station', '[OBJECT]': 'drink', 'text': 'After Amber and Jeremy went to the station, Amber gave a drink to Jeremy', 'IO': 'Jeremy', 'S': 'Amber', 'TEMPLATE_IDX': 6}, {'[PLACE]': 'store', '[OBJECT]': 'drink', 'text': 'Then, Benjamin and Anthony went to the store. Benjamin gave a drink to Anthony', 'IO': 'Anthony', 'S': 'Benjamin', 'TEMPLATE_IDX': 0}, {'[PLACE]': 'house', '[OBJECT]': 'drink', 'text': 'Then, Richard and Michael were thinking about going to the house. Richard wanted to give a drink to Michael', 'IO': 'Michael', 'S': 'Richard', 'TEMPLATE_IDX': 7}, {'[PLACE]': 'school', '[OBJECT]': 'snack', 'text': 'After Cody and Alicia went to the school, Alicia gave a snack to Cody', 'IO': 'Cody', 'S': 'Alicia', 'TEMPLATE_IDX': 8}, {'[PLACE]': 'store', '[OBJECT]': 'drink', 'text': 'Then, Steven and Emily had a lot of fun at the store. Emily gave a drink to Steven', 'IO': 'Steven', 'S': 'Emily', 'TEMPLATE_IDX': 3}, {'[PLACE]': 'restaurant', '[OBJECT]': 'snack', 'text': 'Then, Jose and Alexander were working at the restaurant. Alexander decided to give a snack to Jose', 'IO': 'Jose', 'S': 'Alexander', 'TEMPLATE_IDX': 5}, {'[PLACE]': 'house', '[OBJECT]': 'ring', 'text': 'Then, Travis and Sara had a long argument, and afterwards Sara said to Travis', 'IO': 'Travis', 'S': 'Sara', 'TEMPLATE_IDX': 2}, {'[PLACE]': 'station', '[OBJECT]': 'bone', 'text': 'Then, Mark and Bryan had a lot of fun at the station. Mark gave a bone to Bryan', 'IO': 'Bryan', 'S': 'Mark', 'TEMPLATE_IDX': 1}, {'[PLACE]': 'school', '[OBJECT]': 'snack', 'text': 'Then, Amy and Kevin went to the school. Amy gave a snack to Kevin', 'IO': 'Kevin', 'S': 'Amy', 'TEMPLATE_IDX': 0}, {'[PLACE]': 'hospital', '[OBJECT]': 'drink', 'text': 'Then, Brittany and Bradley were working at the hospital. Bradley decided to give a drink to Brittany', 'IO': 'Brittany', 'S': 'Bradley', 'TEMPLATE_IDX': 5}, {'[PLACE]': 'store', '[OBJECT]': 'necklace', 'text': 'When James and Stephen got a necklace at the store, Stephen decided to give it to James', 'IO': 'James', 'S': 'Stephen', 'TEMPLATE_IDX': 4}, {'[PLACE]': 'school', '[OBJECT]': 'basketball', 'text': 'Then, Jennifer and Allison had a lot of fun at the school. Allison gave a basketball to Jennifer', 'IO': 'Jennifer', 'S': 'Allison', 'TEMPLATE_IDX': 3}, {'[PLACE]': 'school', '[OBJECT]': 'bone', 'text': 'When Travis and Jessica got a bone at the school, Travis decided to give it to Jessica', 'IO': 'Jessica', 'S': 'Travis', 'TEMPLATE_IDX': 13}, {'[PLACE]': 'school', '[OBJECT]': 'snack', 'text': 'Then, Andrew and Jose were thinking about going to the school. Andrew wanted to give a snack to Jose', 'IO': 'Jose', 'S': 'Andrew', 'TEMPLATE_IDX': 7}, {'[PLACE]': 'restaurant', '[OBJECT]': 'kiss', 'text': 'Then, Melissa and Samuel went to the restaurant. Samuel gave a kiss to Melissa', 'IO': 'Melissa', 'S': 'Samuel', 'TEMPLATE_IDX': 11}, {'[PLACE]': 'store', '[OBJECT]': 'computer', 'text': 'Then, William and Rachel were thinking about going to the store. Rachel wanted to give a computer to William', 'IO': 'William', 'S': 'Rachel', 'TEMPLATE_IDX': 12}]\n"
     ]
    }
   ],
   "source": [
    "print(dataset.prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 29,
     "status": "ok",
     "timestamp": 1742788833618,
     "user": {
      "displayName": "Reilly H",
      "userId": "05616995266737589283"
     },
     "user_tz": -780
    },
    "id": "w_5Awk4OZTm5",
    "outputId": "45f29684-e0f8-4732-b252-c36b57f6df8f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7ff2f0246230>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import einops\n",
    "from fancy_einsum import einsum\n",
    "import tqdm.notebook as tqdm\n",
    "import random\n",
    "from pathlib import Path\n",
    "# import plotly.express as px\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from jaxtyping import Float, Int\n",
    "from typing import List, Union, Optional\n",
    "from functools import partial\n",
    "import copy\n",
    "\n",
    "import itertools\n",
    "from transformers import AutoModelForCausalLM, AutoConfig, AutoTokenizer\n",
    "import dataclasses\n",
    "import datasets\n",
    "from IPython.display import HTML\n",
    "\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "\n",
    "import transformer_lens\n",
    "import transformer_lens.utils as utils\n",
    "from transformer_lens.hook_points import (\n",
    "    HookedRootModule,\n",
    "    HookPoint,\n",
    ")\n",
    "from transformer_lens import HookedTransformer, HookedTransformerConfig, FactoredMatrix, ActivationCache\n",
    "\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_logit_diff(logits, dataset):\n",
    "    io_logits = logits[torch.arange(N), dataset.word_idx[\"end\"], dataset.io_tokenIDs]\n",
    "    s_logits = logits[torch.arange(N), dataset.word_idx[\"end\"], dataset.s_tokenIDs]\n",
    "    return (io_logits - s_logits).mean().item()\n",
    "\n",
    "def logit_diff_io_s(model, dataset):\n",
    "    N = dataset.N\n",
    "    logits = model(dataset.toks.long())\n",
    "    io_logits = logits[torch.arange(N), dataset.word_idx[\"end\"], dataset.io_tokenIDs]\n",
    "    s_logits = logits[torch.arange(N), dataset.word_idx[\"end\"], dataset.s_tokenIDs]\n",
    "    return (io_logits - s_logits).mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 0,
     "status": "ok",
     "timestamp": 1742788833619,
     "user": {
      "displayName": "Reilly H",
      "userId": "05616995266737589283"
     },
     "user_tz": -780
    },
    "id": "zGXWvRLSdsmy"
   },
   "outputs": [],
   "source": [
    "from typing import List, Union, Optional\n",
    "import torch\n",
    "from torch import Tensor\n",
    "\n",
    "def logit_diff_perc(\n",
    "    logits: Float[Tensor, \"batch seq d_vocab\"],\n",
    "    clean_logit_diff: float,\n",
    "    dataset_1: Dataset,\n",
    ") -> float:\n",
    "    patched_logit_diff = get_logit_diff(logits, ioi_dataset)\n",
    "    return (patched_logit_diff / clean_logit_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1439,
     "status": "ok",
     "timestamp": 1742788835058,
     "user": {
      "displayName": "Reilly H",
      "userId": "05616995266737589283"
     },
     "user_tz": -780
    },
    "id": "Ov07-Di7Zd0y",
    "outputId": "75636209-ead1-4630-af8e-71227e6c0415"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teacher.reset_hooks(including_permanent=True)\n",
    "logits_original_t = teacher(ioi_dataset.toks.long())\n",
    "logits_original_s = student(ioi_dataset.toks.long())\n",
    "\n",
    "orig_score_t = get_logit_diff(logits_original_t, ioi_dataset)\n",
    "orig_score_s = get_logit_diff(logits_original_s, ioi_dataset)\n",
    "\n",
    "import gc\n",
    "\n",
    "del(logits_original_t)\n",
    "del(logits_original_s)\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-7.0053629875183105, -0.23112374544143677)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_score_t, orig_score_s # logit performance of teacher and student on the task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 81444,
     "status": "ok",
     "timestamp": 1742788916518,
     "user": {
      "displayName": "Reilly H",
      "userId": "05616995266737589283"
     },
     "user_tz": -780
    },
    "id": "X7zWBtJ11WGD",
    "outputId": "0f6d5bda-2dba-4adc-8102-0c25f85d0f87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0, Head 0: Impact = 14.77%, Retained = 85.23%\n",
      "Layer 0, Head 1: Impact = -73.05%, Retained = 173.05%\n",
      "Layer 0, Head 2: Impact = 32.49%, Retained = 67.51%\n",
      "Layer 0, Head 3: Impact = -1.81%, Retained = 101.81%\n",
      "Layer 0, Head 4: Impact = 8.12%, Retained = 91.88%\n",
      "Layer 0, Head 5: Impact = -100.98%, Retained = 200.98%\n",
      "Layer 0, Head 6: Impact = 29.52%, Retained = 70.48%\n",
      "Layer 0, Head 7: Impact = 72.28%, Retained = 27.72%\n",
      "Layer 0, Head 8: Impact = -37.33%, Retained = 137.33%\n",
      "Layer 0, Head 9: Impact = -115.93%, Retained = 215.93%\n",
      "Layer 0, Head 10: Impact = -109.62%, Retained = 209.62%\n",
      "Layer 0, Head 11: Impact = -82.19%, Retained = 182.19%\n",
      "Layer 1, Head 0: Impact = -20.04%, Retained = 120.04%\n",
      "Layer 1, Head 1: Impact = 44.91%, Retained = 55.09%\n",
      "Layer 1, Head 2: Impact = 15.56%, Retained = 84.44%\n",
      "Layer 1, Head 3: Impact = -11.49%, Retained = 111.49%\n",
      "Layer 1, Head 4: Impact = -17.68%, Retained = 117.68%\n",
      "Layer 1, Head 5: Impact = -18.69%, Retained = 118.69%\n",
      "Layer 1, Head 6: Impact = 24.41%, Retained = 75.59%\n",
      "Layer 1, Head 7: Impact = -49.19%, Retained = 149.19%\n",
      "Layer 1, Head 8: Impact = -10.67%, Retained = 110.67%\n",
      "Layer 1, Head 9: Impact = 54.74%, Retained = 45.26%\n",
      "Layer 1, Head 10: Impact = -23.35%, Retained = 123.35%\n",
      "Layer 1, Head 11: Impact = -36.85%, Retained = 136.85%\n",
      "Layer 2, Head 0: Impact = -12.90%, Retained = 112.90%\n",
      "Layer 2, Head 1: Impact = -10.03%, Retained = 110.03%\n",
      "Layer 2, Head 2: Impact = -25.24%, Retained = 125.24%\n",
      "Layer 2, Head 3: Impact = -32.44%, Retained = 132.44%\n",
      "Layer 2, Head 4: Impact = -14.75%, Retained = 114.75%\n",
      "Layer 2, Head 5: Impact = -11.87%, Retained = 111.87%\n",
      "Layer 2, Head 6: Impact = -48.80%, Retained = 148.80%\n",
      "Layer 2, Head 7: Impact = -61.37%, Retained = 161.37%\n",
      "Layer 2, Head 8: Impact = 48.68%, Retained = 51.32%\n",
      "Layer 2, Head 9: Impact = -9.73%, Retained = 109.73%\n",
      "Layer 2, Head 10: Impact = 9.98%, Retained = 90.02%\n",
      "Layer 2, Head 11: Impact = 17.06%, Retained = 82.94%\n",
      "Layer 3, Head 0: Impact = -10.68%, Retained = 110.68%\n",
      "Layer 3, Head 1: Impact = -110.59%, Retained = 210.59%\n",
      "Layer 3, Head 2: Impact = -11.75%, Retained = 111.75%\n",
      "Layer 3, Head 3: Impact = -31.18%, Retained = 131.18%\n",
      "Layer 3, Head 4: Impact = 32.65%, Retained = 67.35%\n",
      "Layer 3, Head 5: Impact = -12.34%, Retained = 112.34%\n",
      "Layer 3, Head 6: Impact = 58.49%, Retained = 41.51%\n",
      "Layer 3, Head 7: Impact = -9.35%, Retained = 109.35%\n",
      "Layer 3, Head 8: Impact = -19.77%, Retained = 119.77%\n",
      "Layer 3, Head 9: Impact = -71.90%, Retained = 171.90%\n",
      "Layer 3, Head 10: Impact = -95.09%, Retained = 195.09%\n",
      "Layer 3, Head 11: Impact = 22.94%, Retained = 77.06%\n",
      "Layer 4, Head 0: Impact = 0.25%, Retained = 99.75%\n",
      "Layer 4, Head 1: Impact = -6.67%, Retained = 106.67%\n",
      "Layer 4, Head 2: Impact = 4.47%, Retained = 95.53%\n",
      "Layer 4, Head 3: Impact = 9.72%, Retained = 90.28%\n",
      "Layer 4, Head 4: Impact = -18.08%, Retained = 118.08%\n",
      "Layer 4, Head 5: Impact = -31.32%, Retained = 131.32%\n",
      "Layer 4, Head 6: Impact = 36.06%, Retained = 63.94%\n",
      "Layer 4, Head 7: Impact = -152.10%, Retained = 252.10%\n",
      "Layer 4, Head 8: Impact = 15.19%, Retained = 84.81%\n",
      "Layer 4, Head 9: Impact = 29.87%, Retained = 70.13%\n",
      "Layer 4, Head 10: Impact = 18.54%, Retained = 81.46%\n",
      "Layer 4, Head 11: Impact = 4.02%, Retained = 95.98%\n",
      "Layer 5, Head 0: Impact = 42.54%, Retained = 57.46%\n",
      "Layer 5, Head 1: Impact = 40.79%, Retained = 59.21%\n",
      "Layer 5, Head 2: Impact = -80.07%, Retained = 180.07%\n",
      "Layer 5, Head 3: Impact = 10.49%, Retained = 89.51%\n",
      "Layer 5, Head 4: Impact = 1.55%, Retained = 98.45%\n",
      "Layer 5, Head 5: Impact = 4.47%, Retained = 95.53%\n",
      "Layer 5, Head 6: Impact = 40.01%, Retained = 59.99%\n",
      "Layer 5, Head 7: Impact = -8.38%, Retained = 108.38%\n",
      "Layer 5, Head 8: Impact = -8.89%, Retained = 108.89%\n",
      "Layer 5, Head 9: Impact = 31.19%, Retained = 68.81%\n",
      "Layer 5, Head 10: Impact = -104.01%, Retained = 204.01%\n",
      "Layer 5, Head 11: Impact = 16.81%, Retained = 83.19%\n",
      "Layer 0, Head 0: Impact = 10.47%, Retained = 89.53%\n",
      "Layer 0, Head 1: Impact = -14.41%, Retained = 114.41%\n",
      "Layer 0, Head 2: Impact = 0.71%, Retained = 99.29%\n",
      "Layer 0, Head 3: Impact = 4.27%, Retained = 95.73%\n",
      "Layer 0, Head 4: Impact = 3.72%, Retained = 96.28%\n",
      "Layer 0, Head 5: Impact = 24.73%, Retained = 75.27%\n",
      "Layer 0, Head 6: Impact = 18.99%, Retained = 81.01%\n",
      "Layer 0, Head 7: Impact = 13.63%, Retained = 86.37%\n",
      "Layer 0, Head 8: Impact = 6.26%, Retained = 93.74%\n",
      "Layer 0, Head 9: Impact = -9.49%, Retained = 109.49%\n",
      "Layer 0, Head 10: Impact = -15.29%, Retained = 115.29%\n",
      "Layer 0, Head 11: Impact = -4.61%, Retained = 104.61%\n",
      "Layer 1, Head 0: Impact = 7.53%, Retained = 92.47%\n",
      "Layer 1, Head 1: Impact = -2.52%, Retained = 102.52%\n",
      "Layer 1, Head 2: Impact = -6.09%, Retained = 106.09%\n",
      "Layer 1, Head 3: Impact = -13.72%, Retained = 113.72%\n",
      "Layer 1, Head 4: Impact = 1.21%, Retained = 98.79%\n",
      "Layer 1, Head 5: Impact = 9.31%, Retained = 90.69%\n",
      "Layer 1, Head 6: Impact = 15.31%, Retained = 84.69%\n",
      "Layer 1, Head 7: Impact = 3.25%, Retained = 96.75%\n",
      "Layer 1, Head 8: Impact = -5.84%, Retained = 105.84%\n",
      "Layer 1, Head 9: Impact = -1.65%, Retained = 101.65%\n",
      "Layer 1, Head 10: Impact = 7.29%, Retained = 92.71%\n",
      "Layer 1, Head 11: Impact = 6.52%, Retained = 93.48%\n",
      "Layer 2, Head 0: Impact = -23.63%, Retained = 123.63%\n",
      "Layer 2, Head 1: Impact = -5.28%, Retained = 105.28%\n",
      "Layer 2, Head 2: Impact = -6.30%, Retained = 106.30%\n",
      "Layer 2, Head 3: Impact = -8.91%, Retained = 108.91%\n",
      "Layer 2, Head 4: Impact = -4.97%, Retained = 104.97%\n",
      "Layer 2, Head 5: Impact = 5.23%, Retained = 94.77%\n",
      "Layer 2, Head 6: Impact = 4.15%, Retained = 95.85%\n",
      "Layer 2, Head 7: Impact = -7.55%, Retained = 107.55%\n",
      "Layer 2, Head 8: Impact = -11.96%, Retained = 111.96%\n",
      "Layer 2, Head 9: Impact = -10.80%, Retained = 110.80%\n",
      "Layer 2, Head 10: Impact = -29.71%, Retained = 129.71%\n",
      "Layer 2, Head 11: Impact = -6.36%, Retained = 106.36%\n",
      "Layer 3, Head 0: Impact = 1.14%, Retained = 98.86%\n",
      "Layer 3, Head 1: Impact = 1.25%, Retained = 98.75%\n",
      "Layer 3, Head 2: Impact = 2.21%, Retained = 97.79%\n",
      "Layer 3, Head 3: Impact = -2.55%, Retained = 102.55%\n",
      "Layer 3, Head 4: Impact = -6.55%, Retained = 106.55%\n",
      "Layer 3, Head 5: Impact = -6.94%, Retained = 106.94%\n",
      "Layer 3, Head 6: Impact = -9.88%, Retained = 109.88%\n",
      "Layer 3, Head 7: Impact = -7.65%, Retained = 107.65%\n",
      "Layer 3, Head 8: Impact = -7.07%, Retained = 107.07%\n",
      "Layer 3, Head 9: Impact = -1.06%, Retained = 101.06%\n",
      "Layer 3, Head 10: Impact = -5.70%, Retained = 105.70%\n",
      "Layer 3, Head 11: Impact = -10.75%, Retained = 110.75%\n",
      "Layer 4, Head 0: Impact = -0.59%, Retained = 100.59%\n",
      "Layer 4, Head 1: Impact = 3.72%, Retained = 96.28%\n",
      "Layer 4, Head 2: Impact = -3.94%, Retained = 103.94%\n",
      "Layer 4, Head 3: Impact = -2.89%, Retained = 102.89%\n",
      "Layer 4, Head 4: Impact = 3.30%, Retained = 96.70%\n",
      "Layer 4, Head 5: Impact = -1.64%, Retained = 101.64%\n",
      "Layer 4, Head 6: Impact = -6.61%, Retained = 106.61%\n",
      "Layer 4, Head 7: Impact = -5.98%, Retained = 105.98%\n",
      "Layer 4, Head 8: Impact = 1.79%, Retained = 98.21%\n",
      "Layer 4, Head 9: Impact = 3.43%, Retained = 96.57%\n",
      "Layer 4, Head 10: Impact = 1.99%, Retained = 98.01%\n",
      "Layer 4, Head 11: Impact = -7.32%, Retained = 107.32%\n",
      "Layer 5, Head 0: Impact = 9.40%, Retained = 90.60%\n",
      "Layer 5, Head 1: Impact = -1.41%, Retained = 101.41%\n",
      "Layer 5, Head 2: Impact = 2.80%, Retained = 97.20%\n",
      "Layer 5, Head 3: Impact = 5.07%, Retained = 94.93%\n",
      "Layer 5, Head 4: Impact = -9.39%, Retained = 109.39%\n",
      "Layer 5, Head 5: Impact = 1.69%, Retained = 98.31%\n",
      "Layer 5, Head 6: Impact = 1.42%, Retained = 98.58%\n",
      "Layer 5, Head 7: Impact = 2.01%, Retained = 97.99%\n",
      "Layer 5, Head 8: Impact = 15.66%, Retained = 84.34%\n",
      "Layer 5, Head 9: Impact = 12.33%, Retained = 87.67%\n",
      "Layer 5, Head 10: Impact = -3.77%, Retained = 103.77%\n",
      "Layer 5, Head 11: Impact = -2.44%, Retained = 102.44%\n",
      "Layer 6, Head 0: Impact = 0.02%, Retained = 99.98%\n",
      "Layer 6, Head 1: Impact = -2.71%, Retained = 102.71%\n",
      "Layer 6, Head 2: Impact = -4.33%, Retained = 104.33%\n",
      "Layer 6, Head 3: Impact = -1.11%, Retained = 101.11%\n",
      "Layer 6, Head 4: Impact = 2.86%, Retained = 97.14%\n",
      "Layer 6, Head 5: Impact = 4.47%, Retained = 95.53%\n",
      "Layer 6, Head 6: Impact = -9.99%, Retained = 109.99%\n",
      "Layer 6, Head 7: Impact = -1.57%, Retained = 101.57%\n",
      "Layer 6, Head 8: Impact = 7.41%, Retained = 92.59%\n",
      "Layer 6, Head 9: Impact = 0.87%, Retained = 99.13%\n",
      "Layer 6, Head 10: Impact = 0.70%, Retained = 99.30%\n",
      "Layer 6, Head 11: Impact = 3.90%, Retained = 96.10%\n",
      "Layer 7, Head 0: Impact = -1.02%, Retained = 101.02%\n",
      "Layer 7, Head 1: Impact = 0.12%, Retained = 99.88%\n",
      "Layer 7, Head 2: Impact = -4.89%, Retained = 104.89%\n",
      "Layer 7, Head 3: Impact = 10.84%, Retained = 89.16%\n",
      "Layer 7, Head 4: Impact = -3.26%, Retained = 103.26%\n",
      "Layer 7, Head 5: Impact = -2.26%, Retained = 102.26%\n",
      "Layer 7, Head 6: Impact = -0.98%, Retained = 100.98%\n",
      "Layer 7, Head 7: Impact = -2.39%, Retained = 102.39%\n",
      "Layer 7, Head 8: Impact = 1.67%, Retained = 98.33%\n",
      "Layer 7, Head 9: Impact = -0.05%, Retained = 100.05%\n",
      "Layer 7, Head 10: Impact = 0.63%, Retained = 99.37%\n",
      "Layer 7, Head 11: Impact = -0.89%, Retained = 100.89%\n",
      "Layer 8, Head 0: Impact = -7.55%, Retained = 107.55%\n",
      "Layer 8, Head 1: Impact = -0.65%, Retained = 100.65%\n",
      "Layer 8, Head 2: Impact = 1.59%, Retained = 98.41%\n",
      "Layer 8, Head 3: Impact = -2.67%, Retained = 102.67%\n",
      "Layer 8, Head 4: Impact = -0.59%, Retained = 100.59%\n",
      "Layer 8, Head 5: Impact = 6.94%, Retained = 93.06%\n",
      "Layer 8, Head 6: Impact = -0.43%, Retained = 100.43%\n",
      "Layer 8, Head 7: Impact = -0.93%, Retained = 100.93%\n",
      "Layer 8, Head 8: Impact = 4.73%, Retained = 95.27%\n",
      "Layer 8, Head 9: Impact = -3.12%, Retained = 103.12%\n",
      "Layer 8, Head 10: Impact = -6.58%, Retained = 106.58%\n",
      "Layer 8, Head 11: Impact = -6.26%, Retained = 106.26%\n",
      "Layer 9, Head 0: Impact = -0.09%, Retained = 100.09%\n",
      "Layer 9, Head 1: Impact = -9.58%, Retained = 109.58%\n",
      "Layer 9, Head 2: Impact = 0.36%, Retained = 99.64%\n",
      "Layer 9, Head 3: Impact = 2.89%, Retained = 97.11%\n",
      "Layer 9, Head 4: Impact = 2.63%, Retained = 97.37%\n",
      "Layer 9, Head 5: Impact = -1.70%, Retained = 101.70%\n",
      "Layer 9, Head 6: Impact = -1.56%, Retained = 101.56%\n",
      "Layer 9, Head 7: Impact = 3.61%, Retained = 96.39%\n",
      "Layer 9, Head 8: Impact = -0.32%, Retained = 100.32%\n",
      "Layer 9, Head 9: Impact = -1.99%, Retained = 101.99%\n",
      "Layer 9, Head 10: Impact = -0.65%, Retained = 100.65%\n",
      "Layer 9, Head 11: Impact = 2.13%, Retained = 97.87%\n",
      "Layer 10, Head 0: Impact = 0.05%, Retained = 99.95%\n",
      "Layer 10, Head 1: Impact = 2.36%, Retained = 97.64%\n",
      "Layer 10, Head 2: Impact = 2.00%, Retained = 98.00%\n",
      "Layer 10, Head 3: Impact = -2.98%, Retained = 102.98%\n",
      "Layer 10, Head 4: Impact = 3.04%, Retained = 96.96%\n",
      "Layer 10, Head 5: Impact = 1.02%, Retained = 98.98%\n",
      "Layer 10, Head 6: Impact = -1.45%, Retained = 101.45%\n",
      "Layer 10, Head 7: Impact = 1.98%, Retained = 98.02%\n",
      "Layer 10, Head 8: Impact = -0.96%, Retained = 100.96%\n",
      "Layer 10, Head 9: Impact = 6.63%, Retained = 93.37%\n",
      "Layer 10, Head 10: Impact = -0.77%, Retained = 100.77%\n",
      "Layer 10, Head 11: Impact = 2.20%, Retained = 97.80%\n",
      "Layer 11, Head 0: Impact = -3.25%, Retained = 103.25%\n",
      "Layer 11, Head 1: Impact = 0.50%, Retained = 99.50%\n",
      "Layer 11, Head 2: Impact = 0.63%, Retained = 99.37%\n",
      "Layer 11, Head 3: Impact = 0.71%, Retained = 99.29%\n",
      "Layer 11, Head 4: Impact = 8.77%, Retained = 91.23%\n",
      "Layer 11, Head 5: Impact = -0.34%, Retained = 100.34%\n",
      "Layer 11, Head 6: Impact = 2.52%, Retained = 97.48%\n",
      "Layer 11, Head 7: Impact = -0.21%, Retained = 100.21%\n",
      "Layer 11, Head 8: Impact = 19.91%, Retained = 80.09%\n",
      "Layer 11, Head 9: Impact = 1.49%, Retained = 98.51%\n",
      "Layer 11, Head 10: Impact = -1.19%, Retained = 101.19%\n",
      "Layer 11, Head 11: Impact = -2.02%, Retained = 102.02%\n"
     ]
    }
   ],
   "source": [
    "def direct_ablate_single_head(\n",
    "    model: HookedTransformer,\n",
    "    dataset: Dataset,\n",
    "    layer: int,\n",
    "    head: int,\n",
    "    orig_score: float,\n",
    "    ablation_type=\"zero\",\n",
    "    print_output: bool = True\n",
    ") -> float:\n",
    "    model.reset_hooks(including_permanent=True)\n",
    "\n",
    "    if ablation_type == \"mean\":\n",
    "        _, cache = model.run_with_cache(\n",
    "            dataset.toks.long(),\n",
    "            return_type=None,\n",
    "            names_filter=lambda name: name.endswith(\"z\") and f\"blocks.{layer}\" in name\n",
    "        )\n",
    "        z_mean = cache[utils.get_act_name(\"z\", layer)].mean(dim=0, keepdim=True)\n",
    "\n",
    "    def hook_fn(z, hook):\n",
    "        if hook.layer() == layer:\n",
    "            z_modified = z.clone()\n",
    "            if ablation_type == \"zero\":\n",
    "                z_modified[:, :, head] = 0\n",
    "            else:\n",
    "                z_modified[:, :, head] = z_mean.expand_as(z[:, :, head])\n",
    "            return z_modified\n",
    "        return z\n",
    "\n",
    "    model.add_hook(lambda name: name.endswith(\"z\"), hook_fn, is_permanent=False)\n",
    "\n",
    "    ablated_logits = model(dataset.toks)\n",
    "\n",
    "    new_score = get_logit_diff(ablated_logits, ioi_dataset)\n",
    "\n",
    "    percent_retained = 100 * (new_score / orig_score)\n",
    "\n",
    "    if print_output:\n",
    "        impact = 100 - percent_retained\n",
    "        print(f\"Layer {layer}, Head {head}: Impact = {impact:.2f}%, Retained = {percent_retained:.2f}%\")\n",
    "\n",
    "    model.reset_hooks()\n",
    "    return percent_retained\n",
    "\n",
    "student_scores = {}\n",
    "for layer in range(6):\n",
    "    for head in range(12):\n",
    "        retained = direct_ablate_single_head(\n",
    "            student, ioi_dataset, layer, head, orig_score_s, ablation_type=\"zero\"\n",
    "        )\n",
    "        student_scores[(layer, head)] = retained\n",
    "\n",
    "teacher_scores = {}\n",
    "for layer in range(12):\n",
    "    for head in range(12):\n",
    "        retained = direct_ablate_single_head(\n",
    "            teacher, ioi_dataset, layer, head, orig_score_t, ablation_type=\"zero\"\n",
    "        )\n",
    "        teacher_scores[(layer, head)] = retained\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 33,
     "status": "ok",
     "timestamp": 1742789088276,
     "user": {
      "displayName": "Reilly H",
      "userId": "05616995266737589283"
     },
     "user_tz": -780
    },
    "id": "qkmH4fud30jq"
   },
   "outputs": [],
   "source": [
    "lh_scores_t = teacher_scores\n",
    "lh_scores_s = student_scores\n",
    "\n",
    "sorted_lh_scores_t = sorted(lh_scores_t.items(), key=lambda item: -item[1], reverse=True)\n",
    "modified_scores_t = []\n",
    "\n",
    "sorted_lh_scores_s = sorted(lh_scores_s.items(), key=lambda item: -item[1], reverse=True)\n",
    "modified_scores_s = []\n",
    "\n",
    "for lh, score in sorted_lh_scores_t:\n",
    "    modified_score = -round(100 - score, 2)\n",
    "    modified_scores_t.append((lh, modified_score))\n",
    "scores_attn_t = modified_scores_t\n",
    "\n",
    "for lh, score in sorted_lh_scores_s:\n",
    "    modified_score = -round(100 - score, 2)\n",
    "    modified_scores_s.append((lh, modified_score))\n",
    "scores_attn_s = modified_scores_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "executionInfo": {
     "elapsed": 263,
     "status": "ok",
     "timestamp": 1742789089025,
     "user": {
      "displayName": "Reilly H",
      "userId": "05616995266737589283"
     },
     "user_tz": -780
    },
    "id": "OV1wcxWv32jO",
    "outputId": "02f9da01-8001-4ca6-c33e-f316da76f293"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lh_scores_drop = {key: min(0, val-100) for key, val in lh_scores_t.items()}\n",
    "scores = list(lh_scores_drop.values())\n",
    "scores = [s.cpu().numpy() if isinstance(s, torch.Tensor) else s for s in scores]\n",
    "plt.hist(scores, bins=10, edgecolor='black')\n",
    "n, bins, patches = plt.hist(scores, bins=10, edgecolor='black')\n",
    "\n",
    "for i in range(len(n)):\n",
    "    plt.text(bins[i]+5, n[i], str(int(n[i])), va='bottom', ha='center')\n",
    "\n",
    "plt.xticks(range(-100, 0, 10))\n",
    "plt.xlabel('Percentage Drop from Full Performance')\n",
    "plt.ylabel('Number of Attention Heads')\n",
    "plt.title('Distribution of Attention Head Performance Drop Percentages')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "executionInfo": {
     "elapsed": 80,
     "status": "ok",
     "timestamp": 1742789089106,
     "user": {
      "displayName": "Reilly H",
      "userId": "05616995266737589283"
     },
     "user_tz": -780
    },
    "id": "cdsPBzUL4ejW",
    "outputId": "b48927ed-16d9-4669-bc16-88278af93f7c"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjsAAAHHCAYAAABZbpmkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAABgyUlEQVR4nO3dd1xT1/8/8FfYGwEFRBEQFRcuXIgbFLfWXW1BarX9FPemrXWvtu6BoxZHbbXuURd1VotVUVxFHLhlWBUQFARyfn/4436NAU0gmBBfz8cjD825N/e+cu9N8ubec++VCSEEiIiIiPSUgbYDEBERERUnFjtERESk11jsEBERkV5jsUNERER6jcUOERER6TUWO0RERKTXWOwQERGRXmOxQ0RERHqNxQ4RERHptQ+62Jk8eTJkMtl7mVfLli3RsmVL6fnRo0chk8mwZcuW9zL/AQMGwN3d/b3Mq7DS09Px+eefw9nZGTKZDCNGjNB2pPfifW6HJUXe5+Po0aPajqLghx9+QMWKFWFoaIg6depoOw4RqUhvip01a9ZAJpNJDzMzM7i4uCAwMBCLFi3Cs2fPNDKfhw8fYvLkyYiJidHI9DRJl7OpYubMmVizZg3+97//Yf369fj000/f+Zrc3Fy4uLhAJpNh3759+Y6zbNkyrFmzRqn933//xeTJk3H79u0iJn+358+fY/LkyTr34y2TyTBkyJB8h+V9ps6ePfueU6kuv899lSpVMGTIECQlJWl0XgcPHsS4cePg5+eHiIgIzJw5U6PT/9AMGDBAYd1ZWVmhYsWK6NmzJ7Zu3Qq5XK7tiEre5/amDe/zO/F9M9J2AE2bOnUqPDw8kJ2djcTERBw9ehQjRozAvHnzsGvXLtSqVUsa99tvv8WECRPUmv7Dhw8xZcoUuLu7q/WX3cGDB9WaT2G8LduqVat08svjdYcPH0bjxo0xadIktV6TkJAAd3d3bNiwAe3bt1caZ9myZShdujQGDBig0P7vv/9iypQpaNmyZbHv9Xr+/DmmTJkCAAp7+IDCbYekKO9zn5mZiRMnTiA8PBx79+7F5cuXYWFhoZF5HD58GAYGBli9ejVMTEw0Ms0PnampKX766ScAwIsXL3Dnzh3s3r0bPXv2RMuWLbFz507Y2NhoOaWy97G9acP7/E583/Su2Gnfvj3q168vPQ8LC8Phw4fRqVMndOnSBbGxsTA3NwcAGBkZwcioeBfB8+fPYWFhofUvR2NjY63OXxXJycmoXr26Wq/55ZdfUK9ePQQHB+Prr79GRkYGLC0tiylh8Xgf26G+e/1z//nnn8PBwQHz5s3Dzp078fHHHxdp2nmf4eTkZJibm2vssyyEQGZmpvR99CEyMjLCJ598otA2ffp0zJ49G2FhYRg0aBA2bdpU4Ou1tQzfx/ZGmqU3h7HepnXr1pg4cSLu3LmDX375RWrPr69EZGQkmjZtilKlSsHKygpeXl74+uuvAbzqR9CgQQMAQEhIiLQrM+8QScuWLVGzZk1ER0ejefPmsLCwkF77Zp+dPLm5ufj666/h7OwMS0tLdOnSBffu3VMYx93dXWmvxJvTfFe2/PrsZGRkYPTo0XB1dYWpqSm8vLzw448/QgihMF7eoY4dO3agZs2aMDU1RY0aNbB///78F/gbkpOTMXDgQDg5OcHMzAy1a9fG2rVrpeF5/TNu3bqFP/74Q8r+rl2pL168wPbt29G3b1/07t0bL168wM6dOxXGcXd3x5UrV3Ds2DFpui1btsSaNWvQq1cvAECrVq2kYa8fZtq3bx+aNWsGS0tLWFtbo2PHjrhy5YrC9AcMGAArKys8ePAA3bp1g5WVFcqUKYMxY8YgNzcXAHD79m2UKVMGADBlyhRpXpMnTwaQ/3aYk5ODadOmwdPTE6ampnB3d8fXX3+NrKwspffXqVMnnDhxAg0bNoSZmRkqVqyIdevWvX2lFMHVq1fRs2dP2Nvbw8zMDPXr18euXbsUxnny5AnGjBkDb29vWFlZwcbGBu3bt8eFCxeUpnf//n1069YNlpaWcHR0xMiRI5Xep7pat24NALh165bU9ssvv8DHxwfm5uawt7dH3759lT5rBX2GZTIZIiIikJGRofTZUnddHThwAPXr14e5uTlWrFghbf+///47pkyZgnLlysHa2ho9e/ZEamoqsrKyMGLECDg6OsLKygohISFK046IiEDr1q3h6OgIU1NTVK9eHeHh4UrLRZ3tJSUlBSNHjoS7uztMTU1Rvnx5BAUF4b///pPGycrKwqRJk1CpUiWYmprC1dUV48aNK/L6mzBhAtq2bYvNmzfj2rVr71yGABAfH49evXrB3t4eFhYWaNy4Mf744w+F6eYt602bNr3ze1cdmt7eACAzMxOTJ09GlSpVYGZmhrJly6J79+64efOm9Hq5XI4FCxagRo0aMDMzg5OTE7744gs8ffpUYT6qrPd3fSfu3LkTHTt2hIuLC0xNTeHp6Ylp06ZJ33OvW7p0KSpWrAhzc3M0bNgQf/31V76/gapuP2/7XVaZ0BMRERECgDhz5ky+w+/duycAiJ49e0ptkyZNEq8vgsuXLwsTExNRv359sXDhQrF8+XIxZswY0bx5cyGEEImJiWLq1KkCgBg8eLBYv369WL9+vbh586YQQogWLVoIZ2dnUaZMGTF06FCxYsUKsWPHDmlYixYtpHkdOXJEABDe3t6iVq1aYt68eWLChAnCzMxMVKlSRTx//lwa183NTQQHByu9p9en+a5swcHBws3NTXqtXC4XrVu3FjKZTHz++ediyZIlonPnzgKAGDFihMJ8AIjatWuLsmXLimnTpokFCxaIihUrCgsLC/Hff/+9db08f/5cVKtWTRgbG4uRI0eKRYsWiWbNmgkAYsGCBVL29evXi9KlS4s6depI2dPT09867Y0bNwqZTCbu3r0rhBCidevWokOHDgrjbN++XZQvX15UrVpVmu7BgwfFzZs3xbBhwwQA8fXXX0vDEhMThRBCrFu3TshkMtGuXTuxePFiMWfOHOHu7i5KlSolbt26JU0/ODhYmJmZiRo1aojPPvtMhIeHix49eggAYtmyZUIIIdLT00V4eLgAID766CNpXhcuXBBCKG+HedPN216XLl0qgoKCBADRrVs3hfHc3NyEl5eXcHJyEl9//bVYsmSJqFevnpDJZOLy5ctvXX5CvFq3AwcOFI8ePVJ6LF68WOkzdfnyZWFrayuqV68u5syZI5YsWSKaN28uZDKZ2LZtmzTemTNnhKenp5gwYYJYsWKFmDp1qihXrpywtbUVDx48kMZ7/vy5qFKlijAzMxPjxo0TCxYsED4+PqJWrVoCgDhy5Mhb8xf0uV+4cKEAIJYvXy6EEGL69OlCJpOJPn36iGXLlokpU6aI0qVLC3d3d/H06VPpdQV9htevXy+aNWsmTE1N8/1sqbquKlWqJOzs7MSECRPE8uXLxZEjR6Tvgjp16ghfX1+xaNEiMWzYMCGTyUTfvn1Fv379RPv27cXSpUvFp59+KgCIKVOmKEy7QYMGYsCAAWL+/Pli8eLFom3btgKAWLJkiVIGVbaXZ8+eiZo1awpDQ0MxaNAgER4eLqZNmyYaNGggzp8/L4QQIjc3V7Rt21ZYWFiIESNGiBUrVoghQ4YIIyMj0bVr17eut7zlZmlpWeDw9evXK72HgpZhYmKicHJyEtbW1uKbb74R8+bNE7Vr1xYGBgYK26U637v5eV/bW05OjvD39xcARN++fcWSJUvErFmzROvWraXfFCGE+Pzzz4WRkZEYNGiQWL58uRg/frywtLQUDRo0EC9fvlRYbu9a7+/6TuzWrZvo3bu3+OGHH0R4eLjo1auXACDGjBmjsCyWLVsmAIhmzZqJRYsWiVGjRgl7e3vh6emp8Buo6vbzrt9lVX0wxY4QQtja2oq6detKz9/8kZk/f74AIB49elTgNM6cOSMAiIiICKVhLVq0UNjg3xyWX7FTrlw5kZaWJrX//vvvAoBYuHCh1KZKsfOubG8WOzt27BAAxPTp0xXG69mzp5DJZOLGjRtSGwBhYmKi0HbhwgUBQCxevFhpXq9bsGCBACB++eUXqe3ly5fC19dXWFlZKbx3Nzc30bFjx7dO73WdOnUSfn5+0vOVK1cKIyMjkZycrDBejRo1FJZTns2bN+f7g/rs2TNRqlQpMWjQIIX2xMREYWtrq9Ce90M3depUhXHr1q0rfHx8pOePHj0SAMSkSZOUcry5HcbExAgA4vPPP1cYb8yYMQKAOHz4sNTm5uYmAIjjx49LbcnJycLU1FSMHj1aaV5vAvDOx+ufKX9/f+Ht7S0yMzOlNrlcLpo0aSIqV64stWVmZorc3FyFed26dUuYmpoqLKu87eP333+X2jIyMkSlSpXUKnb+/PNP8ejRI3Hv3j2xceNG4eDgIMzNzcX9+/fF7du3haGhoZgxY4bCay9duiSMjIwU2t/2Gc7vx7kw62r//v0K4+Z9F9SsWVPhB+rjjz8WMplMtG/fXmF8X19fhc+yECLfH+nAwEBRsWJFhTZVt5fvvvtOAFAoFPLI5XIhxKtixMDAQPz1118Kw5cvXy4AiJMnTyq99nXvKnbOnz8vAIiRI0cq5X9zGY4YMUIAUMjy7Nkz4eHhIdzd3aVtUZ3v3fy8r+3t559/FgDEvHnzlDLkLf+//vpLABAbNmxQGL5//36ldlXXe0HfiULkv4198cUXwsLCQvo+yMrKEg4ODqJBgwYiOztbGm/NmjUCgML3sKrbjyq/y6r4IA5j5bGysnrrWVmlSpUC8Gp3XWE785qamiIkJETl8YOCgmBtbS0979mzJ8qWLYu9e/cWav6q2rt3LwwNDTFs2DCF9tGjR0MIoXRmU0BAADw9PaXntWrVgo2NDeLj4985H2dnZ4Xj2MbGxhg2bBjS09Nx7NixQuV//PgxDhw4oDDdHj16SIcDiiIyMhIpKSn4+OOP8d9//0kPQ0NDNGrUCEeOHFF6zZdffqnwvFmzZu9cNgXJW/ejRo1SaB89ejQAKO2ar169Opo1ayY9L1OmDLy8vFSef9euXREZGan0GDt2rMJ4T548weHDh9G7d288e/ZMWi6PHz9GYGAgrl+/jgcPHgB49TkwMHj19ZKbm4vHjx9Lu5/PnTun8F7Lli2Lnj17Sm0WFhYYPHiwStnzBAQEoEyZMnB1dUXfvn1hZWWF7du3o1y5cti2bRvkcjl69+6tsD6dnZ1RuXJlpfWpzmdY3XXl4eGBwMDAfKcVFBSk0LeuUaNGEELgs88+UxivUaNGuHfvHnJycqS21/uspKam4r///kOLFi0QHx+P1NRUhdersr1s3boVtWvXxkcffaSUM++Q6+bNm1GtWjVUrVpVYbnmHdLJ73OiDisrKwBQ+s7Obxnu3bsXDRs2RNOmTRVeP3jwYNy+fRv//vuvwvhF/d4t7u1t69atKF26NIYOHao079eXv62tLdq0aaMwHx8fH1hZWSnNp6jfE69vY3mf/2bNmuH58+e4evUqAODs2bN4/PgxBg0apNAPsX///rCzs1OYnqrbjyZ+lwE97KD8Nunp6XB0dCxweJ8+ffDTTz/h888/x4QJE+Dv74/u3bujZ8+e0hf3u5QrV06tDoyVK1dWeC6TyVCpUqViP/Xvzp07cHFxUfjAA0C1atWk4a+rUKGC0jTs7OyUjg3nN5/KlSsrLb+C5qOqTZs2ITs7G3Xr1sWNGzek9kaNGmHDhg0IDQ0t1HQB4Pr16wD+7zj8m948O8TMzEzqk5NHlWVTkDt37sDAwACVKlVSaHd2dkapUqU0tm7ylC9fHgEBAUrt9+/fV3h+48YNCCEwceJETJw4Md9pJScno1y5cpDL5Vi4cCGWLVuGW7duKRzXd3BwkP5/584dVKpUSanPkpeXl0rZ8yxduhRVqlSBkZERnJyc4OXlJW1z169fhxBC6bOW583O++p8htVdVx4eHgVO6831aGtrCwBwdXVVapfL5UhNTZWW5cmTJzFp0iRERUXh+fPnCuOnpqZK08pvPoDy9nLz5k306NGjwKzAq+UaGxurtO3nSU5Ofuvr3yU9PR0AlL6j8luGd+7cQaNGjZTaX/+eqVmzptRe1O/d4t7ebt68CS8vr7eeuHD9+nWkpqYW+Jv25vIv6vfElStX8O233+Lw4cNIS0tTGJZXUOdt729+HoyMjJT6jKq6/Wjidxn4gIqd+/fvIzU1VWklvM7c3BzHjx/HkSNH8Mcff2D//v3YtGkTWrdujYMHD8LQ0PCd8ymOswIKuuBcbm6uSpk0oaD5iDc6M78vGzZsAAD4+fnlOzw+Ph4VK1Ys1LTz/npYv349nJ2dlYa/+QVUXOtA1QsNvq91k7dcxowZU+DeibzP18yZMzFx4kR89tlnmDZtGuzt7WFgYIARI0YUyyUQGjZsqHAW5pu5867DlN+yytuDkKcwn2FV19Xbpl3QenzX+r158yb8/f1RtWpVzJs3D66urjAxMcHevXsxf/58peWtqe1FLpfD29sb8+bNy3f4m0Waui5fvgxA+YdTF85e0/b2ljcfR0dH6bvwTW8WEUVZ7ykpKWjRogVsbGwwdepUeHp6wszMDOfOncP48eML9ZlWdfvRxO8y8AEVO+vXrweAAr+k8xgYGMDf3x/+/v6YN28eZs6ciW+++QZHjhxBQECAxq90m7cXIY8QAjdu3FC4HpCdnR1SUlKUXnvnzh2FH3R1srm5ueHPP//Es2fPFP5yytsd6ebmpvK03jWfixcvQi6XK1ThRZnPrVu38Pfff2PIkCFo0aKFwjC5XI5PP/0Uv/76K7799lsABS+XgtrzDtc5Ojrmu8ejMNRdN3K5HNevX5f+MgWApKQkpKSkaGzdqCtvWzM2Nn7nctmyZQtatWqF1atXK7SnpKSgdOnS0nM3NzdcvnwZQgiFZRQXF6ex3J6enhBCwMPDA1WqVNHYdAHdWFe7d+9GVlYWdu3apfDXe1EOI3l6ekrFxtvGuXDhAvz9/YvlCuDr16+HTCZDmzZt3jmum5tbvttMQd8zqnzvFpYmtjdPT0/8888/yM7OLvCyIZ6envjzzz/h5+ensQKwoPV49OhRPH78GNu2bUPz5s2l9tfPPgP+bznfuHEDrVq1ktpzcnJw+/ZtheWrzvbzrt9lVXwQfXYOHz6MadOmwcPDA/379y9wvCdPnii15V2cL+9UuLxruORXfBTGunXrFI5Jb9myBQkJCQoXx/P09MSpU6fw8uVLqW3Pnj1KpzGqk61Dhw7Izc3FkiVLFNrnz58PmUyW78X5CqNDhw5ITExUuFZGTk4OFi9eDCsrK6ViRRV5f8mMGzcOPXv2VHj07t0bLVq0UPhrx9LSMt9lUtDyCgwMhI2NDWbOnIns7Gyl1z169EjtzHnXzVB13QDAggULFNrz/gLq2LGj2vPXBEdHR7Rs2RIrVqxAQkKC0vDXl4uhoaHSX4ybN2+W+vTk6dChAx4+fKhw25Tnz59j5cqVGsvdvXt3GBoaYsqUKUqZhBB4/PhxoaetC+sq7y/b199bamoqIiIiCj3NHj164MKFC9i+fbvSsLz59O7dGw8ePMCqVauUxnnx4gUyMjIKPf/Zs2fj4MGD6NOnT4GHg17XoUMHnD59GlFRUVJbRkYGVq5cCXd3d6Xrd6nyvVtYmtjeevTogf/++0/p+zlvGsCr5Z+bm4tp06YpjZOTk1Oo36iCvhPz28ZevnyJZcuWKYxXv359ODg4YNWqVQp9yjZs2KB0uEzV7UeV32VV6N2enX379uHq1avIyclBUlISDh8+jMjISLi5uWHXrl0wMzMr8LVTp07F8ePH0bFjR7i5uSE5ORnLli1D+fLlpY5vnp6eKFWqFJYvXw5ra2tYWlqiUaNGbz0W/zb29vZo2rQpQkJCkJSUhAULFqBSpUoYNGiQNM7nn3+OLVu2oF27dujduzdu3ryJX375RaHDsLrZOnfujFatWuGbb77B7du3Ubt2bRw8eBA7d+7EiBEjlKZdWIMHD8aKFSswYMAAREdHw93dHVu2bMHJkyexYMECpePxqtiwYQPq1KlT4G7yLl26YOjQoTh37hzq1asHHx8fhIeHY/r06ahUqRIcHR3RunVr1KlTB4aGhpgzZw5SU1NhamoqXaskPDwcn376KerVq4e+ffuiTJkyuHv3Lv744w/4+fnl+yX0Nubm5qhevTo2bdqEKlWqwN7eHjVr1lToR5Cndu3aCA4OxsqVK6Xdx6dPn8batWvRrVs3hb+Y3relS5eiadOm8Pb2xqBBg1CxYkUkJSUhKioK9+/fl66j06lTJ0ydOhUhISFo0qQJLl26hA0bNigdWhw0aBCWLFmCoKAgREdHo2zZsli/fr1GL6rm6emJ6dOnIywsDLdv30a3bt1gbW2NW7duYfv27Rg8eDDGjBlTqGnrwrpq27YtTExM0LlzZ3zxxRdIT0/HqlWr4OjomG9RqoqxY8diy5Yt6NWrFz777DP4+PjgyZMn2LVrF5YvX47atWvj008/xe+//44vv/wSR44cgZ+fH3Jzc3H16lX8/vvv0rVw3iYnJ0e69llmZibu3LmDXbt24eLFi2jVqpXKRe+ECRPw22+/oX379hg2bBjs7e2xdu1a3Lp1C1u3blXq26HK925haWJ7CwoKwrp16zBq1CicPn0azZo1Q0ZGBv7880989dVX6Nq1K1q0aIEvvvgCs2bNQkxMDNq2bQtjY2Ncv34dmzdvxsKFCxU6/quioO/EJk2awM7ODsHBwRg2bBhkMhnWr1+vVMyZmJhg8uTJGDp0KFq3bo3evXvj9u3bWLNmDTw9PRX24Ki6/ajyu6ySIp3LpUPyTgnMe5iYmAhnZ2fRpk0bsXDhQoXTDPO8ecrvoUOHRNeuXYWLi4swMTERLi4u4uOPPxbXrl1TeN3OnTtF9erVhZGRkcKp3i1atBA1atTIN19Bp57/9ttvIiwsTDg6Ogpzc3PRsWNHcefOHaXXz507V5QrV06YmpoKPz8/cfbsWaVpvi3bm6eeC/Hq1MyRI0cKFxcXYWxsLCpXrix++OEH6dTGPABEaGioUqaCTol/U1JSkggJCRGlS5cWJiYmwtvbO9/T41U59Tw6OloAEBMnTixwnNu3byucspqYmCg6duworK2tlU5/XLVqlahYsaIwNDRUOuXyyJEjIjAwUNja2gozMzPh6ekpBgwYIM6ePSuNU9Dps/ldO+fvv/8WPj4+wsTEROE09PzGzc7OFlOmTBEeHh7C2NhYuLq6irCwMIVTvt+2zPLbNvJT0LoVouDLOdy8eVMEBQUJZ2dnYWxsLMqVKyc6deoktmzZIo2TmZkpRo8eLcqWLSvMzc2Fn5+fiIqKyjfXnTt3RJcuXYSFhYUoXbq0GD58uHT6bGGvs5OfrVu3iqZNmwpLS0thaWkpqlatKkJDQ0VcXJw0zts+wwWt66Kuq7zvgs2bN6v03vK2l9dPxd21a5eoVauWMDMzE+7u7mLOnDnS6cuvXxdKne3l8ePHYsiQIaJcuXLCxMRElC9fXgQHBytcW+vly5dizpw5okaNGsLU1FTY2dkJHx8fMWXKFJGamqq8EF+Td9mGvIeFhYVwd3cXPXr0EFu2bFG6dMHb8gvxarvs2bOnKFWqlDAzMxMNGzYUe/bsURhH3e/dN73P7e358+fim2++kbYrZ2dn0bNnT+n6TnlWrlwpfHx8hLm5ubC2thbe3t5i3Lhx4uHDh9I46qz3gr4TT548KRo3bizMzc2Fi4uLGDdunDhw4EC+n9NFixYJNzc3YWpqKho2bChOnjwpfHx8RLt27RTGU2X7UfV3+V1kQmiphykREdF7dPToUbRq1QqbN29We68HFZ5cLkeZMmXQvXv3fA9bvQ8fRJ8dIiIiKn6ZmZlKh7fWrVuHJ0+e5HvLpPdF7/rsEBERkXacOnUKI0eORK9eveDg4IBz585h9erVqFmzpnTvLW1gsUNEREQa4e7uDldXVyxatAhPnjyBvb09goKCMHv2bLUuuKtp7LNDREREeo19doiIiEivsdghIiIivab3fXbkcjkePnwIa2vrYrmkOREREWmeEALPnj2Di4uLWjf9zI/eFzsPHz4s8g3piIiISDvu3buH8uXLF2kael/s5N2O4N69e7CxsdFyGiIiIlJFWloaXF1dC3VboTfpfbGTd+jKxsaGxQ4REVEJo4kuKOygTERERHqNxQ4RERHpNRY7RERElK/Zs2dDJpNhxIgRCu1RUVFo3bo1LC0tYWNjg+bNm+PFixfaCakCve+zQ0REROo7c+YMVqxYgVq1aim0R0VFoV27dggLC8PixYthZGSECxcuFPn08OLEYoeIiIgUpKeno3///li1ahWmT5+uMGzkyJEYNmwYJkyYILV5eXm974hq0d0yjIiIiLQiNDQUHTt2REBAgEJ7cnIy/vnnHzg6OqJJkyZwcnJCixYtcOLECS0lVQ2LHSIiIpJs3LgR586dw6xZs5SGxcfHAwAmT56MQYMGYf/+/ahXrx78/f1x/fr19x1VZSx2iIiICMCrC/AOHz4cGzZsgJmZmdJwuVwOAPjiiy8QEhKCunXrYv78+fDy8sLPP//8vuOqjMUOERERAQCio6ORnJyMevXqwcjICEZGRjh27BgWLVoEIyMjODk5AQCqV6+u8Lpq1arh7t272oisEnZQJiIiIgCAv78/Ll26pNAWEhKCqlWrYvz48ahYsSJcXFwQFxenMM61a9fQvn379xlVLSx2iIiICMCr+0nWrFlToc3S0hIODg5S+9ixYzFp0iTUrl0bderUwdq1a3H16lVs2bJFG5FVwmKHiIiIVDZixAhkZmZi5MiRePLkCWrXro3IyEh4enpqO1qBZEIIoe0QxSktLQ22trZITU3ljUCJiIhKCE3+frODMhEREek1HsYiIiLSE1FRUdK1cLStYsWK8PX11XYMACx2iIiI9EJUVBSa+jWBXEc6pxjIgBMn/9aJgofFDhERkR6Ij4+HXAC/fGSOamW020sl9pEcn2x/gfj4eBY7REREpFnVyhigXllDbcfQKeygTERERHqNxQ4RERHpNRY7REREpNdY7BAREZFeY7FDREREeo3FDhEREek1FjtERESk11jsEBERkV5jsUNERER6jcUOERER6TUWO0RERKTXWOwQERGRXmOxQ0RERHqNxQ4RERHpNRY7REREpNdY7BAREZFeY7FDREREeo3FDhEREek1FjtERESk11jsEBERkV5jsUNERER6jcUOERER6TUWO0RERKTXWOwQERGRXmOxQ0RERHqNxQ4RERHpNRY7REREpNdY7BAREZFeY7FDREREeo3FDhEREek1FjtERESk11jsEBERkV5jsUNERER6jcUOERER6TUWO0RERKTXWOwQERGRXmOxQ0RERHqNxQ4RERHpNZ0pdmbPng2ZTIYRI0ZIbZmZmQgNDYWDgwOsrKzQo0cPJCUlaS8kERERlTg6UeycOXMGK1asQK1atRTaR44cid27d2Pz5s04duwYHj58iO7du2spJREREZVEWi920tPT0b9/f6xatQp2dnZSe2pqKlavXo158+ahdevW8PHxQUREBP7++2+cOnVKi4mJiIioJNF6sRMaGoqOHTsiICBAoT06OhrZ2dkK7VWrVkWFChUQFRX1vmMSERFRCWWkzZlv3LgR586dw5kzZ5SGJSYmwsTEBKVKlVJod3JyQmJiYoHTzMrKQlZWlvQ8LS1NY3mJiIio5NHanp179+5h+PDh2LBhA8zMzDQ23VmzZsHW1lZ6uLq6amzaREREVPJordiJjo5GcnIy6tWrByMjIxgZGeHYsWNYtGgRjIyM4OTkhJcvXyIlJUXhdUlJSXB2di5wumFhYUhNTZUe9+7dK+Z3QkRERLpMa4ex/P39cenSJYW2kJAQVK1aFePHj4erqyuMjY1x6NAh9OjRAwAQFxeHu3fvwtfXt8DpmpqawtTUtFizExERUcmhtWLH2toaNWvWVGiztLSEg4OD1D5w4ECMGjUK9vb2sLGxwdChQ+Hr64vGjRtrIzIRERGVQFrtoPwu8+fPh4GBAXr06IGsrCwEBgZi2bJl2o5FREREJYhOFTtHjx5VeG5mZoalS5di6dKl2glEREREJZ7Wr7NDREREVJxY7BAREZFeY7FDREREeo3FDhEREek1FjtERESk11jsEBERkV5jsUNERER6jcUOERER6TUWO0RERKTXWOwQERGRXmOxQ0RERHqNxQ4RERHpNRY7REREpNdY7BAREZFeY7FDREREeo3FDhEREek1FjtERESk11jsEBERkV5jsUNERER6jcUOERER6TUWO0RERKTXilzspKWlYceOHYiNjdVEHiIiIiKNUrvY6d27N5YsWQIAePHiBerXr4/evXujVq1a2Lp1q8YDEhERERWF2sXO8ePH0axZMwDA9u3bIYRASkoKFi1ahOnTp2s8IBEREVFRqF3spKamwt7eHgCwf/9+9OjRAxYWFujYsSOuX7+u8YBERERERaF2sePq6oqoqChkZGRg//79aNu2LQDg6dOnMDMz03hAIiIioqIwUvcFI0aMQP/+/WFlZQU3Nze0bNkSwKvDW97e3prOR0RERFQkahc7X331FRo2bIh79+6hTZs2MDB4tXOoYsWK7LNDREREOkftYgcA6tevj/r16yu0dezYUSOBiIiIiDRJpWJn1KhRKk9w3rx5hQ5DREREpGkqFTvnz59XeH7u3Dnk5OTAy8sLAHDt2jUYGhrCx8dH8wmJiIiIikClYufIkSPS/+fNmwdra2usXbsWdnZ2AF6diRUSEiJdf4eIiIhIV6h96vncuXMxa9YsqdABADs7O0yfPh1z587VaDgiIiKiolK72ElLS8OjR4+U2h89eoRnz55pJBQRERGRpqhd7Hz00UcICQnBtm3bcP/+fdy/fx9bt27FwIED0b179+LISERERFRoap96vnz5cowZMwb9+vVDdnb2q4kYGWHgwIH44YcfNB6QiIiIqCjULnYsLCywbNky/PDDD7h58yYAwNPTE5aWlhoPR0RERFRUhbqoIABYWlqiVq1amsxCREREpHGFKnbOnj2L33//HXfv3sXLly8Vhm3btk0jwYiIiIg0Qe0Oyhs3bkSTJk0QGxuL7du3Izs7G1euXMHhw4dha2tbHBmJiIiICk3tYmfmzJmYP38+du/eDRMTEyxcuBBXr15F7969UaFCheLISERERFRoahc7N2/elG76aWJigoyMDMhkMowcORIrV67UeEAiIiKiolC72LGzs5MuHliuXDlcvnwZAJCSkoLnz59rNh0RERFREandQbl58+aIjIyEt7c3evXqheHDh+Pw4cOIjIyEv79/cWQkIiIiKjS1i50lS5YgMzMTAPDNN9/A2NgYf//9N3r06IFvv/1W4wGJiIiIikLtYsfe3l76v4GBASZMmKDRQERERESapHafHeBVJ+Vvv/0WH3/8MZKTkwEA+/btw5UrVzQajoiIiKio1C52jh07Bm9vb/zzzz/Ytm0b0tPTAQAXLlzApEmTNB6QiIiIqCjULnYmTJiA6dOnIzIyEiYmJlJ769atcerUKY2GIyIiIioqtYudS5cu4aOPPlJqd3R0xH///aeRUERERESaonaxU6pUKSQkJCi1nz9/HuXKldNIKCIiIiJNUbvY6du3L8aPH4/ExETIZDLI5XKcPHkSY8aMQVBQUHFkJCIiIiq0Qt0bq2rVqnB1dUV6ejqqV6+O5s2bo0mTJrzODhEREekcta+zY2JiglWrVmHixIm4fPky0tPTUbduXVSuXLk48hEREREVidrFTp4KFSrwLudERESk81QudkaNGqXSePPmzSt0GCIiIiJNU7nYOX/+vMLzEydOwMfHB+bm5lKbTCbTXDIiIiIiDVC52Dly5IjCc2tra/z666+oWLGixkMRERERaUqh7o1FREREVFKw2CEiIiK9xmKHiIiI9JrKfXYuXryo8FwIgatXr0p3Pc9Tq1YtzSQjIiIi0gCVi506depAJpNBCCG1derUCQCkdplMhtzcXM2nJCIiIioklYudW7duFWcOIiIiomKhcrHj5uZWnDmIiIiIigU7KBMREZFe02qxEx4ejlq1asHGxgY2Njbw9fXFvn37pOGZmZkIDQ2Fg4MDrKys0KNHDyQlJWkxMREREZU0Wi12ypcvj9mzZyM6Ohpnz55F69at0bVrV1y5cgUAMHLkSOzevRubN2/GsWPH8PDhQ3Tv3l2bkYmIiKiEKfRdzzWhc+fOCs9nzJiB8PBwnDp1CuXLl8fq1avx66+/onXr1gCAiIgIVKtWDadOnULjxo21EZmIiIhKGJ3ps5Obm4uNGzciIyMDvr6+iI6ORnZ2NgICAqRxqlatigoVKiAqKqrA6WRlZSEtLU3hQURERB8utYudpKQkfPrpp3BxcYGRkREMDQ0VHuq6dOkSrKysYGpqii+//BLbt29H9erVkZiYCBMTE5QqVUphfCcnJyQmJhY4vVmzZsHW1lZ6uLq6qp2JiIiI9Ifah7EGDBiAu3fvYuLEiShbtixkMlmRAnh5eSEmJgapqanYsmULgoODcezYsUJPLywsDKNGjZKep6WlseAhIiL6gKld7Jw4cQJ//fUX6tSpo5EAJiYmqFSpEgDAx8cHZ86cwcKFC9GnTx+8fPkSKSkpCnt3kpKS4OzsXOD0TE1NYWpqqpFsREREVPKpfRjL1dVV4ZYRmiaXy5GVlQUfHx8YGxvj0KFD0rC4uDjcvXsXvr6+xTZ/IiIi0i9q79lZsGABJkyYgBUrVsDd3b1IMw8LC0P79u1RoUIFPHv2DL/++iuOHj2KAwcOwNbWFgMHDsSoUaNgb28PGxsbDB06FL6+vjwTi4iIiFSmdrHTp08fPH/+HJ6enrCwsICxsbHC8CdPnqg8reTkZAQFBSEhIQG2traoVasWDhw4gDZt2gAA5s+fDwMDA/To0QNZWVkIDAzEsmXL1I1MREREH7BC7dnRlNWrV791uJmZGZYuXYqlS5dqbJ5ERET0YVG72AkODi6OHERERETFolBXUM7NzcWOHTsQGxsLAKhRowa6dOlSqOvsEBERERUntYudGzduoEOHDnjw4AG8vLwAvLqQn6urK/744w94enpqPCQRERFRYal96vmwYcPg6emJe/fu4dy5czh37hzu3r0LDw8PDBs2rDgyEhERERWa2nt2jh07hlOnTsHe3l5qc3BwwOzZs+Hn56fRcERERERFpfaeHVNTUzx79kypPT09HSYmJhoJRURERKQpahc7nTp1wuDBg/HPP/9ACAEhBE6dOoUvv/wSXbp0KY6MRERERIWmdrGzaNEieHp6wtfXF2ZmZjAzM4Ofnx8qVaqEhQsXFkdGIiIiokJTu89OqVKlsHPnTly/fh1Xr14FAFSrVk26mScRERGRLinUdXYAoHLlyqhcubImsxARERFpnErFzqhRozBt2jRYWlpi1KhRbx133rx5GglGREREpAkqFTvnz59Hdna29H8iIiKikkKlYufIkSP5/p+IiIhI16l9NtZnn32W73V2MjIy8Nlnn2kkFBEREZGmqF3srF27Fi9evFBqf/HiBdatW6eRUERERESaovLZWGlpadJFBJ89ewYzMzNpWG5uLvbu3QtHR8diCUlERERUWCoXO6VKlYJMJoNMJkOVKlWUhstkMkyZMkWj4YiIiIiKSuVi58iRIxBCoHXr1ti6davCjUBNTEzg5uYGFxeXYglJREREVFgqFzstWrQAANy6dQuurq4wMFC7uw8RERHRe6f2FZTd3NyQkpKC06dPIzk5GXK5XGF4UFCQxsIRERERFZXaxc7u3bvRv39/pKenw8bGBjKZTBomk8lY7BAREZFOUftY1OjRo/HZZ58hPT0dKSkpePr0qfR48uRJcWQkIiIiKjS1i50HDx5g2LBhsLCwKI48RERERBqldrETGBiIs2fPFkcWIiIiIo1Tu89Ox44dMXbsWPz777/w9vaGsbGxwvAuXbpoLBwRERFRUald7AwaNAgAMHXqVKVhMpkMubm5RU9FREREpCFqFztvnmpOREREpMuKdGXAzMxMTeUgIiIiKhZqFzu5ubmYNm0aypUrBysrK8THxwMAJk6ciNWrV2s8IBEREVFRqF3szJgxA2vWrMH3338PExMTqb1mzZr46aefNBqOiIiIqKjULnbWrVuHlStXon///jA0NJTaa9eujatXr2o0HBEREVFRFeqigpUqVVJql8vlyM7O1kgoIiIiIk1Ru9ipXr06/vrrL6X2LVu2oG7duhoJRURERKQpap96/t133yE4OBgPHjyAXC7Htm3bEBcXh3Xr1mHPnj3FkZGIiIio0NTes9O1a1fs3r0bf/75JywtLfHdd98hNjYWu3fvRps2bYojIxEREVGhqb1nBwCaNWuGyMhITWchIiIi0ji19+xUrFgRjx8/VmpPSUlBxYoVNRKKiIiISFPULnZu376d7/2vsrKy8ODBA42EIiIiItIUlQ9j7dq1S/r/gQMHYGtrKz3Pzc3FoUOH4O7urtFwREREREWlcrHTrVs36f/BwcEKw4yNjeHu7o65c+dqLBgRERGRJqhc7OTd7dzDwwNnzpxB6dKliy0UERERkaao3WdnypQpsLa2Vmp/+fIl1q1bp5FQRERERJqidrETEhKC1NRUpfZnz54hJCREI6GIiIiINEXtYkcIAZlMptR+//59hU7LRERERLpA5T47devWhUwmg0wmg7+/P4yM/u+lubm5uHXrFtq1a1csIYmIiIgKS+2zsWJiYhAYGAgrKytpmImJCdzd3dGjRw+NByQiIiIqCpWLnUmTJgEA3N3d0adPH5iZmSmNc/nyZdSsWVNz6YiIiIiKSO0+O8HBwQqFzrNnz7By5Uo0bNgQtWvX1mg4IiIioqJSu9jJc/z4cQQHB6Ns2bL48ccf0bp1a5w6dUqT2YiIiIiKTK27nicmJmLNmjVYvXo10tLS0Lt3b2RlZWHHjh2oXr16cWUkIiIiKjSV9+x07twZXl5euHjxIhYsWICHDx9i8eLFxZmNiIiIqMhU3rOzb98+DBs2DP/73/9QuXLl4sxEREREpDEq79k5ceIEnj17Bh8fHzRq1AhLlizBf//9V5zZiIiIiIpM5WKncePGWLVqFRISEvDFF19g48aNcHFxgVwuR2RkJJ49e1acOYmIiIgKRe2zsSwtLfHZZ5/hxIkTuHTpEkaPHo3Zs2fD0dERXbp0KY6MRERERIVW6FPPAcDLywvff/897t+/j99++01TmYiIiIg0pkjFTh5DQ0N069YNu3bt0sTkiIiIiDRGI8UOERERka5isUNERER6jcUOERER6TWVip169erh6dOnAICpU6fi+fPnxRqKiIiISFNUKnZiY2ORkZEBAJgyZQrS09OLNRQRERGRpqh0u4g6deogJCQETZs2hRACP/74I6ysrPId97vvvtNoQCIiIqKiUKnYWbNmDSZNmoQ9e/ZAJpNh3759MDJSfqlMJmOxQ0RERDpFpWLHy8sLGzduBAAYGBjg0KFDcHR0LNZgRERERJqg9tlYcrlcY4XOrFmz0KBBA1hbW8PR0RHdunVDXFycwjiZmZkIDQ2Fg4MDrKys0KNHDyQlJWlk/kRERKT/CnXq+c2bNzF06FAEBAQgICAAw4YNw82bN9WezrFjxxAaGopTp04hMjIS2dnZaNu2rdQZGgBGjhyJ3bt3Y/PmzTh27BgePnyI7t27FyY2ERERfYBUOoz1ugMHDqBLly6oU6cO/Pz8AAAnT55EjRo1sHv3brRp00blae3fv1/h+Zo1a+Do6Ijo6Gg0b94cqampWL16NX799Ve0bt0aABAREYFq1arh1KlTaNy4sbrxiYiI6AOjdrEzYcIEjBw5ErNnz1ZqHz9+vFrFzptSU1MBAPb29gCA6OhoZGdnIyAgQBqnatWqqFChAqKioljsEBER0TupfRgrNjYWAwcOVGr/7LPP8O+//xY6iFwux4gRI+Dn54eaNWsCABITE2FiYoJSpUopjOvk5ITExMR8p5OVlYW0tDSFBxEREX241C52ypQpg5iYGKX2mJiYInVcDg0NxeXLl6Wzvgpr1qxZsLW1lR6urq5Fmh4RERGVbGofxho0aBAGDx6M+Ph4NGnSBMCrPjtz5szBqFGjChViyJAh2LNnD44fP47y5ctL7c7Oznj58iVSUlIU9u4kJSXB2dk532mFhYUp5EhLS2PBQ0RE9AFTu9iZOHEirK2tMXfuXISFhQEAXFxcMHnyZAwbNkytaQkhMHToUGzfvh1Hjx6Fh4eHwnAfHx8YGxvj0KFD6NGjBwAgLi4Od+/eha+vb77TNDU1hampqbpvi4iIiPSU2sWOTCbDyJEjMXLkSDx79gwAYG1tXaiZh4aG4tdff8XOnTthbW0t9cOxtbWFubk5bG1tMXDgQIwaNQr29vawsbHB0KFD4evry87JREREpBK1i53XFbbIyRMeHg4AaNmypUJ7REQEBgwYAACYP38+DAwM0KNHD2RlZSEwMBDLli0r0nyJiIjow1GkYqeohBDvHMfMzAxLly7F0qVL30MiIiIi0jeFuoIyERERUUnBYoeIiIj0mlrFTnZ2Nvz9/XH9+vXiykNERESkUWoVO8bGxrh48WJxZSEiIiLSOLUPY33yySdYvXp1cWQhIiIi0ji1z8bKycnBzz//jD///BM+Pj6wtLRUGD5v3jyNhSMiIiIqKrWLncuXL6NevXoAgGvXrikMk8lkmklFREREpCFqFztHjhwpjhxERERExaLQp57fuHEDBw4cwIsXLwCodoFAIiIiovdN7WLn8ePH8Pf3R5UqVdChQwckJCQAAAYOHIjRo0drPCARERFRUahd7IwcORLGxsa4e/cuLCwspPY+ffpg//79Gg1HREREVFRq99k5ePAgDhw4gPLlyyu0V65cGXfu3NFYMCIiIiJNUHvPTkZGhsIenTxPnjyBqampRkIRERERaYraxU6zZs2wbt066blMJoNcLsf333+PVq1aaTQcERERUVGpfRjr+++/h7+/P86ePYuXL19i3LhxuHLlCp48eYKTJ08WR0YiIiKiQlN7z07NmjVx7do1NG3aFF27dkVGRga6d++O8+fPw9PTszgyEhERERWa2nt2AMDW1hbffPONprMQERERaVyhip2nT59i9erViI2NBQBUr14dISEhsLe312g4IiIioqJS+zDW8ePH4e7ujkWLFuHp06d4+vQpFi1aBA8PDxw/frw4MhIREREVmtp7dkJDQ9GnTx+Eh4fD0NAQAJCbm4uvvvoKoaGhuHTpksZDEhERERWW2nt2bty4gdGjR0uFDgAYGhpi1KhRuHHjhkbDERERERWV2sVOvXr1pL46r4uNjUXt2rU1EoqIiIhIU1Q6jHXx4kXp/8OGDcPw4cNx48YNNG7cGABw6tQpLF26FLNnzy6elERERESFpFKxU6dOHchkMgghpLZx48YpjdevXz/06dNHc+mIiIiIikilYufWrVvFnYOIiIioWKhU7Li5uRV3DiIiIqJiUaiLCj58+BAnTpxAcnIy5HK5wrBhw4ZpJBgRERGRJqhd7KxZswZffPEFTExM4ODgAJlMJg2TyWQsdoiIiEinqF3sTJw4Ed999x3CwsJgYKD2metERERE75Xa1crz58/Rt29fFjpERERUIqhdsQwcOBCbN28ujixEREREGqf2YaxZs2ahU6dO2L9/P7y9vWFsbKwwfN68eRoLR0RERFRUhSp2Dhw4AC8vLwBQ6qBMREREpEvULnbmzp2Ln3/+GQMGDCiGOERERESapXafHVNTU/j5+RVHFiIiIiKNU7vYGT58OBYvXlwcWYiIiIg0Tu3DWKdPn8bhw4exZ88e1KhRQ6mD8rZt2zQWjoiIiKio1C52SpUqhe7duxdHFiIiIiKNU7vYiYiIKI4cRERERMWCl0EmIiIivab2nh0PD4+3Xk8nPj6+SIGIiIiINEntYmfEiBEKz7Ozs3H+/Hns378fY8eO1VQuIiIiIo1Qu9gZPnx4vu1Lly7F2bNnixyIiIiISJM01menffv22Lp1q6YmR0RERKQRGit2tmzZAnt7e01NjoiIiEgj1D6MVbduXYUOykIIJCYm4tGjR1i2bJlGwxEREREVldrFTrdu3RSeGxgYoEyZMmjZsiWqVq2qqVxEREREGqF2sTNp0qTiyEFERERULHhRQSIiItJrKu/ZMTAweOvFBAFAJpMhJyenyKGIiIiINEXlYmf79u0FDouKisKiRYsgl8s1EoqIiIhIU1Qudrp27arUFhcXhwkTJmD37t3o378/pk6dqtFwREREREVVqD47Dx8+xKBBg+Dt7Y2cnBzExMRg7dq1cHNz03Q+IiIioiJRq9hJTU3F+PHjUalSJVy5cgWHDh3C7t27UbNmzeLKR0RERFQkKh/G+v777zFnzhw4Ozvjt99+y/ewFhEREZGuUbnYmTBhAszNzVGpUiWsXbsWa9euzXe8bdu2aSwcERERUVGpXOwEBQW989RzIiIiIl2jcrGzZs2aYoxBREREVDx4BWUiIiLSayx2iIiISK+x2CEiIiK9xmKHiIiI9BqLHSIiItJrLHaIiIhIr7HYISIiIr3GYoeIiIj0mlaLnePHj6Nz585wcXGBTCbDjh07FIYLIfDdd9+hbNmyMDc3R0BAAK5fv66dsERERFQiabXYycjIQO3atbF06dJ8h3///fdYtGgRli9fjn/++QeWlpYIDAxEZmbme05KREREJZXKt4soDu3bt0f79u3zHSaEwIIFC/Dtt99Kd1hft24dnJycsGPHDvTt2/d9RiUiIqISSmf77Ny6dQuJiYkICAiQ2mxtbdGoUSNERUUV+LqsrCykpaUpPIiIiOjDpbPFTmJiIgDAyclJod3JyUkalp9Zs2bB1tZWeri6uhZrTiIiItJtOlvsFFZYWBhSU1Olx71797QdiYiIiLRIZ4sdZ2dnAEBSUpJCe1JSkjQsP6amprCxsVF4EBER0YdLZ4sdDw8PODs749ChQ1JbWloa/vnnH/j6+moxGREREZUkWj0bKz09HTdu3JCe37p1CzExMbC3t0eFChUwYsQITJ8+HZUrV4aHhwcmTpwIFxcXdOvWTXuhiYiIqETRarFz9uxZtGrVSno+atQoAEBwcDDWrFmDcePGISMjA4MHD0ZKSgqaNm2K/fv3w8zMTFuRiYiIqITRarHTsmVLCCEKHC6TyTB16lRMnTr1PaYiIiIifaKzfXaIiIiINIHFDhEREek1FjtERESk11jsEBERkV5jsUNERER6jcUOERER6TUWO0RERKTXWOwQERGRXmOxQ0RERHqNxQ4RERHpNRY7REREpNdY7BARfaAePHiATz75BA4ODjA3N4e3tzfOnj2r7VhaxWWin7R6I1AiItKOp0+fws/PD61atcK+fftQpkwZXL9+HXZ2dtqOpjVcJvqLxQ4R0Qdozpw5cHV1RUREhNTm4eGhxUTax2Wiv3gYi4joA7Rr1y7Ur18fvXr1gqOjI+rWrYtVq1ZpO5ZWcZnoLxY7REQfoPj4eISHh6Ny5co4cOAA/ve//2HYsGFYu3attqNpDZeJ/uJhLCKiD5BcLkf9+vUxc+ZMAEDdunVx+fJlLF++HMHBwVpOpx1cJvqLe3aIiD5AZcuWRfXq1RXaqlWrhrt372opkfZxmegvFjtERB8gPz8/xMXFKbRdu3YNbm5uWkqkfVwm+ovFDhHRB2jkyJE4deoUZs6ciRs3buDXX3/FypUrERoaqu1oWsNlor9Y7BARfYAaNGiA7du347fffkPNmjUxbdo0LFiwAP3799d2NK3hMtFf7KBMRPSB6tSpEzp16qTtGDqFy0Q/cc8OERER6TXu2SEiKgGioqIQHx+v7RioWLEifH19tR0DAJcJqY7FDhGRjouKikJTvyaQC20nAQxkwImTf2v9x53LhNTBYoeISMfFx8dDLoBfPjJHtTLa630Q+0iOT7a/QHx8vNZ/2LlMSB0sdoiISohqZQxQr6yhtmPolA9lmcyePRthYWEYPnw4FixYoO04JQ47KBMREemwM2fOYMWKFahVq5a2o5RYLHaIiIh0VHp6Ovr3749Vq1bBzs5O23FKLBY7REREOio0NBQdO3ZEQECAtqOUaOyzQ0REpIM2btyIc+fO4cyZM9qOUuKx2CEiItIx9+7dw/DhwxEZGQkzMzNtxynxWOwQERHpmOjoaCQnJ6NevXpSW25uLo4fP44lS5YgKysLhob6fxaaprDYISIi0jH+/v64dOmSQltISAiqVq2K8ePHs9BREzsoExG9R+Hh4ahVqxZsbGxgY2MDX19f7Nu3T9uxSMdYW1ujZs2aCg9LS0s4ODigZs2a2o5X4rDYISJ6j8qXL4/Zs2cjOjoaZ8+eRevWrdG1a1dcuXJF29GI9BYPYxERvUedO3dWeD5jxgyEh4fj1KlTqFGjhpZSUUlw9OhRbUcosVjsEBFpSW5uLjZv3oyMjAzeV4moGLHYISJ6zy5dugRfX19kZmbCysoK27dvR/Xq1bUdi4rg5MmT2o6gExl0FYsdIqL3zMvLCzExMUhNTcWWLVsQHByMY8eOseApgRLS5TCQvep4Hh4eru04VAAWO0RE75mJiQkqVaoEAPDx8cGZM2ewcOFCrFixQsvJSF0pmQJyAfzykTmqldHuOT97r+dg4pEsrWbQVSx2iIi0TC6XIyuLP1IlWbUyBqhXVrvXvon9L1er89dlPPWciPTerFmz0KBBA1hbW8PR0RHdunVDXFycVrKEhYXh+PHjuH37Ni5duoSwsDAcPXoU/fv310oeXaBL64f0E4sdItJ7x44dQ2hoKE6dOoXIyEhkZ2ejbdu2yMjIeO9ZkpOTERQUBC8vL/j7++PMmTM4cOAA2rRp896z6ApdWj+kn3gYi4j03v79+xWer1mzBo6OjoiOjkbz5s3fa5bVq1e/1/mVBLq0fkg/cc8OEX1wUlNTAQD29vZaTkL54fohTeOeHSL6oMjlcowYMQJ+fn7vvMdQVFQU4uPj31Oygn1I109RZ/0QqYrFDhF9UEJDQ3H58mWcOHHireNFRUWhqV8TyMV7CkYAVF8/ROpgsUNEH4whQ4Zgz549OH78OMqXL//WcePj43n9lPdMnfVDpA4WO0Qacvz4cfzwww+Ijo5GQkICtm/fjm7dun2wOXQpixACQ4cOxfbt23H06FF4eHio/FpeP6X4FWX9EKmCHZSJNCQjIwO1a9fG0qVLmUPHsoSGhuKXX37Br7/+CmtrayQmJiIxMREvXrzQai56heuHihv37BBpSPv27dG+fXttx9CZHIDuZMm7Z1HLli0V2iMiIjBgwID3H4gUcP1QcWOxQ0R6Twj2MtZlXD9U3FjsEJFO4eneuk8Xlo0uZKCSg8UOEekMnu6t2xLS5TCQvTrslHfoiagkYLFDRDqDp3vrtpRMwfVDJRKLHSLSOTzdW7dx/VBJw2KHSEPS09Nx48YN6fmtW7cQExMDe3t7VKhQ4YPLoWtZiOjDxWKHSEPOnj2LVq1aSc9HjRoFAAgODsaaNWs+uBy6loWIPlwsdog0pGXLljpxCq2u5AB0KwsRfbh4BWUiIiLSa9yzQx8kXbmWS0ZGBiwtLbUdA4BuZOG1U4ioOLDYoQ+OLl3LxUAGncgB6FYWIiJNYrFDHxxduZZL3nVCtJ1Dl7Lw2ilEVBxY7NAHS9vXCsm7Toi2c+hSFl47hYiKQ4nooLx06VK4u7vDzMwMjRo1wunTp7UdiYiIiEoInS92Nm3ahFGjRmHSpEk4d+4cateujcDAQCQnJ2s7GhEREZUAOl/szJs3D4MGDUJISAiqV6+O5cuXw8LCAj///LO2oxEREVEJoNPFzsuXLxEdHY2AgACpzcDAAAEBAYiKitJiMiIiIiopdLqD8n///Yfc3Fw4OTkptDs5OeHq1av5viYrKwtZWf93NkdqaioAIC0trfiCUony/PlzAED0w1ykv9Teudaxj+Q6kUOXsuhKDmbR7Ry6lEVXcuhalrj/XmV5/vx5oX9/816nkauwCx324MEDAUD8/fffCu1jx44VDRs2zPc1kyZNEgD44IMPPvjggw89eNy7d6/I9YRO79kpXbo0DA0NkZSUpNCelJQEZ2fnfF8TFhYm3WwQAFJSUuDm5oa7d+/C1ta2WPMWh7S0NLi6uuLevXuwsbHRdhy1Mb/2lOTsAPNrG/NrV0nPrwlCCDx79gwuLi5FnpZOFzsmJibw8fHBoUOH0K1bNwCAXC7HoUOHMGTIkHxfY2pqClNTU6V2W1vbEr3B2NjYML8WleT8JTk7wPzaxvzaVdLzF5WmdlLodLEDAKNGjUJwcDDq16+Phg0bYsGCBcjIyEBISIi2oxEREVEJoPPFTp8+ffDo0SN89913SExMRJ06dbB//36lTstERERE+dH5YgcAhgwZUuBhq3cxNTXFpEmT8j20VRIwv3aV5PwlOTvA/NrG/NpV0vPrGpkQmjini4iIiEg36fRFBYmIiIiKisUOERER6TUWO0RERKTXWOwQERGRXtObYmfGjBlo0qQJLCwsUKpUqXzHuXv3Ljp27AgLCws4Ojpi7NixyMnJURjn6NGjqFevHkxNTVGpUiWsWbOm+MMX4Ny5c2jTpg1KlSoFBwcHDB48GOnp6QrjqPKetOHatWvo2rUrSpcuDRsbGzRt2hRHjhxRGEdXsx89ehQymSzfx5kzZ6TxLl68iGbNmsHMzAyurq74/vvvtZha2R9//IFGjRrB3NwcdnZ20oU58+jq8gcAd3d3pWU/e/ZshXF0ffkDr+7VV6dOHchkMsTExCgM0+X8Xbp0QYUKFWBmZoayZcvi008/xcOHDxXG0dX8t2/fxsCBA+Hh4QFzc3N4enpi0qRJePnypcJ4upof0NzvGb2myDec0BHfffedmDdvnhg1apSwtbVVGp6TkyNq1qwpAgICxPnz58XevXtF6dKlRVhYmDROfHy8sLCwEKNGjRL//vuvWLx4sTA0NBT79+9/j+/klQcPHgg7Ozvx5ZdfiqtXr4rTp0+LJk2aiB49eqj1nrSlcuXKokOHDuLChQvi2rVr4quvvhIWFhYiISFBCKHb2bOyskRCQoLC4/PPPxceHh5CLpcLIYRITU0VTk5Oon///uLy5cvit99+E+bm5mLFihVaTv/Kli1bhJ2dnQgPDxdxcXHiypUrYtOmTdJwXV7+Qgjh5uYmpk6dqrAO0tPTpeG6vvzzDBs2TLRv314AEOfPn5fadT3/vHnzRFRUlLh9+7Y4efKk8PX1Fb6+vtJwXc6/b98+MWDAAHHgwAFx8+ZNsXPnTuHo6ChGjx4tjaPL+YXQzO8ZKdKbYidPREREvhvH3r17hYGBgUhMTJTawsPDhY2NjcjKyhJCCDFu3DhRo0YNhdf16dNHBAYGFmvm/KxYsUI4OjqK3Nxcqe3ixYsCgLh+/boQQrX3pA2PHj0SAMTx48eltrS0NAFAREZGCiF0N3t+Xr58KcqUKSOmTp0qtS1btkzY2dkpZB0/frzw8vLSRkQF2dnZoly5cuKnn34qcBxdX/5ubm5i/vz5BQ7X5eWfZ+/evaJq1ariypUrSsVOScj/up07dwqZTCZevnwphCh5+b///nvh4eEhPS8p+Yvye0aK9OYw1rtERUXB29tb4crLgYGBSEtLw5UrV6RxAgICFF4XGBiIqKio95oVeLX728TEBAYG/7eKzM3NAQAnTpwAoNp70gYHBwd4eXlh3bp1yMjIQE5ODlasWAFHR0f4+PgA0N3s+dm1axceP36scIuSqKgoNG/eHCYmJlJbYGAg4uLi8PTpU23ElJw7dw4PHjyAgYEB6tati7Jly6J9+/a4fPmyNE5JWP6zZ8+Gg4MD6tatix9++EFhF70uL3/g1c2KBw0ahPXr18PCwkJpuK7nf92TJ0+wYcMGNGnSBMbGxgBKVn4ASE1Nhb29vfS8pOV/U0n4/OqaD6bYSUxMVLrFRN7zxMTEt46TlpaGFy9evJ+g/1/r1q2RmJiIH374AS9fvsTTp08xYcIEAEBCQsJb8+YN0xaZTIY///wT58+fh7W1NczMzDBv3jzs378fdnZ2Uj5dzJ6f1atXIzAwEOXLl5fadDl/fHw8AGDy5Mn49ttvsWfPHtjZ2aFly5Z48uQJAN3ODwDDhg3Dxo0bceTIEXzxxReYOXMmxo0bJw3X5fxCCAwYMABffvkl6tevn+84upw/z/jx42FpaQkHBwfcvXsXO3fulIaVhPx5bty4gcWLF+OLL76Q2kpS/vyU9PzaoNPFzoQJEwrsKJr3uHr1qrZjqkXV91SjRg2sXbsWc+fOhYWFBZydneHh4QEnJyeFvT26mF0IgdDQUDg6OuKvv/7C6dOn0a1bN3Tu3Fkq1HQ5/+vu37+PAwcOYODAgVpK/X9UzS+XywEA33zzDXr06AEfHx9ERERAJpNh8+bNOp8feHUD4JYtW6JWrVr48ssvMXfuXCxevBhZWVk6n3/x4sV49uwZwsLCtJY1P+pu/2PHjsX58+dx8OBBGBoaIigoCEKLF9wvzOf3wYMHaNeuHXr16oVBgwZpKfkr+vh7VpLo9L2xRo8ejQEDBrx1nIoVK6o0LWdnZ5w+fVqhLSkpSRqW929e2+vj2NjYSIeQikqd99SvXz/069cPSUlJsLS0hEwmw7x586ThqrwnTVI1++HDh7Fnzx48ffoUNjY2AIBly5YhMjISa9euxYQJE957dnXyvy4iIgIODg7o0qWLQntB20resOKgav68grJ69epSu6mpKSpWrIi7d+9KGUvC8s/TqFEj5OTk4Pbt2/Dy8tLp5X/48GFERUUp3dOofv366N+/P9auXavT+fOULl0apUuXRpUqVVCtWjW4urri1KlT8PX1LRH5Hz58iFatWqFJkyZYuXKlwnglIf/baOPzW+Jpuc+Qxr2rQ1dSUpLUtmLFCmFjYyMyMzOFEK86KNesWVPhdR9//LFWOijnZ/Xq1cLCwkI8ffpUCKHae9KGXbt2CQMDA/Hs2TOF9ipVqogZM2YIIXQ3++vkcrnw8PBQOIsjT14Hx7wOm0IIERYWphMdHFNTU4WpqalCB+WXL18KR0dH6WyTkrD8X/fLL78IAwMD8eTJEyGEbi//O3fuiEuXLkmPAwcOCABiy5Yt4t69e0II3c6fnzt37ggA4siRI0II3c9///59UblyZdG3b1+Rk5OjNFzX8+cpyu8ZKdKbYufOnTvi/PnzYsqUKcLKykqcP39enD9/XvrBzTtVr23btiImJkbs379flClTJt9Tz8eOHStiY2PF0qVLtXbquRBCLF68WERHR4u4uDixZMkSYW5uLhYuXCgNV+U9acOjR4+Eg4OD6N69u4iJiRFxcXFizJgxwtjYWMTExOh09tf9+eefAoCIjY1VGpaSkiKcnJzEp59+Ki5fviw2btwoLCwsdObU1eHDh4ty5cqJAwcOiKtXr4qBAwcKR0dHqVjQ5eX/999/i/nz54uYmBhx8+ZN8csvv4gyZcqIoKAgaRxdX/6vu3XrltLZWLqc/9SpU2Lx4sXi/Pnz4vbt2+LQoUOiSZMmwtPTU/oh1eX89+/fF5UqVRL+/v7i/v37CpcvyKPL+YXQzO8ZKdKbYic4OFgAUHrk/SUihBC3b98W7du3F+bm5qJ06dJi9OjRIjs7W2E6R44cEXXq1BEmJiaiYsWKIiIi4v2+kdd8+umnwt7eXpiYmIhatWqJdevWKY2jynvShjNnzoi2bdsKe3t7YW1tLRo3biz27t2rMI6uZs/z8ccfiyZNmhQ4/MKFC6Jp06bC1NRUlCtXTsyePfs9pnu7ly9fitGjRwtHR0dhbW0tAgICxOXLlxXG0dXlHx0dLRo1aiRsbW2FmZmZqFatmpg5c6bSX6y6vPxfl1+xI4Tu5r948aJo1aqVsLe3F6ampsLd3V18+eWX4v79+wrj6Wr+iIiIfH8L3jyQoav5hdDc7xn9H5kQWuxxRkRERFTMdPpsLCIiIqKiYrFDREREeo3FDhEREek1FjtERESk11jsEBERkV5jsUNERER6jcUOERER6TUWO0SkdVevXkXjxo1hZmaGOnXqaDtOkR09ehQymQwpKSkAgDVr1qBUqVJayZKYmIg2bdrA0tJSaxmItI3FDum8AQMGSHcFNjExQaVKlTB16lTk5ORoO9o7yWQy7NixQ9sxJK/fYdnS0hKVK1fGgAEDEB0drdVckyZNgqWlJeLi4nDo0CGtZgGA27dv53tX6k8++aTY5vn6fGxtbeHn54fDhw8Xebrz589HQkICYmJicO3aNQ0kJSp5WOxQidCuXTskJCTg+vXrGD16NCZPnowffvihUNPKzc2FXC7XcMKSIyIiAgkJCbhy5QqWLl2K9PR0NGrUCOvWrSvwNcW9zG7evImmTZvCzc0NDg4O+Y6TnZ1dbPMvyJ9//omEhATpsXTp0mKdX966OXnyJEqXLo1OnTohPj6+UNN6+fIlgFfL1sfHB5UrV4ajo2ORpkVUYmn7fhVE7xIcHCy6du2q0NamTRvRuHFjIYQQmZmZYvTo0cLFxUVYWFiIhg0bKtxDJu/OwTt37hTVqlUThoaG4tatWyIzM1OMGzdOlC9fXpiYmAhPT0+FO4VfunRJtGvXTlhaWgpHR0fxySefiEePHknDW7RoIYYOHSrGjh0r7OzshJOTk5g0aZI03M3NTeG+Nm5ubkIIIW7cuCG6dOkiHB0dhaWlpahfv76IjIxUeH8PHz4UHTp0EGZmZsLd3V1s2LBBuLm5ifnz50vjPH36VAwcOFCULl1aWFtbi1atWkk3Wi0IALF9+3al9qCgIGFtbS3dKLSgZfbkyRPx6aefilKlSglzc3PRrl07ce3aNaVlvX37dlGpUiVhamoq2rZtK+7evfvWTK8/Jk2aJN1PauPGjaJ58+bC1NRUREREiNzcXDFlyhRRrlw5YWJiImrXri327dsnTSvvdZs2bRJNmzYVZmZmon79+iIuLk6cPn1a+Pj4CEtLS9GuXTuRnJxcYKaC7mdV0LCnT58q3LvoyJEjAoB4+vSpwnJ5mzfXzYMHDwQAsXz5ciGEattjaGioGD58uHBwcBAtW7ZU2gaDg4OFEK9uNNmlSxdhaWkprK2tRa9evURiYqI0rUmTJonatWuLVatWCXd3dyGTyaSMy5cvFx07dhTm5uaiatWq4u+//xbXr18XLVq0EBYWFsLX11fcuHFDmpYq27ubm5uYMWOGCAkJEVZWVsLV1VXpppz37t0Tffv2FXZ2dsLCwkL4+PiIU6dOScN37Ngh6tatK0xNTYWHh4eYPHky7xVFEu7ZoRLJ3Nxc+mtzyJAhiIqKwsaNG3Hx4kX06tUL7dq1w/Xr16Xxnz9/jjlz5uCnn37ClStX4OjoiKCgIPz2229YtGgRYmNjsWLFClhZWQEAUlJS0Lp1a9StWxdnz57F/v37kZSUhN69eyvkWLt2LSwtLfHPP//g+++/x9SpUxEZGQkAOHPmDID/+2s973l6ejo6dOiAQ4cO4fz582jXrh06d+6Mu3fvStMNCgrCw4cPcfToUWzduhUrV65EcnKywrx79eqF5ORk7Nu3D9HR0ahXrx78/f3x5MkTtZfnyJEj8ezZMyl7QctswIABOHv2LHbt2oWoqCgIIdChQweFvS7Pnz/HjBkzsG7dOpw8eRIpKSno27dvgfNOSEhAjRo1MHr0aCQkJGDMmDHSsAkTJmD48OGIjY1FYGAgFi5ciLlz5+LHH3/ExYsXERgYiC5duiisa+DVYbFvv/0W586dg5GREfr164dx48Zh4cKF+Ouvv3Djxg189913ai+n98nc3BzAq70q6myPJiYmOHnyJJYvX44zZ86gXbt26N27NxISErBw4ULI5XJ07doVT548wbFjxxAZGYn4+Hj06dNHYVo3btzA1q1bsW3bNsTExEjt06ZNQ1BQEGJiYlC1alX069cPX3zxBcLCwnD27FkIITBkyBBpfFW2dwCYO3cu6tevj/Pnz+Orr77C//73P8TFxUnTaNGiBR48eIBdu3bhwoULGDdunLS38a+//kJQUBCGDx+Of//9FytWrMCaNWswY8YMja0PKuG0XW0Rvcvre3bkcrmIjIwUpqamYsyYMeLOnTvC0NBQPHjwQOE1/v7+IiwsTAjxf3dBfn2vR1xcnACg9BdmnmnTpom2bdsqtN27d08AEHFxcUKIV39JN23aVGGcBg0aiPHjx0vPUcCelDfVqFFDLF68WAghRGxsrAAgzpw5Iw2/fv26ACDt2fnrr7+EjY2N0p3APT09lf4ifl1BeV68eCEAiDlz5ggh8l9m165dEwDEyZMnpbb//vtPmJubi99//13hda//xZ33fv75558Cc9WuXVthr1je3pMFCxYojOfi4iJmzJih0NagQQPx1VdfKbzu9T10v/32mwAgDh06JLXNmjVLeHl5FZgnbzrm5ubC0tJSepw7d+697NnJyMgQX331lTA0NBQXLlxQeXusW7eu0nS7du0q7dERQoiDBw8KQ0NDhb1tV65cEQDE6dOnhRCv9uwYGxsr7f0CIL799lvpeVRUlAAgVq9eLbX99ttvwszM7K3v9fXtXYhXe3Y++eQT6blcLheOjo4iPDxcCCHEihUrhLW1tXj8+HG+0/P39xczZ85UaFu/fr0oW7bsW3PQh8Po/ZVVRIW3Z88eWFlZITs7G3K5HP369cPkyZNx9OhR5ObmokqVKgrjZ2VlKfT9MDExQa1ataTnMTExMDQ0RIsWLfKd34ULF3DkyBFpT8/rbt68Kc3v9WkCQNmyZZX2wLwpPT0dkydPxh9//IGEhATk5OTgxYsX0l+6cXFxMDIyQr169aTXVKpUCXZ2dgr50tPTlfq3vHjxAjdv3nzr/PMjhADwqpNsnjeXWWxsLIyMjNCoUSOpzcHBAV5eXoiNjZXajIyM0KBBA+l51apVUapUKcTGxqJhw4Zq5apfv770/7S0NDx8+BB+fn4K4/j5+eHChQsKba/ndnJyAgB4e3srtL1rPQHApk2bUK1aNem5q6srEhIS1HoP6vj4449haGiIFy9eoEyZMli9ejVq1aqFadOmqbQ9+vj4vHMesbGxcHV1haurq9RWvXp1aR3lrTs3NzeUKVNG6fWqLNvMzEykpaXBxsbmndt7ftOVyWRwdnaW1lFMTAzq1q0Le3v7fN/ThQsXcPLkSYU9Obm5ucjMzMTz589hYWHxzuVC+o3FDpUIrVq1Qnh4OExMTODi4gIjo1ebbnp6OgwNDREdHQ1DQ0OF17z+w2Bubq7wQ553iKAg6enp6Ny5M+bMmaM0rGzZstL/jY2NFYbJZLJ3duQdM2YMIiMj8eOPP6JSpUowNzdHz5491eoEmp6ejrJly+Lo0aNKwwpzenFeseLh4SG1vbnMtMHS0rJQr3t9veS9hzfbVOlw7erqikqVKim0GRi8OvqfVyACmus8PX/+fAQEBMDW1lah0FB1eyzs8spPQdNSZdkCkJavqtv72z5Lqnxep0yZgu7duysNMzMze+tr6cPAYodKBEtLS6UfHQCoW7cucnNzkZycjGbNmqk8PW9vb8jlchw7dgwBAQFKw+vVq4etW7fC3d1dKqwKw9jYGLm5uQptJ0+exIABA/DRRx8BePVFffv2bWm4l5cXcnJycP78eekv9Rs3buDp06cK+RITE2FkZAR3d/dC58uzYMEC2NjY5Lss8lSrVg05OTn4559/0KRJEwDA48ePERcXh+rVq0vj5eTk4OzZs9JenLi4OKSkpCjsISkMGxsbuLi44OTJkwp75E6ePKn2HqOiyCtCEhISULduXQBQ6NNSFM7Ozvlu55raHoFX6/HevXu4d++etHfn33//RUpKisJ61JR3be+qqFWrFn766Sc8efIk37079erVQ1xcXL7LjgjgqedUwlWpUgX9+/dHUFAQtm3bhlu3buH06dOYNWsW/vjjjwJf5+7ujuDgYHz22WfYsWMHbt26haNHj+L3338HAISGhuLJkyf4+OOPcebMGdy8eRMHDhxASEiIUvHyNu7u7jh06BASExOlYqVy5cpSp88LFy6gX79+CnsZqlatioCAAAwePBinT5/G+fPnMXjwYIU9LQEBAfD19UW3bt1w8OBB3L59G3///Te++eYbnD179q2ZUlJSkJiYiDt37iAyMhI9e/bEr7/+ivDw8LfuFapcuTK6du2KQYMG4cSJE7hw4QI++eQTlCtXDl27dpXGMzY2xtChQ/HPP/8gOjoaAwYMQOPGjTVSkIwdOxZz5szBpk2bEBcXhwkTJiAmJgbDhw8v8rRVZW5ujsaNG2P27NmIjY3FsWPH8O233xbrPDW1PQKvth1vb2/0798f586dw+nTpxEUFIQWLVooHDbUlHdt76r4+OOP4ezsjG7duuHkyZOIj4/H1q1bERUVBQD47rvvsG7dOkyZMgVXrlxBbGwsNm7cWOzrhUoOFjtU4kVERCAoKAijR4+Gl5cXunXrhjNnzqBChQpvfV14eDh69uyJr776ClWrVsWgQYOQkZEBANIehNzcXLRt2xbe3t4YMWIESpUqJR3GUMXcuXMRGRkJV1dXaS/AvHnzYGdnhyZNmqBz584IDAxU6J8DAOvWrYOTkxOaN2+Ojz76CIMGDYK1tbW0S14mk2Hv3r1o3rw5QkJCUKVKFfTt2xd37tyR+lEUJCQkBGXLlkXVqlXxv//9D1ZWVjh9+jT69ev3zvcTEREBHx8fdOrUCb6+vhBCYO/evQqHICwsLDB+/Hj069cPfn5+sLKywqZNm1ReZm8zbNgwjBo1CqNHj4a3tzf279+PXbt2oXLlyhqZvqp+/vln5OTkwMfHByNGjMD06dOLdX6a2h6BV9vOzp07YWdnh+bNmyMgIAAVK1bU2Dp6kyrb+7uYmJjg4MGDcHR0RIcOHeDt7Y3Zs2dLh64DAwOxZ88eHDx4EA0aNEDjxo0xf/58uLm5FcdbohJIJl4/8ExEOun+/ftwdXXFn3/+CX9/f23HKdCaNWswYsQI6TYJRES6gH12iHTQ4cOHkZ6eDm9vbyQkJGDcuHFwd3dH8+bNtR2NiKjEYbFDpIOys7Px9ddfIz4+HtbW1mjSpAk2bNigdMYKERG9Gw9jERERkV5jB2UiIiLSayx2iIiISK+x2CEiIiK9xmKHiIiI9BqLHSIiItJrLHaIiIhIr7HYISIiIr3GYoeIiIj0GosdIiIi0mv/DyPG5l96qHSxAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lh_scores_drop = {key: min(0, val-100) for key, val in lh_scores_s.items()}\n",
    "scores = list(lh_scores_drop.values())\n",
    "scores = [s.cpu().numpy() if isinstance(s, torch.Tensor) else s for s in scores]\n",
    "plt.hist(scores, bins=10, edgecolor='black')\n",
    "n, bins, patches = plt.hist(scores, bins=10, edgecolor='black')\n",
    "\n",
    "for i in range(len(n)):\n",
    "    plt.text(bins[i]+5, n[i], str(int(n[i])), va='bottom', ha='center')\n",
    "\n",
    "plt.xticks(range(-100, 0, 10))\n",
    "plt.xlabel('Percentage Drop from Full Performance')\n",
    "plt.ylabel('Number of Attention Heads')\n",
    "plt.title('Distribution of Attention Head Performance Drop Percentages')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6918,
     "status": "ok",
     "timestamp": 1742789096025,
     "user": {
      "displayName": "Reilly H",
      "userId": "05616995266737589283"
     },
     "user_tz": -780
    },
    "id": "p3VzeS9X4npn",
    "outputId": "14a56550-4971-47b6-bc7d-d4da8d009c42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing teacher model MLPs...\n",
      "Completed Layer 0 MLP: Retained = 96.33%\n",
      "Completed Layer 1 MLP: Retained = 78.87%\n",
      "Completed Layer 2 MLP: Retained = 100.33%\n",
      "Completed Layer 3 MLP: Retained = 102.21%\n",
      "Completed Layer 4 MLP: Retained = 126.26%\n",
      "Completed Layer 5 MLP: Retained = 90.92%\n",
      "Completed Layer 6 MLP: Retained = 93.72%\n",
      "Completed Layer 7 MLP: Retained = 112.61%\n",
      "Completed Layer 8 MLP: Retained = 105.13%\n",
      "Completed Layer 9 MLP: Retained = 96.81%\n",
      "Completed Layer 10 MLP: Retained = 69.60%\n",
      "Completed Layer 11 MLP: Retained = 100.13%\n",
      "\n",
      "Analyzing student model MLPs...\n",
      "Completed Layer 0 MLP: Retained = 556.07%\n",
      "Completed Layer 1 MLP: Retained = 297.15%\n",
      "Completed Layer 2 MLP: Retained = 367.34%\n",
      "Completed Layer 3 MLP: Retained = 115.41%\n",
      "Completed Layer 4 MLP: Retained = -562.85%\n",
      "Completed Layer 5 MLP: Retained = 185.14%\n"
     ]
    }
   ],
   "source": [
    "def direct_ablate_single_mlp(\n",
    "    model: HookedTransformer,\n",
    "    dataset: Dataset,\n",
    "    layer: int,\n",
    "    orig_score: float,\n",
    "    ablation_type=\"zero\",\n",
    "    print_output: bool = True\n",
    ") -> float:\n",
    "    model.reset_hooks(including_permanent=True)\n",
    "\n",
    "    if ablation_type == \"mean\":\n",
    "        _, cache = model.run_with_cache(\n",
    "            dataset.toks.long(),\n",
    "            return_type=None,\n",
    "            names_filter=lambda name: name.endswith(\"mlp_out\") and f\"blocks.{layer}\" in name\n",
    "        )\n",
    "        mlp_mean = cache[utils.get_act_name(\"mlp_out\", layer)].mean(dim=0, keepdim=True)\n",
    "\n",
    "    def hook_fn(mlp_out, hook):\n",
    "        if hook.layer() == layer:\n",
    "            if ablation_type == \"zero\":\n",
    "                return torch.zeros_like(mlp_out)\n",
    "            else:\n",
    "                return mlp_mean.expand_as(mlp_out)\n",
    "        return mlp_out\n",
    "\n",
    "    model.add_hook(lambda name: name.endswith(\"mlp_out\"), hook_fn, is_permanent=False)\n",
    "\n",
    "    ablated_logits = model(dataset.toks)\n",
    "\n",
    "    new_score = get_logit_diff(ablated_logits, ioi_dataset)\n",
    "\n",
    "    percent_retained = 100 * (new_score / orig_score)\n",
    "\n",
    "    if print_output:\n",
    "        impact = 100 - percent_retained\n",
    "        print(f\"Layer {layer} MLP: Impact = {impact:.2f}%, Retained = {percent_retained:.2f}%\")\n",
    "\n",
    "    model.reset_hooks()\n",
    "    return percent_retained\n",
    "\n",
    "\n",
    "scores_mlp_t = []\n",
    "scores_mlp_s = []\n",
    "\n",
    "print(\"Analyzing teacher model MLPs...\")\n",
    "for layer in range(12):\n",
    "    retained = max(0, direct_ablate_single_mlp(teacher, ioi_dataset, layer, orig_score_t, ablation_type=\"zero\", print_output=False))\n",
    "    try:\n",
    "      scores_mlp_t.append((layer, -round(100 - retained.item(), 2)))\n",
    "    except:\n",
    "      scores_mlp_t.append((layer, -round(100 - retained, 2)))\n",
    "    print(f\"Completed Layer {layer} MLP: Retained = {retained:.2f}%\")\n",
    "\n",
    "print(\"\\nAnalyzing student model MLPs...\")\n",
    "for layer in range(6):\n",
    "    retained = direct_ablate_single_mlp(student, ioi_dataset, layer, orig_score_s, ablation_type=\"zero\", print_output=False)\n",
    "    try:\n",
    "      scores_mlp_s.append((layer, -round(100 - retained.item(), 2)))\n",
    "    except:\n",
    "      scores_mlp_s.append((layer, -round(100 - retained, 2)))\n",
    "    print(f\"Completed Layer {layer} MLP: Retained = {retained:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1742789096054,
     "user": {
      "displayName": "Reilly H",
      "userId": "05616995266737589283"
     },
     "user_tz": -780
    },
    "id": "h0OzHKeX546l",
    "outputId": "891d0a25-d352-4141-e0bb-f8b77a77799f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, -3.67), (1, -21.13), (2, 0.33), (3, 2.21), (4, 26.26), (5, -9.08), (6, -6.28), (7, 12.61), (8, 5.13), (9, -3.19), (10, -30.4), (11, 0.13), ((0, 5), -24.73), ((11, 8), -19.91), ((0, 6), -18.99), ((5, 8), -15.66), ((1, 6), -15.31), ((0, 7), -13.63), ((5, 9), -12.33), ((7, 3), -10.84), ((0, 0), -10.47), ((5, 0), -9.4), ((1, 5), -9.31), ((11, 4), -8.77), ((1, 0), -7.53), ((6, 8), -7.41), ((1, 10), -7.29), ((8, 5), -6.94), ((10, 9), -6.63), ((1, 11), -6.52), ((0, 8), -6.26), ((2, 5), -5.23), ((5, 3), -5.07), ((8, 8), -4.73), ((6, 5), -4.47), ((0, 3), -4.27), ((2, 6), -4.15), ((6, 11), -3.9), ((0, 4), -3.72), ((4, 1), -3.72), ((9, 7), -3.61), ((4, 9), -3.43), ((4, 4), -3.3), ((1, 7), -3.25), ((10, 4), -3.04), ((9, 3), -2.89), ((6, 4), -2.86), ((5, 2), -2.8), ((9, 4), -2.63), ((11, 6), -2.52), ((10, 1), -2.36), ((3, 2), -2.21), ((10, 11), -2.2), ((9, 11), -2.13), ((5, 7), -2.01), ((10, 2), -2.0), ((4, 10), -1.99), ((10, 7), -1.98), ((4, 8), -1.79), ((5, 5), -1.69), ((7, 8), -1.67), ((8, 2), -1.59), ((11, 9), -1.49), ((5, 6), -1.42), ((3, 1), -1.25), ((1, 4), -1.21), ((3, 0), -1.14), ((10, 5), -1.02), ((6, 9), -0.87), ((0, 2), -0.71), ((11, 3), -0.71), ((6, 10), -0.7), ((11, 2), -0.63), ((7, 10), -0.63), ((11, 1), -0.5), ((9, 2), -0.36), ((7, 1), -0.12), ((10, 0), -0.05), ((6, 0), -0.02), ((7, 9), 0.05), ((9, 0), 0.09), ((11, 7), 0.21), ((9, 8), 0.32), ((11, 5), 0.34), ((8, 6), 0.43), ((8, 4), 0.59), ((4, 0), 0.59), ((9, 10), 0.65), ((8, 1), 0.65), ((10, 10), 0.77), ((7, 11), 0.89), ((8, 7), 0.93), ((10, 8), 0.96), ((7, 6), 0.98), ((7, 0), 1.02), ((3, 9), 1.06), ((6, 3), 1.11), ((11, 10), 1.19), ((5, 1), 1.41), ((10, 6), 1.45), ((9, 6), 1.56), ((6, 7), 1.57), ((4, 5), 1.64), ((1, 9), 1.65), ((9, 5), 1.7), ((9, 9), 1.99), ((11, 11), 2.02), ((7, 5), 2.26), ((7, 7), 2.39), ((5, 11), 2.44), ((1, 1), 2.52), ((3, 3), 2.55), ((8, 3), 2.67), ((6, 1), 2.71), ((4, 3), 2.89), ((10, 3), 2.98), ((8, 9), 3.12), ((11, 0), 3.25), ((7, 4), 3.26), ((5, 10), 3.77), ((4, 2), 3.94), ((6, 2), 4.33), ((0, 11), 4.61), ((7, 2), 4.89), ((2, 4), 4.97), ((2, 1), 5.28), ((3, 10), 5.7), ((1, 8), 5.84), ((4, 7), 5.98), ((1, 2), 6.09), ((8, 11), 6.26), ((2, 2), 6.3), ((2, 11), 6.36), ((3, 4), 6.55), ((8, 10), 6.58), ((4, 6), 6.61), ((3, 5), 6.94), ((3, 8), 7.07), ((4, 11), 7.32), ((2, 7), 7.55), ((8, 0), 7.55), ((3, 7), 7.65), ((2, 3), 8.91), ((5, 4), 9.39), ((0, 9), 9.49), ((9, 1), 9.58), ((3, 6), 9.88), ((6, 6), 9.99), ((3, 11), 10.75), ((2, 9), 10.8), ((2, 8), 11.96), ((1, 3), 13.72), ((0, 1), 14.41), ((0, 10), 15.29), ((2, 0), 23.63), ((2, 10), 29.71)]\n",
      "[(0, 456.07), (1, 197.15), (2, 267.34), (3, 15.41), (4, -662.85), (5, 85.14), ((0, 7), -72.28), ((3, 6), -58.49), ((1, 9), -54.74), ((2, 8), -48.68), ((1, 1), -44.91), ((5, 0), -42.54), ((5, 1), -40.79), ((5, 6), -40.01), ((4, 6), -36.06), ((3, 4), -32.65), ((0, 2), -32.49), ((5, 9), -31.19), ((4, 9), -29.87), ((0, 6), -29.52), ((1, 6), -24.41), ((3, 11), -22.94), ((4, 10), -18.54), ((2, 11), -17.06), ((5, 11), -16.81), ((1, 2), -15.56), ((4, 8), -15.19), ((0, 0), -14.77), ((5, 3), -10.49), ((2, 10), -9.98), ((4, 3), -9.72), ((0, 4), -8.12), ((5, 5), -4.47), ((4, 2), -4.47), ((4, 11), -4.02), ((5, 4), -1.55), ((4, 0), -0.25), ((0, 3), 1.81), ((4, 1), 6.67), ((5, 7), 8.38), ((5, 8), 8.89), ((3, 7), 9.35), ((2, 9), 9.73), ((2, 1), 10.03), ((1, 8), 10.67), ((3, 0), 10.68), ((1, 3), 11.49), ((3, 2), 11.75), ((2, 5), 11.87), ((3, 5), 12.34), ((2, 0), 12.9), ((2, 4), 14.75), ((1, 4), 17.68), ((4, 4), 18.08), ((1, 5), 18.69), ((3, 8), 19.77), ((1, 0), 20.04), ((1, 10), 23.35), ((2, 2), 25.24), ((3, 3), 31.18), ((4, 5), 31.32), ((2, 3), 32.44), ((1, 11), 36.85), ((0, 8), 37.33), ((2, 6), 48.8), ((1, 7), 49.19), ((2, 7), 61.37), ((3, 9), 71.9), ((0, 1), 73.05), ((5, 2), 80.07), ((0, 11), 82.19), ((3, 10), 95.09), ((0, 5), 100.98), ((5, 10), 104.01), ((0, 10), 109.62), ((3, 1), 110.59), ((0, 9), 115.93), ((4, 7), 152.1)]\n"
     ]
    }
   ],
   "source": [
    "scores_combined_t = scores_mlp_t + scores_attn_t\n",
    "scores_combined_s = scores_mlp_s + scores_attn_s\n",
    "print(scores_combined_t)\n",
    "print(scores_combined_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ikq3v95610s"
   },
   "source": [
    "# Match components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 2445,
     "status": "ok",
     "timestamp": 1742789098500,
     "user": {
      "displayName": "Reilly H",
      "userId": "05616995266737589283"
     },
     "user_tz": -780
    },
    "id": "IyTwy0QV57L9"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "sims = {}\n",
    "max_vals_attn = {}\n",
    "\n",
    "for student_layer in range(6):\n",
    "    for student_head in range(12):\n",
    "        curr_comb = (student_layer, student_head)\n",
    "        if curr_comb not in max_vals_attn.keys():\n",
    "            max_vals_attn[curr_comb] = (None, 0)\n",
    "        for teacher_layer in range(12):\n",
    "            for teacher_head in range(12):\n",
    "                curr_s = local_cache_s[\"attn\", student_layer][:, student_head].mean(dim=0)\n",
    "                curr_t = local_cache_t[\"attn\", teacher_layer][:, teacher_head].mean(dim=0)\n",
    "                sim = torch.mean(F.cosine_similarity(curr_s.unsqueeze(1), curr_t.unsqueeze(1), dim=2))\n",
    "                if sim > max_vals_attn[curr_comb][1]:\n",
    "                    max_vals_attn[curr_comb] = ((teacher_layer, teacher_head), sim)\n",
    "                sims[(student_layer, student_head, teacher_layer, teacher_head)] = sim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1742789098503,
     "user": {
      "displayName": "Reilly H",
      "userId": "05616995266737589283"
     },
     "user_tz": -780
    },
    "id": "Y8XXrl_w7ByC"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.linalg import svd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# computes similarity between eigenvectors of activation matrices from two layers.\n",
    "def activation_eigenvector_similarity(layer1, layer2, k=3):\n",
    "    acts1 = np.array(local_cache_t[f'blocks.{layer1}.hook_mlp_out'].cpu())\n",
    "    acts2 = np.array(local_cache_s[f'blocks.{layer2}.hook_mlp_out'].cpu())\n",
    "\n",
    "    acts1_flattened = acts1.reshape(-1, acts1.shape[-1])\n",
    "    acts2_flattened = acts2.reshape(-1, acts2.shape[-1])\n",
    "\n",
    "    cov1 = np.dot(acts1_flattened.T, acts1_flattened) / acts1_flattened.shape[0] # covariance matrices\n",
    "    cov2 = np.dot(acts2_flattened.T, acts2_flattened) / acts2_flattened.shape[0]\n",
    "\n",
    "    # get eigenvectors with singular value decomp\n",
    "    U1, _, _ = svd(cov1)\n",
    "    U2, _, _ = svd(cov2)\n",
    "    U1_topk = U1[:, :k]\n",
    "    U2_topk = U2[:, :k]\n",
    "\n",
    "    similarity_matrix = cosine_similarity(U1_topk.T, U2_topk.T)\n",
    "    avg_similarity = np.mean(similarity_matrix)\n",
    "\n",
    "    return avg_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 39421,
     "status": "ok",
     "timestamp": 1742789137923,
     "user": {
      "displayName": "Reilly H",
      "userId": "05616995266737589283"
     },
     "user_tz": -780
    },
    "id": "tahH4kDh7DQz"
   },
   "outputs": [],
   "source": [
    "sims_mlp = {}\n",
    "\n",
    "for i in range(0, 6):\n",
    "    for j in range(0, 12):\n",
    "        curr_sim = abs(activation_eigenvector_similarity(j, i))\n",
    "        sims_mlp[(i, j)] = curr_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalise MLP and attn. head similarities to be on the same scale\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "mlp_keys = [k for k, v in sims_mlp.items() if v > 0]\n",
    "mlp_values = np.array([v for v in sims_mlp.values() if v > 0])\n",
    "\n",
    "attn_values = torch.tensor([v.item() for v in sims.values()])\n",
    "\n",
    "mlp_mean, mlp_std = np.mean(mlp_values), np.std(mlp_values)\n",
    "attn_mean, attn_std = torch.mean(attn_values), torch.std(attn_values)\n",
    "\n",
    "if mlp_values.size > 0:\n",
    "    mlp_min, mlp_max = np.min(mlp_values), np.max(mlp_values)\n",
    "else:\n",
    "    mlp_min, mlp_max = 0, 0\n",
    "if attn_values.numel() > 0:\n",
    "    attn_min, attn_max = torch.min(attn_values), torch.max(attn_values)\n",
    "else:\n",
    "    attn_min, attn_max = 0, 0\n",
    "\n",
    "mlp_values_normalized = ((mlp_values - mlp_mean) / mlp_std) * attn_std.item() + attn_mean.item()\n",
    "\n",
    "mlp_adjusted_values = mlp_values_normalized\n",
    "\n",
    "sims_mlp_adjusted = {k: v for k, v in zip(mlp_keys, mlp_adjusted_values)}\n",
    "\n",
    "sims_mlp_adjusted.update({k: 0 for k in sims_mlp if k not in sims_mlp_adjusted})\n",
    "\n",
    "max_val = max(sims_mlp_adjusted.values())\n",
    "\n",
    "if max_val == 0:\n",
    "    sim_mlp_scaled = {key: 0 for key in sims_mlp_adjusted.keys()}\n",
    "else:\n",
    "    sim_mlp_scaled = {key: val / max_val for key, val in sims_mlp_adjusted.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1742789137924,
     "user": {
      "displayName": "Reilly H",
      "userId": "05616995266737589283"
     },
     "user_tz": -780
    },
    "id": "DJ8V_64V7FGy",
    "outputId": "29dbaaf7-8867-483b-c391-ff8ef3965bb9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: (1, 0.13220264),\n",
       " 1: (5, 0.17380045),\n",
       " 2: (5, 0.16502175),\n",
       " 3: (5, 0.15884043),\n",
       " 4: (9, 0.105078615),\n",
       " 5: (10, 0.15294863)}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_vals_mlp = {}\n",
    "\n",
    "for (i, j), val in sims_mlp.items():\n",
    "    if i not in max_vals_mlp or val > max_vals_mlp[i][1]:\n",
    "        max_vals_mlp[i] = (j, val)\n",
    "\n",
    "max_vals_mlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qtHGD1mp7Hf6"
   },
   "source": [
    "# Calculate model divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1742789137925,
     "user": {
      "displayName": "Reilly H",
      "userId": "05616995266737589283"
     },
     "user_tz": -780
    },
    "id": "8eYFvxLi7J87",
    "outputId": "49e5f91e-7f2d-4401-a183-05526479b333"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, -3.67), (1, -21.13), (2, 0.33), (3, 2.21), (4, 26.26), (5, -9.08), (6, -6.28), (7, 12.61), (8, 5.13), (9, -3.19), (10, -30.4), (11, 0.13), ((0, 5), -24.73), ((11, 8), -19.91), ((0, 6), -18.99), ((5, 8), -15.66), ((1, 6), -15.31), ((0, 7), -13.63), ((5, 9), -12.33), ((7, 3), -10.84), ((0, 0), -10.47), ((5, 0), -9.4), ((1, 5), -9.31), ((11, 4), -8.77), ((1, 0), -7.53), ((6, 8), -7.41), ((1, 10), -7.29), ((8, 5), -6.94), ((10, 9), -6.63), ((1, 11), -6.52), ((0, 8), -6.26), ((2, 5), -5.23), ((5, 3), -5.07), ((8, 8), -4.73), ((6, 5), -4.47), ((0, 3), -4.27), ((2, 6), -4.15), ((6, 11), -3.9), ((0, 4), -3.72), ((4, 1), -3.72), ((9, 7), -3.61), ((4, 9), -3.43), ((4, 4), -3.3), ((1, 7), -3.25), ((10, 4), -3.04), ((9, 3), -2.89), ((6, 4), -2.86), ((5, 2), -2.8), ((9, 4), -2.63), ((11, 6), -2.52), ((10, 1), -2.36), ((3, 2), -2.21), ((10, 11), -2.2), ((9, 11), -2.13), ((5, 7), -2.01), ((10, 2), -2.0), ((4, 10), -1.99), ((10, 7), -1.98), ((4, 8), -1.79), ((5, 5), -1.69), ((7, 8), -1.67), ((8, 2), -1.59), ((11, 9), -1.49), ((5, 6), -1.42), ((3, 1), -1.25), ((1, 4), -1.21), ((3, 0), -1.14), ((10, 5), -1.02), ((6, 9), -0.87), ((0, 2), -0.71), ((11, 3), -0.71), ((6, 10), -0.7), ((11, 2), -0.63), ((7, 10), -0.63), ((11, 1), -0.5), ((9, 2), -0.36), ((7, 1), -0.12), ((10, 0), -0.05), ((6, 0), -0.02), ((7, 9), 0.05), ((9, 0), 0.09), ((11, 7), 0.21), ((9, 8), 0.32), ((11, 5), 0.34), ((8, 6), 0.43), ((8, 4), 0.59), ((4, 0), 0.59), ((9, 10), 0.65), ((8, 1), 0.65), ((10, 10), 0.77), ((7, 11), 0.89), ((8, 7), 0.93), ((10, 8), 0.96), ((7, 6), 0.98), ((7, 0), 1.02), ((3, 9), 1.06), ((6, 3), 1.11), ((11, 10), 1.19), ((5, 1), 1.41), ((10, 6), 1.45), ((9, 6), 1.56), ((6, 7), 1.57), ((4, 5), 1.64), ((1, 9), 1.65), ((9, 5), 1.7), ((9, 9), 1.99), ((11, 11), 2.02), ((7, 5), 2.26), ((7, 7), 2.39), ((5, 11), 2.44), ((1, 1), 2.52), ((3, 3), 2.55), ((8, 3), 2.67), ((6, 1), 2.71), ((4, 3), 2.89), ((10, 3), 2.98), ((8, 9), 3.12), ((11, 0), 3.25), ((7, 4), 3.26), ((5, 10), 3.77), ((4, 2), 3.94), ((6, 2), 4.33), ((0, 11), 4.61), ((7, 2), 4.89), ((2, 4), 4.97), ((2, 1), 5.28), ((3, 10), 5.7), ((1, 8), 5.84), ((4, 7), 5.98), ((1, 2), 6.09), ((8, 11), 6.26), ((2, 2), 6.3), ((2, 11), 6.36), ((3, 4), 6.55), ((8, 10), 6.58), ((4, 6), 6.61), ((3, 5), 6.94), ((3, 8), 7.07), ((4, 11), 7.32), ((2, 7), 7.55), ((8, 0), 7.55), ((3, 7), 7.65), ((2, 3), 8.91), ((5, 4), 9.39), ((0, 9), 9.49), ((9, 1), 9.58), ((3, 6), 9.88), ((6, 6), 9.99), ((3, 11), 10.75), ((2, 9), 10.8), ((2, 8), 11.96), ((1, 3), 13.72), ((0, 1), 14.41), ((0, 10), 15.29), ((2, 0), 23.63), ((2, 10), 29.71)]\n",
      "[(0, 456.07), (1, 197.15), (2, 267.34), (3, 15.41), (4, -662.85), (5, 85.14), ((0, 7), -72.28), ((3, 6), -58.49), ((1, 9), -54.74), ((2, 8), -48.68), ((1, 1), -44.91), ((5, 0), -42.54), ((5, 1), -40.79), ((5, 6), -40.01), ((4, 6), -36.06), ((3, 4), -32.65), ((0, 2), -32.49), ((5, 9), -31.19), ((4, 9), -29.87), ((0, 6), -29.52), ((1, 6), -24.41), ((3, 11), -22.94), ((4, 10), -18.54), ((2, 11), -17.06), ((5, 11), -16.81), ((1, 2), -15.56), ((4, 8), -15.19), ((0, 0), -14.77), ((5, 3), -10.49), ((2, 10), -9.98), ((4, 3), -9.72), ((0, 4), -8.12), ((5, 5), -4.47), ((4, 2), -4.47), ((4, 11), -4.02), ((5, 4), -1.55), ((4, 0), -0.25), ((0, 3), 1.81), ((4, 1), 6.67), ((5, 7), 8.38), ((5, 8), 8.89), ((3, 7), 9.35), ((2, 9), 9.73), ((2, 1), 10.03), ((1, 8), 10.67), ((3, 0), 10.68), ((1, 3), 11.49), ((3, 2), 11.75), ((2, 5), 11.87), ((3, 5), 12.34), ((2, 0), 12.9), ((2, 4), 14.75), ((1, 4), 17.68), ((4, 4), 18.08), ((1, 5), 18.69), ((3, 8), 19.77), ((1, 0), 20.04), ((1, 10), 23.35), ((2, 2), 25.24), ((3, 3), 31.18), ((4, 5), 31.32), ((2, 3), 32.44), ((1, 11), 36.85), ((0, 8), 37.33), ((2, 6), 48.8), ((1, 7), 49.19), ((2, 7), 61.37), ((3, 9), 71.9), ((0, 1), 73.05), ((5, 2), 80.07), ((0, 11), 82.19), ((3, 10), 95.09), ((0, 5), 100.98), ((5, 10), 104.01), ((0, 10), 109.62), ((3, 1), 110.59), ((0, 9), 115.93), ((4, 7), 152.1)]\n"
     ]
    }
   ],
   "source": [
    "component_influence_teacher = scores_combined_t\n",
    "component_influence_student = scores_combined_s\n",
    "print(component_influence_teacher)\n",
    "print(component_influence_student)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1742789137949,
     "user": {
      "displayName": "Reilly H",
      "userId": "05616995266737589283"
     },
     "user_tz": -780
    },
    "id": "otMr2W1h7MTs",
    "outputId": "8cb987bb-85a6-4377-f2ad-afe0273c3425"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[((4, 1), ((4, 8), tensor(0.9996, device='cuda:0'))), ((5, 9), ((10, 6), tensor(0.9996, device='cuda:0'))), ((4, 11), ((9, 4), tensor(0.9994, device='cuda:0'))), ((4, 5), ((4, 4), tensor(0.9994, device='cuda:0'))), ((4, 6), ((10, 6), tensor(0.9994, device='cuda:0'))), ((3, 2), ((4, 8), tensor(0.9993, device='cuda:0'))), ((5, 6), ((11, 6), tensor(0.9993, device='cuda:0'))), ((5, 7), ((9, 4), tensor(0.9993, device='cuda:0'))), ((4, 9), ((10, 6), tensor(0.9992, device='cuda:0'))), ((2, 10), ((4, 4), tensor(0.9989, device='cuda:0'))), ((3, 6), ((9, 5), tensor(0.9989, device='cuda:0'))), ((5, 5), ((6, 3), tensor(0.9989, device='cuda:0'))), ((1, 11), ((4, 4), tensor(0.9989, device='cuda:0'))), ((4, 4), ((9, 4), tensor(0.9986, device='cuda:0'))), ((5, 2), ((11, 6), tensor(0.9983, device='cuda:0'))), ((2, 4), ((6, 6), tensor(0.9980, device='cuda:0'))), ((3, 1), ((11, 9), tensor(0.9979, device='cuda:0'))), ((1, 7), ((6, 6), tensor(0.9978, device='cuda:0'))), ((4, 2), ((8, 3), tensor(0.9975, device='cuda:0'))), ((5, 1), ((10, 0), tensor(0.9973, device='cuda:0'))), ((3, 10), ((9, 4), tensor(0.9972, device='cuda:0'))), ((2, 8), ((8, 3), tensor(0.9970, device='cuda:0'))), ((2, 6), ((6, 7), tensor(0.9970, device='cuda:0'))), ((3, 4), ((7, 4), tensor(0.9965, device='cuda:0'))), ((4, 8), ((10, 0), tensor(0.9961, device='cuda:0'))), ((5, 11), ((9, 0), tensor(0.9945, device='cuda:0'))), ((3, 3), ((6, 5), tensor(0.9945, device='cuda:0'))), ((1, 1), ((8, 0), tensor(0.9938, device='cuda:0'))), ((4, 0), ((7, 4), tensor(0.9920, device='cuda:0'))), ((3, 7), ((6, 1), tensor(0.9910, device='cuda:0'))), ((4, 7), ((8, 8), tensor(0.9899, device='cuda:0'))), ((3, 9), ((7, 9), tensor(0.9898, device='cuda:0'))), ((5, 3), ((11, 11), tensor(0.9896, device='cuda:0'))), ((0, 9), ((1, 9), tensor(0.9884, device='cuda:0'))), ((3, 5), ((11, 3), tensor(0.9882, device='cuda:0'))), ((3, 0), ((9, 10), tensor(0.9873, device='cuda:0'))), ((1, 10), ((0, 0), tensor(0.9873, device='cuda:0'))), ((5, 4), ((8, 0), tensor(0.9860, device='cuda:0'))), ((2, 2), ((8, 2), tensor(0.9851, device='cuda:0'))), ((2, 5), ((4, 3), tensor(0.9827, device='cuda:0'))), ((5, 10), ((7, 9), tensor(0.9827, device='cuda:0'))), ((0, 8), ((1, 4), tensor(0.9817, device='cuda:0'))), ((4, 10), ((9, 10), tensor(0.9817, device='cuda:0'))), ((3, 11), ((6, 1), tensor(0.9812, device='cuda:0'))), ((0, 2), ((1, 9), tensor(0.9791, device='cuda:0'))), ((0, 10), ((10, 8), tensor(0.9767, device='cuda:0'))), ((3, 8), ((4, 3), tensor(0.9742, device='cuda:0'))), ((4, 3), ((4, 0), tensor(0.9635, device='cuda:0'))), ((5, 0), ((0, 11), tensor(0.9631, device='cuda:0'))), ((1, 3), ((2, 3), tensor(0.9626, device='cuda:0'))), ((1, 4), ((6, 0), tensor(0.9621, device='cuda:0'))), ((0, 0), ((1, 8), tensor(0.9590, device='cuda:0'))), ((0, 5), ((0, 1), tensor(0.9588, device='cuda:0'))), ((1, 6), ((1, 7), tensor(0.9582, device='cuda:0'))), ((0, 7), ((1, 0), tensor(0.9566, device='cuda:0'))), ((2, 11), ((4, 11), tensor(0.9561, device='cuda:0'))), ((2, 9), ((8, 5), tensor(0.9521, device='cuda:0'))), ((0, 1), ((0, 1), tensor(0.9507, device='cuda:0'))), ((2, 7), ((4, 7), tensor(0.9439, device='cuda:0'))), ((0, 3), ((0, 1), tensor(0.9394, device='cuda:0'))), ((2, 0), ((8, 7), tensor(0.9384, device='cuda:0'))), ((1, 0), ((2, 0), tensor(0.9366, device='cuda:0'))), ((0, 6), ((1, 8), tensor(0.9344, device='cuda:0'))), ((2, 1), ((4, 1), tensor(0.9343, device='cuda:0'))), ((1, 5), ((2, 5), tensor(0.9282, device='cuda:0'))), ((1, 2), ((2, 2), tensor(0.9258, device='cuda:0'))), ((1, 9), ((2, 9), tensor(0.9249, device='cuda:0'))), ((0, 11), ((1, 8), tensor(0.9127, device='cuda:0'))), ((1, 8), ((2, 8), tensor(0.9041, device='cuda:0'))), ((0, 4), ((0, 4), tensor(0.9033, device='cuda:0'))), ((5, 8), ((1, 10), tensor(0.9031, device='cuda:0'))), ((2, 3), ((4, 1), tensor(0.8304, device='cuda:0')))]\n",
      "[(1, (5, 0.17380045)), (2, (5, 0.16502175)), (3, (5, 0.15884043)), (5, (10, 0.15294863)), (0, (1, 0.13220264)), (4, (9, 0.105078615))]\n"
     ]
    }
   ],
   "source": [
    "attn_matches = max_vals_attn\n",
    "mlp_matches = max_vals_mlp\n",
    "print(sorted(attn_matches.items(), key=lambda x: x[1][1], reverse=True))\n",
    "print(sorted(mlp_matches.items(), key=lambda x: x[1][1], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1742789137967,
     "user": {
      "displayName": "Reilly H",
      "userId": "05616995266737589283"
     },
     "user_tz": -780
    },
    "id": "Npntd_607MrK"
   },
   "outputs": [],
   "source": [
    "teacher_influences = {comp: abs(score) for comp, score in component_influence_teacher}\n",
    "student_influences = {comp: abs(score) for comp, score in component_influence_student}\n",
    "teacher_probs, student_probs = teacher_influences, student_influences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1742789137978,
     "user": {
      "displayName": "Reilly H",
      "userId": "05616995266737589283"
     },
     "user_tz": -780
    },
    "id": "-XOI94op7SKL"
   },
   "outputs": [],
   "source": [
    "\n",
    "matched_pairs = {}\n",
    "\n",
    "for (student_layer, student_head), ((teacher_layer, teacher_head), similarity) in attn_matches.items():\n",
    "    matched_pairs[(teacher_layer, teacher_head)] = (student_layer, student_head)\n",
    "\n",
    "for student_mlp, (teacher_mlp, similarity) in mlp_matches.items():\n",
    "    matched_pairs[teacher_mlp] = student_mlp\n",
    "\n",
    "teacher_matched_probs = []\n",
    "student_matched_probs = []\n",
    "\n",
    "for teacher_comp, student_comp in matched_pairs.items():\n",
    "    if teacher_comp in teacher_probs and student_comp in student_probs:\n",
    "        teacher_matched_probs.append(teacher_probs[teacher_comp])\n",
    "        student_matched_probs.append(student_probs[student_comp])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1742789137992,
     "user": {
      "displayName": "Reilly H",
      "userId": "05616995266737589283"
     },
     "user_tz": -780
    },
    "id": "1VrPc_927ThJ",
    "outputId": "2e519024-f127-47cc-99b6-6538f0eb7630"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(1, 8): (0, 11),\n",
       " (0, 1): (0, 5),\n",
       " (1, 9): (0, 9),\n",
       " (0, 4): (0, 4),\n",
       " (1, 0): (0, 7),\n",
       " (1, 4): (0, 8),\n",
       " (10, 8): (0, 10),\n",
       " (2, 0): (1, 0),\n",
       " (8, 0): (5, 4),\n",
       " (2, 2): (1, 2),\n",
       " (2, 3): (1, 3),\n",
       " (6, 0): (1, 4),\n",
       " (2, 5): (1, 5),\n",
       " (1, 7): (1, 6),\n",
       " (6, 6): (2, 4),\n",
       " (2, 8): (1, 8),\n",
       " (2, 9): (1, 9),\n",
       " (0, 0): (1, 10),\n",
       " (4, 4): (4, 5),\n",
       " (8, 7): (2, 0),\n",
       " (4, 1): (2, 3),\n",
       " (8, 2): (2, 2),\n",
       " (4, 3): (3, 8),\n",
       " (6, 7): (2, 6),\n",
       " (4, 7): (2, 7),\n",
       " (8, 3): (4, 2),\n",
       " (8, 5): (2, 9),\n",
       " (4, 11): (2, 11),\n",
       " (9, 10): (4, 10),\n",
       " (11, 9): (3, 1),\n",
       " (4, 8): (4, 1),\n",
       " (6, 5): (3, 3),\n",
       " (7, 4): (4, 0),\n",
       " (11, 3): (3, 5),\n",
       " (9, 5): (3, 6),\n",
       " (6, 1): (3, 11),\n",
       " (7, 9): (5, 10),\n",
       " (9, 4): (5, 7),\n",
       " (4, 0): (4, 3),\n",
       " (10, 6): (5, 9),\n",
       " (8, 8): (4, 7),\n",
       " (10, 0): (5, 1),\n",
       " (0, 11): (5, 0),\n",
       " (11, 6): (5, 6),\n",
       " (11, 11): (5, 3),\n",
       " (6, 3): (5, 5),\n",
       " (1, 10): (5, 8),\n",
       " (9, 0): (5, 11),\n",
       " 1: 0,\n",
       " 5: 3,\n",
       " 9: 4,\n",
       " 10: 5}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matched_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 42,
     "status": "ok",
     "timestamp": 1742789138035,
     "user": {
      "displayName": "Reilly H",
      "userId": "05616995266737589283"
     },
     "user_tz": -780
    },
    "id": "-INZnPn17UxW",
    "outputId": "3e82b465-973a-4459-94ca-5a05c2914b98"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5.84,\n",
       " 14.41,\n",
       " 1.65,\n",
       " 3.72,\n",
       " 7.53,\n",
       " 1.21,\n",
       " 0.96,\n",
       " 23.63,\n",
       " 7.55,\n",
       " 6.3,\n",
       " 8.91,\n",
       " 0.02,\n",
       " 5.23,\n",
       " 3.25,\n",
       " 9.99,\n",
       " 11.96,\n",
       " 10.8,\n",
       " 10.47,\n",
       " 3.3,\n",
       " 0.93,\n",
       " 3.72,\n",
       " 1.59,\n",
       " 2.89,\n",
       " 1.57,\n",
       " 5.98,\n",
       " 2.67,\n",
       " 6.94,\n",
       " 7.32,\n",
       " 0.65,\n",
       " 1.49,\n",
       " 1.79,\n",
       " 4.47,\n",
       " 3.26,\n",
       " 0.71,\n",
       " 1.7,\n",
       " 2.71,\n",
       " 0.05,\n",
       " 2.63,\n",
       " 0.59,\n",
       " 1.45,\n",
       " 4.73,\n",
       " 0.05,\n",
       " 4.61,\n",
       " 2.52,\n",
       " 2.02,\n",
       " 1.11,\n",
       " 7.29,\n",
       " 0.09,\n",
       " 21.13,\n",
       " 9.08,\n",
       " 3.19,\n",
       " 30.4]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teacher_matched_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1742789138039,
     "user": {
      "displayName": "Reilly H",
      "userId": "05616995266737589283"
     },
     "user_tz": -780
    },
    "id": "BoN4hd_I7XNG",
    "outputId": "7db56896-f392-47dc-cad0-6ca2e8afbe9a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[82.19,\n",
       " 100.98,\n",
       " 115.93,\n",
       " 8.12,\n",
       " 72.28,\n",
       " 37.33,\n",
       " 109.62,\n",
       " 20.04,\n",
       " 1.55,\n",
       " 15.56,\n",
       " 11.49,\n",
       " 17.68,\n",
       " 18.69,\n",
       " 24.41,\n",
       " 14.75,\n",
       " 10.67,\n",
       " 54.74,\n",
       " 23.35,\n",
       " 31.32,\n",
       " 12.9,\n",
       " 32.44,\n",
       " 25.24,\n",
       " 19.77,\n",
       " 48.8,\n",
       " 61.37,\n",
       " 4.47,\n",
       " 9.73,\n",
       " 17.06,\n",
       " 18.54,\n",
       " 110.59,\n",
       " 6.67,\n",
       " 31.18,\n",
       " 0.25,\n",
       " 12.34,\n",
       " 58.49,\n",
       " 22.94,\n",
       " 104.01,\n",
       " 8.38,\n",
       " 9.72,\n",
       " 31.19,\n",
       " 152.1,\n",
       " 40.79,\n",
       " 42.54,\n",
       " 40.01,\n",
       " 10.49,\n",
       " 4.47,\n",
       " 8.89,\n",
       " 16.81,\n",
       " 456.07,\n",
       " 15.41,\n",
       " 662.85,\n",
       " 85.14]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_matched_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_attn = [match for match in attn_matches.items()]\n",
    "\n",
    "matched_attn_sim = set(attn_matches.items())\n",
    "unmatched_attn_sim = set(attn_matches.items()) - set(filtered_attn)\n",
    "\n",
    "filtered_attn_list = [x[0] for x in filtered_attn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_mlp = [match for match in mlp_matches.items()]\n",
    "\n",
    "matched_mlp_sim = set(filtered_mlp)\n",
    "unmatched_mlp_sim = set(mlp_matches.items()) - set(filtered_mlp)\n",
    "\n",
    "filtered_mlp_list = [a[0] for a in filtered_mlp]\n",
    "filtered_mlp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched = list(matched_attn_sim) + list(matched_mlp_sim)\n",
    "unmatched = list(unmatched_attn_sim) + list(unmatched_mlp_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sims = matched + unmatched\n",
    "matched_norm = [\n",
    "    (entry[0], (entry[1][0], entry[1][1]))\n",
    "    for entry in matched\n",
    "]\n",
    "\n",
    "unmatched_norm = [\n",
    "    (entry[0], (entry[1][0], entry[1][1]))\n",
    "    for entry in unmatched\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_matched = []\n",
    "student_unmatched = []\n",
    "\n",
    "for student_comp, (teacher_comp, similarity) in matched_norm:\n",
    "    try:\n",
    "        student_matched.append((student_probs[student_comp], teacher_probs[teacher_comp], similarity.item()))\n",
    "    except:\n",
    "        student_matched.append((student_probs[student_comp], teacher_probs[teacher_comp], similarity))\n",
    "\n",
    "for student_comp, (teacher_comp, similarity) in unmatched_norm:\n",
    "    try:\n",
    "        student_unmatched.append((student_probs[student_comp], teacher_probs[teacher_comp], similarity.item()))\n",
    "    except:\n",
    "        student_unmatched.append((student_probs[student_comp], teacher_probs[teacher_comp], similarity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_student = student_unmatched + student_matched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher performance: -7.0053629875183105\n",
      "Student performance: -0.23112374544143677\n",
      "Performance drop: -6.774239242076874\n",
      "Mean performance: -3.6182433664798737\n"
     ]
    }
   ],
   "source": [
    "print(f\"Teacher performance: {orig_score_t}\")\n",
    "print(f\"Student performance: {orig_score_s}\")\n",
    "print(f\"Performance drop: {orig_score_t - orig_score_s}\")\n",
    "print(f\"Mean performance: {(orig_score_t + orig_score_s) / 2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.9074308055403248, 0.3111201443052768, 0.996961772441864),\n",
       " (0.3287577180728063, 0.003963313940194608, 0.962141215801239),\n",
       " (0.31722888406799066, 1.4505729021112268, 0.9560507535934448),\n",
       " (2.056409278375093, 0.29526688854449834, 0.9978733062744141),\n",
       " (0.6071232746084346, 0.6460201722517213, 0.996532142162323),\n",
       " (0.7584857081555297, 0.009908284850486523, 0.9973386526107788),\n",
       " (0.45390135170572404, 0.6440385152816239, 0.9581529498100281),\n",
       " (0.22946098648294283, 0.1406976448769086, 0.9881876707077026),\n",
       " (0.02882208501203901, 1.4961510124234647, 0.9859961867332458),\n",
       " (0.1558252080005722, 0.521175783135591, 0.9992665648460388),\n",
       " (0.6941473764512363, 0.23978049338177382, 0.9816961288452148),\n",
       " (0.9146828140272251, 1.979675313127207, 0.9978430867195129),\n",
       " (2.8282833098910536, 0.937323746856025, 0.9898607134819031),\n",
       " (0.31258016067895206, 0.01783491273087574, 0.9945087432861328),\n",
       " (0.08311917419600927, 0.2199639236808008, 0.9988729357719421),\n",
       " (0.5799747300164495, 0.2873402606641091, 0.9995672106742859),\n",
       " (0.2746465778243975, 1.1572876705368258, 0.9589877128601074),\n",
       " (2.0383722316256234, 0.1902390691293412, 0.9767019152641296),\n",
       " (0.18557703769041894, 0.6539468001321104, 0.9989359974861145),\n",
       " (0.19859346317972681, 0.12880770305632477, 0.9873067736625671),\n",
       " (0.36762104560516856, 0.572698864358121, 0.9742295742034912),\n",
       " (0.4265668581781774, 0.5370290388963694, 0.9812316298484802),\n",
       " (0.1240279400195485, 0.35471659764741753, 0.9996066689491272),\n",
       " (0.6041480916394499, 0.3269734000660552, 0.979123055934906),\n",
       " (1.5283143013803135, 1.1572876705368258, 0.9126543998718262),\n",
       " (0.6852218275442823, 0.6539468001321104, 0.9988722801208496),\n",
       " (0.46933511335733197, 0.3150834582454714, 0.9851008653640747),\n",
       " (0.1984075142441653, 2.3700617362363765, 0.9040664434432983),\n",
       " (1.8777123513004512, 2.8555676939102157, 0.9588498473167419),\n",
       " (0.21848999928481186, 0.35471659764741753, 0.9993415474891663),\n",
       " (0.23987412687438917, 0.18429409821904932, 0.9384071230888367),\n",
       " (0.3361956754952679, 0.521175783135591, 0.9985865354537964),\n",
       " (0.5823920661787496, 0.6539468001321104, 0.9994288682937622),\n",
       " (1.9340548787755985, 0.009908284850486523, 0.9827010631561279),\n",
       " (0.5554294705223259, 0.2873402606641091, 0.9992464780807495),\n",
       " (0.2824564331179823, 0.009908284850486523, 0.9961444139480591),\n",
       " (0.2742746799532744, 1.979675313127207, 0.997951865196228),\n",
       " (0.16530860371421086, 1.444627931200935, 0.9031306505203247),\n",
       " (0.34753856056452204, 1.0364065953608903, 0.928193986415863),\n",
       " (0.1509905356759721, 0.7371763928761973, 0.903287410736084),\n",
       " (0.548921257777672, 1.1572876705368258, 0.934402346611023),\n",
       " (0.7439816911817295, 0.4993775564645207, 0.9993039965629578),\n",
       " (1.0876153240994593, 0.3368816849165417, 0.9988783597946167),\n",
       " (0.17386225475004177, 0.5370290388963694, 0.9909701347351074),\n",
       " (1.336972846687487, 0.009908284850486523, 0.9898247718811035),\n",
       " (0.18092831430138037, 1.3752699372475294, 0.9521389007568359),\n",
       " (0.6705318616349204, 0.2873402606641091, 0.9993979930877686),\n",
       " (0.08311917419600927, 0.5291024110159802, 0.9975275993347168),\n",
       " (0.9051994183135863, 0.5291024110159802, 0.9970179796218872),\n",
       " (1.141168617541183, 1.1850308681181883, 0.9438655376434326),\n",
       " (0.6032183469616422, 0.7371763928761973, 0.8304243087768555),\n",
       " (0.19506043340405757, 0.4002947079596555, 0.9896024465560913),\n",
       " (0.8350966696068851, 1.4961510124234647, 0.9938228130340576),\n",
       " (0.22072138651155035, 0.572698864358121, 0.9827090501785278),\n",
       " (0.34474932653109885, 0.12880770305632477, 0.9816591143608093),\n",
       " (1.3440389062388256, 1.49218769848327, 0.9565545916557312),\n",
       " (1.358356974277064, 2.8555676939102157, 0.9506551623344421),\n",
       " (0.1865067823682266, 0.7371763928761973, 0.9343400001525879),\n",
       " (1.4888931270412666, 0.4993775564645207, 0.9983378648757935),\n",
       " (0.5797887810808879, 0.8858006656334949, 0.9944815635681152),\n",
       " (1.768188428254703, 0.521175783135591, 0.9971551299095154),\n",
       " (0.00464872338903855, 0.6460201722517213, 0.991960883140564),\n",
       " (0.18074236536581884, 0.11691776123574095, 0.963497519493103),\n",
       " (0.7910267718787997, 0.9135438632148574, 0.9631072282791138),\n",
       " (0.3726416668653302, 4.6826554203399295, 0.9365625381469727),\n",
       " (0.21365532696021175, 1.7656563603566982, 0.9626466035842896),\n",
       " (0.07475147209573987, 0.521175783135591, 0.9994311332702637),\n",
       " (0.0336567573366391, 2.8555676939102157, 0.9394195079803467),\n",
       " (2.1557060099649563, 0.3269734000660552, 0.9884111285209656),\n",
       " (0.43419076453620054, 2.074794847691878, 0.9872657656669617),\n",
       " (0.28933654373375933, 1.2484438911613018, 0.925757884979248),\n",
       " (1.017884473263881, 2.140189527705089, 0.9248654842376709),\n",
       " (12.325625193696812, 0.63214857346104, 0.10507861524820328),\n",
       " (1.5831692373709685, 6.024237189095805, 0.15294863283634186),\n",
       " (8.480573104155246, 4.187241177815604, 0.1322026401758194),\n",
       " (0.2865473097003362, 1.7993445288483525, 0.15884043276309967),\n",
       " (4.971158843302263, 1.7993445288483525, 0.16502174735069275),\n",
       " (3.6659832645958006, 1.7993445288483525, 0.17380045354366302)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scale influences by length of pairs\n",
    "all_student_scaled = all_student.copy()\n",
    "\n",
    "for i in range(len(all_student)):\n",
    "    (I_S, I_T, S) = all_student[i]\n",
    "    all_student_scaled[i] = (I_S * len(all_student), I_T * len(all_student), S)\n",
    "\n",
    "all_student_normalised = all_student.copy()\n",
    "sum_I_T = sum(I_T for _, I_T, _ in all_student)\n",
    "sum_I_S = sum(I_S for I_S, _, _ in all_student)\n",
    "for i in range(len(all_student_normalised)):\n",
    "    (I_S, I_T, S) = all_student[i]\n",
    "    all_student_normalised[i] = (I_S / sum_I_S, I_T / sum_I_T, S)\n",
    "    \n",
    "# normalise scaled influences\n",
    "all_student_scaled_normalised = all_student_normalised.copy()\n",
    "sum_I_T = sum(I_T for _, I_T, _ in all_student_normalised)\n",
    "sum_I_S = sum(I_S for I_S, _, _ in all_student_normalised)\n",
    "for i in range(len(all_student_scaled_normalised)):\n",
    "    (I_S, I_T, S) = all_student_normalised[i]\n",
    "    all_student_scaled_normalised[i] = (I_S * len(all_student), I_T * len(all_student), S)\n",
    "\n",
    "all_student_scaled_normalised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alignment(pairs):\n",
    "    return sum(S * (1 - abs(I_S - I_T)) for I_S, I_T, S in pairs) / len(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alignment score: 0.9\n"
     ]
    }
   ],
   "source": [
    "print(f\"Alignment score: {round(alignment(all_student_normalised), 2)}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOD4SQ0p6vgYMyivLs2ekZF",
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
